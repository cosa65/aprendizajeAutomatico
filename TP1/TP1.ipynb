{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "\n",
    "import sklearn.model_selection\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "import scipy as sp\n",
    "from scipy.stats import expon\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import math\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6   ...       193  \\\n",
       "index                                                           ...             \n",
       "0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "...       ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "          194     195     196     197     198     199  \n",
       "index                                                  \n",
       "0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "...       ...\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego. \n",
    "\n",
    "# X_competencia = pd.read_csv(\"X_competencia.csv\", index_col=\"index\")\n",
    "# y_competencia_ejemplo = pd.read_csv(\"y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "display(X)\n",
    "display(y)\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAADFCAYAAAAhb/tIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADQ1JREFUeJzt3XGsnXV9x/H3R6osm2yALaQr3YqmJFaTFXLDWEg2DItCTVZMBimJWk2zqiuLZvsH9Q/JFhJcBiYkjKUGQlkU6KaGZsNt2GCYxoIX7UpLx+ygg9qmvQ6HGDJm4bs/ztN5Kbc9p/ecc+9df+9XcnKe8zu/5zzfb8/tp89znvP0pqqQpJa9ab4LkKT5ZhBKap5BKKl5BqGk5hmEkppnEEpqnkEoqXkGoaTm9Q3CJMuTPJJkb5I9ST7Zjd+U5IdJdna3NdPW+XSSfUmeTvK+cTYgScNKvytLkiwFllbV95KcBTwBXANcB/y0qv7iuPmrgPuAS4FfBb4BXFRVr55oG4sXL64VK1YM04ckvcETTzzxo6pa0m/eon4TquoQcKhbfinJXmDZSVZZC9xfVa8AzybZRy8Uv3OiFVasWMHk5GS/UiTplCT5j0HmndJnhElWABcDj3VDNyTZleTuJOd0Y8uA56etdoAZgjPJxiSTSSanpqZOpQxJGqmBgzDJW4GvAJ+qqp8AdwLvAFbT22O89djUGVZ/w/F3VW2uqomqmliypO+eqySNzUBBmOTN9ELwS1X1VYCqOlxVr1bVa8AX6R3+Qm8PcPm01S8ADo6uZEkarUHOGge4C9hbVbdNG186bdoHgN3d8jZgXZIzk1wIrAQeH13JkjRafU+WAJcDHwKeTLKzG/sMcH2S1fQOe/cDHwOoqj1JtgJPAUeBTSc7YyxJ822Qs8bfYubP/R46yTo3AzcPUVdfK278+3G+PAD7b3n/2Lchaf55ZYmk5hmEkppnEEpqnkEoqXkGoaTmGYSSmmcQSmqeQSipeQahpOYZhJKaZxBKap5BKKl5BqGk5hmEkppnEEpqnkEoqXkGoaTmGYSSmmcQSmqeQSipeQahpOYN8us8Jemk5uK3SsL4frOke4SSmtc3CJMsT/JIkr1J9iT5ZDd+bpKHk/yguz+nG0+S25PsS7IrySXjbkKShjHIHuFR4E+q6p3AZcCmJKuAG4HtVbUS2N49BrgaWNndNgJ3jrxqSRqhvkFYVYeq6nvd8kvAXmAZsBbY0k3bAlzTLa8F7q2eHcDZSZaOvHJJGpFT+owwyQrgYuAx4PyqOgS9sATO66YtA56fttqBbuz419qYZDLJ5NTU1KlXLkkjMnAQJnkr8BXgU1X1k5NNnWGs3jBQtbmqJqpqYsmSJYOWIUkjN1AQJnkzvRD8UlV9tRs+fOyQt7s/0o0fAJZPW/0C4OBoypWk0RvkrHGAu4C9VXXbtKe2Aeu75fXAg9PGP9ydPb4MePHYIbQkLUSDfKH6cuBDwJNJdnZjnwFuAbYm2QA8B1zbPfcQsAbYB7wMfHSkFUvSiPUNwqr6FjN/7gdw5QzzC9g0ZF2SNGe8skRS8wxCSc0zCCU1zyCU1DyDUFLzDEJJzTMIJTXPIJTUPINQUvMMQknNMwglNc8glNQ8g1BS8wxCSc0zCCU1zyCU1DyDUFLzDEJJzTMIJTXPIJTUPINQUvMMQknNMwglNc8glNS8vkGY5O4kR5LsnjZ2U5IfJtnZ3dZMe+7TSfYleTrJ+8ZVuCSNyiB7hPcAV80w/oWqWt3dHgJIsgpYB7yrW+cvk5wxqmIlaRz6BmFVPQq8MODrrQXur6pXqupZYB9w6RD1SdLYDfMZ4Q1JdnWHzud0Y8uA56fNOdCNvUGSjUkmk0xOTU0NUYYkDWe2QXgn8A5gNXAIuLUbzwxza6YXqKrNVTVRVRNLliyZZRmSNLxZBWFVHa6qV6vqNeCL/Pzw9wCwfNrUC4CDw5UoSeM1qyBMsnTaww8Ax84obwPWJTkzyYXASuDx4UqUpPFa1G9CkvuAK4DFSQ4AnwOuSLKa3mHvfuBjAFW1J8lW4CngKLCpql4dT+mSNBp9g7Cqrp9h+K6TzL8ZuHmYoiRpLnlliaTmGYSSmmcQSmqeQSipeQahpOYZhJKaZxBKap5BKKl5BqGk5hmEkppnEEpqnkEoqXkGoaTmGYSSmmcQSmqeQSipeQahpOYZhJKaZxBKap5BKKl5BqGk5hmEkppnEEpqXt8gTHJ3kiNJdk8bOzfJw0l+0N2f040nye1J9iXZleSScRYvSaMwyB7hPcBVx43dCGyvqpXA9u4xwNXAyu62EbhzNGVK0vj0DcKqehR44bjhtcCWbnkLcM208XurZwdwdpKloypWksZhtp8Rnl9VhwC6+/O68WXA89PmHejG3iDJxiSTSSanpqZmWYYkDW/UJ0syw1jNNLGqNlfVRFVNLFmyZMRlSNLgZhuEh48d8nb3R7rxA8DyafMuAA7OvjxJGr/ZBuE2YH23vB54cNr4h7uzx5cBLx47hJakhWpRvwlJ7gOuABYnOQB8DrgF2JpkA/AccG03/SFgDbAPeBn46BhqlqSR6huEVXX9CZ66coa5BWwatihJmkteWSKpeQahpOYZhJKaZxBKap5BKKl5BqGk5hmEkppnEEpqnkEoqXkGoaTmGYSSmmcQSmqeQSipeQahpOYZhJKaZxBKap5BKKl5BqGk5hmEkppnEEpqnkEoqXkGoaTmGYSSmtf39xqfTJL9wEvAq8DRqppIci7wALAC2A9cV1U/Hq5MSRqfUewRvqeqVlfVRPf4RmB7Va0EtnePJWnBGseh8VpgS7e8BbhmDNuQpJEZNggL+KckTyTZ2I2dX1WHALr782ZaMcnGJJNJJqempoYsQ5Jmb6jPCIHLq+pgkvOAh5P866ArVtVmYDPAxMREDVmHJM3aUHuEVXWwuz8CfA24FDicZClAd39k2CIlaZxmHYRJfinJWceWgfcCu4FtwPpu2nrgwWGLlKRxGubQ+Hzga0mOvc6Xq+ofknwX2JpkA/AccO3wZUrS+Mw6CKvqGeA3Zhj/T+DKYYqSpLnklSWSmmcQSmqeQSipeQahpOYZhJKaZxBKap5BKKl5BqGk5hmEkppnEEpqnkEoqXkGoaTmGYSSmmcQSmqeQSipeQahpOYZhJKaZxBKap5BKKl5BqGk5hmEkppnEEpqnkEoqXljC8IkVyV5Osm+JDeOazuSNKyxBGGSM4A7gKuBVcD1SVaNY1uSNKxx7RFeCuyrqmeq6n+A+4G1Y9qWJA1l0Zhedxnw/LTHB4DfnD4hyUZgY/fwp0mePsVtLAZ+NOsKB5DPj/PVX2fsvcyR06UPsJcFKZ8/5V5+fZBJ4wrCzDBWr3tQtRnYPOsNJJNVNTHb9ReS06WX06UPsJeFaly9jOvQ+ACwfNrjC4CDY9qWJA1lXEH4XWBlkguTvAVYB2wb07YkaShjOTSuqqNJbgD+ETgDuLuq9ox4M7M+rF6ATpdeTpc+wF4WqrH0kqrqP0uSTmNeWSKpeQahpOYt+CDsd6lekjOTPNA9/1iSFXNfZX8D9PHHSZ5KsivJ9iQDff9pPgx6+WSS309SSRbsVzcG6SXJdd17syfJl+e6xkEN8DP2a0keSfL97udszXzU2U+Su5McSbL7BM8nye1dn7uSXDL0Rqtqwd7onWj5d+DtwFuAfwFWHTfnD4G/6pbXAQ/Md92z7OM9wC92y59YiH0M2ks37yzgUWAHMDHfdQ/xvqwEvg+c0z0+b77rHqKXzcAnuuVVwP75rvsEvfw2cAmw+wTPrwG+Tu/7ypcBjw27zYW+RzjIpXprgS3d8t8CVyaZ6Qvd86lvH1X1SFW93D3cQe+7lwvRoJdP/hnw58B/z2Vxp2iQXv4AuKOqfgxQVUfmuMZBDdJLAb/cLf8KC/S7vVX1KPDCSaasBe6tnh3A2UmWDrPNhR6EM12qt+xEc6rqKPAi8LY5qW5wg/Qx3QZ6/+ItRH17SXIxsLyq/m4uC5uFQd6Xi4CLknw7yY4kV81ZdadmkF5uAj6Y5ADwEPBHc1PayJ3q36e+xnWJ3aj0vVRvwDnzbeAak3wQmAB+Z6wVzd5Je0nyJuALwEfmqqAhDPK+LKJ3eHwFvb30f07y7qr6rzHXdqoG6eV64J6qujXJbwF/3fXy2vjLG6mR/51f6HuEg1yq939zkiyit8t/st3q+TDQJYdJfhf4LPB7VfXKHNV2qvr1chbwbuCbSfbT+wxn2wI9YTLoz9eDVfWzqnoWeJpeMC40g/SyAdgKUFXfAX6B3n/I8P/N6C/hne8PRvt8aLoIeAa4kJ9/APyu4+Zs4vUnS7bOd92z7ONieh92r5zveoft5bj532ThniwZ5H25CtjSLS+md0j2tvmufZa9fB34SLf8zi48Mt+1n6CfFZz4ZMn7ef3JkseH3t58NzzAH8ga4N+6kPhsN/an9PaaoPev2t8A+4DHgbfPd82z7OMbwGFgZ3fbNt81z7aX4+Yu2CAc8H0JcBvwFPAksG6+ax6il1XAt7uQ3Am8d75rPkEf9wGHgJ/R2/vbAHwc+Pi09+SOrs8nR/Hz5SV2kpq30D8jlKSxMwglNc8glNQ8g1BS8wxCSc0zCCU1zyCU1Lz/BUUktZhWO3+PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO 1. \n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO\n",
    "\n",
    "X_dev, X_eval, y_dev, y_eval = train_test_split(X, y, test_size = 0.1)\n",
    "\n",
    "# Objetivo: variables X_dev, X_eval, y_dev e y_eval asignadas\n",
    "#########################################################\n",
    "\n",
    "\n",
    "# print(\"X_dev: {}, y_dev: {} para desarrollo\".format(X_dev.shape, y_dev.shape))\n",
    "# print(\"X_eval: {}, y_eval: {} para evaluación\".format(X_eval.shape, y_eval.shape))\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(y_dev))  # muestra un histograma para la distribución de y.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA: Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.   **\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.6892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.7523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.8543</td>\n",
       "      <td>0.7456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8056</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.7566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.8167                 0.6556              0.8737   \n",
       "2                         0.8278                 0.6111              0.8878   \n",
       "3                         0.8222                 0.7111              0.8739   \n",
       "4                         0.8361                 0.7111              0.8543   \n",
       "5                         0.8056                 0.7444              0.8822   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.6892  \n",
       "2                          0.6410  \n",
       "3                          0.7523  \n",
       "4                          0.7456  \n",
       "5                          0.7566  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAEGCAYAAAAAHm2OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XtcVVXeBvDnd7gjiICEiiKMyuUAKkIkmZXzagNTajM2aVpmb2DaWNpl1GlmssvkdJ1pMPPVHDXNUrMylUqdcqx0TA9euSqaAiqgiAhyE1jvH5yDRzaXA3L3+X4+fjpn73XWXm41nrP23usnSikQERERmdO19wCIiIio42FAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItKwbq8D9+zZU/n4+LTX4YmIOqWEhIQLSimP9h4HdX3tFhB8fHxgMBja6/BERJ2SiJxu7zHQzYGXGIiIiEiDAYGIiIg0GBCIiIhIo93uQSAiopaRkJBwi7W19XIAweAXP7JcFYDEioqKmLCwsNzaOxkQiIg6OWtr6+W9evUK9PDwyNfpdKq9x0OdQ1VVlZw/f16fnZ29HMC42vuZNImIOr9gDw+PywwH1BQ6nU55eHgUoHrmSbu/jcdDREQtT8dwQM1h/HtTZxZgQCAiIiIN3oNANUI+DGlw/9FHj7bRSIjoRvjMjw9ryf5OvX5vgiXtVq9e3ePRRx8dcODAgaTQ0NDSlhxDWygqKpJRo0b5/fe//007ceKE7c6dO51mzJhxsan9hIaGBhw8eDC1oTYTJ07sP3fu3JywsLAmn6ezZ89aT5w40feHH3443tTPNgVnEIiIqEWsW7fObdiwYUVr1qxxa83jVFRUtEq/ixYt6jlu3Lh8a2trHD9+3G79+vV1/j6uXr3aYD+NhQMAWL9+/enmhAMA6NOnT4Wnp+fV7du3d2vO5y3FgEBEZIGQD0Ma/XUzKygo0BkMBqeVK1ee+uKLL1zN9/35z3/29PPz0/v7++uffPJJLwBITEy0u/322/38/f31er0+MCkpyW7r1q3Oo0aNGmj63NSpU73j4uLcAcDLyyvk+eef7x0WFua/YsUK13feeadncHBwoL+/v/5Xv/rVgMLCQh0AZGZmWo8ZM2aAv7+/3t/fX79jx45us2fP7vPqq6/eYur3qaee8vrrX/96C2rZsGGD+4MPPngJAP70pz95GQwGp4CAAP3LL798S1xcnHt0dPQvfvnLXw4cOXKkX0FBgS4yMtJPr9cH+vn56T/66KMepn4cHR1DAWDr1q3OERER/lFRUb/w9fUNGjdunG9VVRUAICIiwv/77793NLV/6qmnvPz9/fVDhgwJyMzMtAaApKQkuyFDhgQEBwcHzpkzp4+pXwC4//77L61evdr9hv/gGsCAQEREN2zt2rU97r777oLBgweX9ejRo/LHH390BIANGzZ0j4+Pd01ISEhNS0tLXrBgQTYATJ482XfGjBm5aWlpyQaDIdXb27vhr+UA7O3tqxISEtKmT5+eP2XKlPzExMSUtLS0ZH9//5K4uLieADBjxgzvkSNHFqalpSUnJSUlDxs2rPTJJ5+88Mknn7gDQGVlJTZt2uQaExOTZ953aWmpZGZm2vn7+5cDwGuvvXYmPDy8KDU1NXnBggW5AHDgwAGnTz755Oe9e/cec3R0rIqPj09PTk5O2bVr17EXXnihr+mHv7mUlBSHxYsXZ6anpydlZGTY7dixw6l2m5KSEl1kZGRRWlpacmRkZNGiRYs8AGDWrFn9nnzyydzExMSUPn36XHd+RowYcWXfvn2avlrSTX8PAq+7U22WfBPk3wui623YsMFt9uzZuQAwYcKEi2vWrHG74447infs2NH94YcfvuDs7FwFAJ6enpX5+fm6nJwc26lTp14CAEdHRwWg0acwpk6dmm96nZCQ4PDiiy96FRYWWl25csXqrrvuKgCAPXv2OG/cuPFnALC2toa7u3ulu7t7ZY8ePSp2797tcO7cOZugoKDiXr16VZr3nZ2dbe3s7NzgtYuRI0de9vT0rASq1xCYM2dO37179zrpdDrk5ubaZmVlWXt7e1/XR0hIyJUBAwZcBYCgoKDiEydO2Nbu18bGRk2aNKkAAMLCwq78+9//7g4ABw8edNq+fXs6AMTExOS99NJLfU2f6dOnT0Vubq6mr5Z00wcEIiK6MdnZ2VZ79+7tfuzYMYdZs2ahsrJSREQtWbIkSykFEbmuvVJ1ZwEbGxtl/i28rKzsug+aQgYATJ8+3Xfjxo3pkZGRJXFxce67du1ybmiMjz322IXly5f3zM3NtXnsscfyau/v1q1bVXl5eYOz6o6OjjXHX7p0qVteXp710aNHU+zs7JSXl1dISUmJ5vN2dnY1v1krKytUVFRI7TbW1tZKp9OZXtfZprbi4mKxs7PTTlm0IF5iICKiG7JmzRrX3/72t3lnz549eubMmaPZ2dlH+vbtW759+3anqKioy2vWrOlpukcgJyfHys3NrapXr17la9as6QEAJSUlUlhYqBswYEBZenq6Q0lJieTl5Vn9+OOP3es7ZnFxsc7b2/tqWVmZrFu3ruZmwhEjRhS+9dZbHkD1zYwXL17UAcAjjzxyaefOnS6HDx/uNmHChILa/Xl4eFRWVlZKcXGxAICLi0tlUVGRVX3HLygosOrZs+dVOzs7tWXLFuezZ8+2+Lf5oUOHFq1atcoVAFasWHHdDZOJiYn2fn5+JS19THOcQSAi6mIsfSyxpXz66afuc+fOPWe+bfz48flr1qxxW7t2bcaBAwcchw4dGmhjY6NGjx5d8N5775356KOPfo6Nje3/6quv9rGxsVGffvrpCb1eXz527Nj8wMDAIF9f39KgoKDi+o45f/78sxEREYFeXl7lgYGBxaYf5kuWLMmYNm1afz8/v546nQ7vvffe6dGjR1+xt7dXt99+++UePXpUWlvX/aPvzjvvLNi+fbvT/fffXxgREVFibW2t/P399ZMnT77g6up63SWJmJiYi9HR0QODg4MDg4KCin19fVv8sc5FixZlTpkyxTcuLq7XPffcc8nJyalmDDt27HCOiorSBJ2WJPVN9bS28PBwZTAY2uXY5ngPwjU8F9V4D8I1PBfXdJRzISIJSqlw822HDx8+NWTIkAutfvBOrLKyEkFBQfpPP/30REhISFldbXbv3u3w1ltv9dq0adPPbT2+uhQWFuq6detWpdPpsGzZMtf169e7ffvttycAIDw83P/rr79O9/DwqGysn8YcPny455AhQ3xqb+cMAhERdWkJCQn248ePHxQdHZ1fXzgAgBEjRpTs37//ckVFBeqbZWhLu3fvdpw9e7a3Ugrdu3evXLVq1SmgeqGk2bNn57REOGhI+58BIiKiVhQWFlaalZVl0fTOnDlzNDcwtpeoqKiitLS05Nrb+/TpU/HII49cau3j8yZFIiIi0uAMAlEX5jM/vsH9p16/t41GQkSdDWcQiIiISIMzCF0EvykSEd1cLl++rFuyZIn7888/f97Kqt4lG5qNAYGIqKt5yaVFyz3jpYKbrtxzU59iSEtLs73vvvsGHT9+POn77793XLFihfuqVasya7fz8vIKMRgMKb17925SScq1a9e6JCUlOSxcuDAbqK4o+b//+7/ec+fOzWksHDS3PDQDAnU5nE0hah/m5Z5DQ0PPttZxWusxRPNyzzfizjvvLL7zzjvrXeSpOaZMmVIAoGZhJBsbG2zcuPGUJZ81Lw99zz33XLH0mJ36HgSf+fEN/iIiorbR1co933vvvb9Yv369i2nfhAkTfFatWtUjLS3NNiwszF+v1wfq9frAHTt2dKvdj/nvIzs722rEiBGDAgMD9ZMnT+5vvjjh6NGjBwQFBQUOHDgw6O233+5p2r5x48buer0+0N/fXx8ZGekHAHFxce5Tp071BoBjx47ZRkZG+vn5+ekjIyP9jh8/bmsa47Rp0/qFhoYG9O3bN2TlypU1fw7NKQ9tUUAQkSgRSRORdBGZX8d+bxHZKSIHReSIiPy6KYMgIqLOrauVe544ceLF9evXu5r27d69u/sDDzxQ0KdPn4offvjhWHJycsr69etPPvPMM94NjXn+/Pl9IiMji1JSUpLHjRt36dy5czU1G9auXXsqKSkp5dChQ8lLly71zM7Otjp79qz1rFmzfD7//PMTaWlpyZs2bTpRu88ZM2Z4T548Oe/YsWPJEydOzJs5c2Y/076cnBwbg8GQ+uWXXx5fsGCBl2l7c8pDNzqPIiJWABYDGAMgC8B+EdmslDJfvOHPADYopZaIiB7AVwB8mjIQIiLqvLpauecHHnigYO7cud4lJSXy2WefuURERBQ6OTmpvLw83eOPP94/OTnZQafT4fTp03YNjXnv3r3On3/+eToATJo0qeCJJ56oOe4bb7zhGR8f38N4fJukpCT7nJwc64iIiMKAgIBy0/mq3efBgwe7ff311ycAYObMmRdffvnlmjLQ48aNu2RlZYWwsLDSvLw8G9P25pSHtuRCSwSAdKXUSQAQkXUAxgMwDwgKgKnqlguAVrv2RETUHLw3pfV0xXLPjo6Oavjw4YWff/559/Xr17s+9NBDFwHgtdde87zllluufvbZZz9XVVXBwcGh0RtCTaWczW3dutV5165dzgaDIdXZ2bkqIiLCv6SkRFfX+WoKe3v7mpNrfp6bUx7akksMXgDM78TMMm4z9xKAh0UkC9WzB0/V1ZGITBcRg4gYzp8/35RxEhFRB9UVyz0DwKRJky6uWrWq5/79+51/+9vfXgaqyzz37t37qpWVFd5//333ysqGyyEMHz68cMWKFe5A9eWWy5cvWwHApUuXrFxcXCqdnZ2rDh48aH/48OFuADBq1KgrP/30k3Nqaqqt6XzV7jM0NPTK8uXLXQFg6dKlbuHh4UUNDgLNKw9tyQxCXVGmdvx7CMAqpdQ7IhIJYI2IBCulrksrSqllAJYB1dUcmzJQIiKykIWPJbaUrljuGQB+85vfXJ4xY4bv6NGjL5m+mc+ZMyd3woQJAzZt2uR6xx13FDo4ODT4rfz1118/O2HChF/o9frAyMjIot69e5cDwIQJEwqWLVvm4efnpx8wYEDpkCFDrgDVlwLi4uJO/eY3vxlYVVUFd3f3q3v27Lnu8cQlS5ZkPProoz7//Oc/e7m7u1esXr36VGN/Rs0pD91ouWfjD/yXlFK/Mr7/IwAopf5m1iYJQJRSKtP4/iSA4Uqp3Pr6bYlyzy0xZdhVShzzXFxzo+eio5T1bQk8F9d0lXPBcs/N0xnLPbekhspD11fu2ZJLDPsBDBIRXxGxBTAJwOZabTIA/A8AiEggAHsAvIZARETtLiEhwb5///4hI0eOvNxYuee77777ckVFk9Yw6vCaWx660UsMSqkKEZkFYBsAKwArlFJJIvIKAINSajOA5wB8ICLPoPrywzTV2NQEERFRG+is5Z5bSnPLQ1u0XJRS6itU33xovu1Fs9fJAEY09eBERETUMXXqlRSJiIiodTAgEBERkQYDAhEREWmwmiMRURcT8mFIi5Z7Pvro0WaXe966davzO++847lz5850U7sJEyb43HfffQWPPfZYfllZmTzzzDN94uPjXW1tbZW9vX3VX/7ylzMPPvjgZfO+IyIi/HNzc23s7OyqbGxs1LJly07dfvvtJQCQl5dnFRMT089gMDgBQHh4eNHy5csz3d3dKwHgyJEjdk899VS/n3/+2d7a2loFBASULF26NKNfv37XPa5w+vRpm2nTpvXfuXNn+p49exwyMzNtJ06c2KS1A06dOmUzY8aMft98883JhtrdddddAz/77LOfe/bs2aQnCwBg3759Dm+88YbnZ599dqqpn20KziAQEbWQlIDABn91deblni39zDPPPNMnOzvbJjU1Nen48eNJX3311XHTaoO1rV69+mRaWlpybGxs7vPPP19Tf2DKlCn9fX19yzMzMxMzMzMTfXx8yh9++OH+QPUSw2PHjh30xBNPnM/IyEg8efJk0syZM89nZ2drviAvXLjQ8/HHH78AAAaDwTE+Pt6ldhsAuHq1/rpSPj4+VxsLBwCwa9eu9OaEAwCIiIgoOXfunK2pimNr4QwCUTM09j/7wNSUNhoJUcdgKvf873//O238+PED//73vzdak6ewsFD38ccfe5w8efKIg4ODAoB+/fpVxMTE5Df0uTvvvPNKXFxcL6C6bPTRo0e7bd26teaH8ltvvXW2f//+IUlJSXY7duxwGjZsWNHkyZNrZgLGjh1bWFe/8fHxru++++6Z0tJS+dvf/tantLRUFxAQ4PTcc8+dS0lJcTh37pxNRkaGrZubW8Xbb799ZvLkyb4lJSU6APjnP/+ZMWbMmCtpaWm2991336Djx48nxcXFuW/durVHSUmJLiMjwy46OvrS//3f/2UB1eWrDQZDyuXLl3XR0dGDIiIiigwGg5Onp2f5tm3b0p2cnNSuXbscY2NjfRwdHatuu+22ou+++87l+PHjSQAQHR196cMPP3T961//mtP4n07zcAaBiIhuWH3lnhuSnJxs17t373I3N7cmFRHasmVL9+jo6EsAcPjwYXu9Xl9svnyytbU19Hp98aFDh+wTExMdhg0bVu+SzSapqam2Li4uFQ4ODsre3l798Y9/PDt27Nj81NTU5NjY2HwAOHLkiOO2bdvSt2zZ8rOlZZ+Tk5MdN23adDIlJSVp8+bNrunp6Ta122RkZNg//fTTuenp6UkuLi6Vq1evdgWAmJgY38WLF58+dOhQqpWV1XVrC912221X9uzZ02CBqhvFGQQiuiFdZjblpTpnk6/xrfP//2RUX7lnEalz0bz6tjdk6tSpvygpKdFVVVXBYDCkAIBSSuqqftjUqoiZmZk2bm5uDS6hGBUVdcnJyUkBQHl5uVhS9vmOO+64bLoXYuDAgaUnTpywGzhw4HXXKLy8vMpM91OEhoYWnzp1yu7ChQtWV65c0Y0ZM+YKADz66KMXd+zY0cP0md69e1fk5ORowkZL4gwCERHdEFO559///vf9vby8Qt57771emzdvdq2qqsItt9xSUVBQcN2X0fz8fGsPD48KvV5fdu7cOdv8/HyLfhatXr36ZEZGxtH777//YmxsrDcADB06tCQpKcnRvKpiZWUlUlJSHAcPHlwaFBRUeuDAgUZnMxwdHavKysoaHEe3bt1qZjpMZZ9TUlKSjx49mnz16tU6P2tra1sThKysrNTVq1c1qaV2m4qKikbrJJWUlOjs7e2bNPPSVAwIRER0Qxoq9xwcHFyWk5Njc+DAAXsAOHbsmG1qaqrD8OHDS5ydnasmTZp0ITY21ru0tFSA6icJ3n///XpvcrSzs1P/+Mc/zhw6dKjbgQMH7IODg8uCgoKK582b19vUZt68eb2Dg4OLg4ODy2JjY/MSEhKc1q1bVzNFtHHjxu779u1zMO83JCSk7MyZMzU3/XXv3r2yqKio3p+RTS373FQeHh6V3bp1q/r222+7AUDtGz+Tk5Pt/P39m1S+ual4iYGIqIux9LHEltJQueeoqKiilStXnnzsscd8ysrKdNbW1mrx4sWnTdPu77777pk5c+Z4+fn5BdnZ2SkHB4fKBQsWNHiDo5OTk5o5c2bO66+/7rlhw4bTa9euPRUTE+Pt7e0drJTCsGHDrqxdu/aUqe2XX36Z/vTTT/ebN29eP2traxUYGFiyZMmSDPM+u3fvXuXt7V2WmJhoFxwcXBYdHV349ttv9w4ICNA/99xz52qPoalln5tj6dKlp2bMmNHf0dGxasSIEYXOzs41KeS7777rft999zXpEcymanQao7Ww3HPL4rm4pi3K+m74W8PV3jrKdXeei2saPRf2kxvcH2LBPQhtcS5Y7rn1rF69uofBYHCMi4tr9AmMtlBQUKBzcXGpAoAXXnih17lz52xWrlyZWVJSIsOHD/c3GAypNjY3fhtCfeWeOYNAREQEYOrUqZcuXLjQYX4ubtiwweWdd97pXVlZKV5eXmUff/zxKQBIT0+3fe211860RDhoSIc5EURERO3t2Wef7TAzMbGxsfmmRyzNhYSElIWEhJS19vF5kyIRERFpcAaBbj583v0angsiqgdnEIiIiEiDAYGIiKgTyszMtF60aJF7a/XPSwxERF1MSkBgi5Z7DkxNuenKPTf1HJn/PteuXeuSlJTksHDhwuza7RwdHUOLi4sPNrX/N99808PR0bFq1qxZeQCQn5+vmzlzpve7776b2dhnm1semjMIRETUIrpSuecbMWXKlIK6wsGNmDt37nlTOAAAV1fXqq1bt56sXdehLs0tD82A0Iibvb47EZElTOWeV65ceeqLL75wteQzpnLPy5cvz2hqueecnBxb4Fq55zfffLNmcaO33nrr7JEjR7olJSXZLVu2zK2ucs+33nprae1+4+PjXSdMmFAAAIMHDw4wGAz2pn0RERH+P/zwg+POnTsdQ0NDAwIDA/WhoaEBhw8f1hRpiouLc586dao3UF0lcujQoQHBwcGBs2fP7mN+viIjI/30en2gn5+f/qOPPqopxPTee++5+/n56f39/fX333+/LwA8++yzfV588UVPANizZ4/DkCFDAvz8/PRjxowZcP78eSvTGGfOnOkVEhIS6OPjE/zNN984mfo0lYdu6LzWxoBAREQ3rCuVewaqK1KuXbvWDai+9JCbm2szcuTI4iFDhpTu27cvNSUlJXnBggVn5s6d27ehfp988knvmJiY84mJiSm9evWq+bbv6OhYFR8fn56cnJyya9euYy+88EJfY5VK+7fffrv3rl27jqWlpSUvXbo0o3af06ZN8124cGHWsWPHkoOCgkrmzZtXEzwqKirk6NGjKW+88UbmK6+8UrO9OeWhGRCIiOiGbdiwwe2hhx7KB66VewbqL+vc3HLPnp6egxctWtTrD3/4Qy7QeuWep06dmr9582ZXAFi9erXr2LFj8wHg4sWLVr/+9a8HDBo0KGju3Ln9jh07Zl9fnwBw4MABp9jY2IsA8MQTT9RcIqiqqpI5c+b09fPz048aNcovNzfXNisry3rbtm3dx44dm9+7d+8KAPD09LyuClReXp5VYWGh1b333lsEALGxsXl79+6tmSn43e9+lw8At99++5WsrKyaSwrNKQ/NgEBERDekK5Z79vX1vdqjR4+Kn376yeHzzz93e+SRRy4CwLx587zuuuuuwuPHjydt2bIlvby8vNGx63Q6TRhaunSpW15envXRo0dTUlNTk93d3a+WlJTojMGm2UWS7O3tFVA9i1JZWVmTkJpTHpoBgYiIbkhXLPcMAA888MDFhQsX9iosLLSKiIgoAYDLly9b9e3btxwAli5d2rOxczNs2LCiDz74wA0APvjgg5pHEgsKCqx69ux51c7OTm3ZssX57NmztgAQFRV1efPmzW7Z2dlWAJCTk3PdDZvu7u6V3bt3rzTdX/Cvf/3LPTIysqixcTSnPDQfcyQi6mIsfSyxpXTFcs8A8PDDD+f/5S9/8Z49e3bNeObNm5cdExPjGxcX12vkyJHXPYpZl/fffz9j0qRJv3j//fc9x40bV3PzZUxMzMXo6OiBwcHBgUFBQcW+vr6lABAeHl763HPPnRs5cmSATqdTwcHBxbUfT1y5cuXPM2fO7P/000/rvL29yz755JPr9telOeWhWe65kXK2XaaULcs91+gsZX1bAs/FNV3lXLDcc+vpaOWeW0pj5aFZ7pmIiKgBHa3cc0tpbnnoLncirtNYIRqAxWiIiKhGRyr33FKaWx6aNykSEXV+VVVVVZY/00dkZPx7U+fTDQwIRESdX+L58+ddGBKoKaqqquT8+fMuABLr2t+1LzFQi2psaemOcjMa0c2moqIiJjs7e3l2dnYw+MWPLFcFILGioiKmrp0MCEREnVxYWFgugHHtPQ7qWpg0iYiISIMBgYiIiDQYEIiIiEiDAYGIiIg0LAoIIhIlImkiki4i8+tp86CIJItIkoh83LLDJCIiorbU6FMMImIFYDGAMQCyAOwXkc1KqWSzNoMA/BHACKVUvojc0loDpmbiqpJERNQElswgRABIV0qdVEqVA1gHYHytNrEAFiul8gFAKZXbssMkIiKitmRJQPACkGn2Psu4zZwfAD8R2S0ie0Ukqq6ORGS6iBhExHD+/PnmjZiIiIhanSUBoa6lO2vXiLYGMAjA3QAeArBcRHpoPqTUMqVUuFIq3MPDo6ljJSIiojZiSUDIAtDP7H1fALVrZWcB+FIpdVUp9TOANFQHBiIiIuqELAkI+wEMEhFfEbEFMAnA5lptNgEYBQAi0hPVlxxOtuRAiYiIqO00GhCUUhUAZgHYBiAFwAalVJKIvCIiprW/twHIE5FkADsB/EEplddagyYiIqLWZVGxJqXUVwC+qrXtRbPXCsCzxl9ERETUyXElRSIiItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINiwKCiESJSJqIpIvI/AbaPSAiSkTCW26IRERE1NYaDQgiYgVgMYBoAHoAD4mIvo52zgCeBvBTSw+SiIiI2pYlMwgRANKVUieVUuUA1gEYX0e7VwG8CaC0BcdHRERE7cCSgOAFINPsfZZxWw0RCQXQTym1taGORGS6iBhExHD+/PkmD5aIiIjahiUBQerYpmp2iugA/APAc411pJRappQKV0qFe3h4WD5KIiIialOWBIQsAP3M3vcFcNbsvTOAYAD/EZFTAIYD2MwbFYmIiDovSwLCfgCDRMRXRGwBTAKw2bRTKVWglOqplPJRSvkA2AtgnFLK0CojJiIiolbXaEBQSlUAmAXy7Ig9AAAKJElEQVRgG4AUABuUUkki8oqIjGvtARIREVHbs7akkVLqKwBf1dr2Yj1t777xYREREVF74kqKREREpMGAQERERBoMCERERKTBgEBEREQaDAhERESkwYBAREREGgwIREREpMGAQERERBoMCERERKTBgEBEREQaDAhERESkwYBAREREGgwIREREpMGAQERERBoMCERERKTBgEBEREQaDAhERESkwYBAREREGgwIREREpMGAQERERBoMCERERKTBgEBEREQaDAhERESkwYBAREREGgwIREREpMGAQERERBoMCERERKTBgEBEREQaDAhERESkwYBAREREGgwIREREpMGAQERERBoMCERERKTBgEBEREQaDAhERESkwYBAREREGgwIREREpGFRQBCRKBFJE5F0EZlfx/5nRSRZRI6IyLci0r/lh0pERERtpdGAICJWABYDiAagB/CQiOhrNTsIIFwpNRjARgBvtvRAiYiIqO1YMoMQASBdKXVSKVUOYB2A8eYNlFI7lVLFxrd7AfRt2WESERFRW7IkIHgByDR7n2XcVp/HAXx9I4MiIiKi9mVtQRupY5uqs6HIwwDCAdxVz/7pAKYDgLe3t4VDJCIiorZmyQxCFoB+Zu/7Ajhbu5GIjAbwJwDjlFJldXWklFqmlApXSoV7eHg0Z7xERETUBiwJCPsBDBIRXxGxBTAJwGbzBiISCmApqsNBbssPk4iIiNpSowFBKVUBYBaAbQBSAGxQSiWJyCsiMs7Y7C0ATgA+FZFDIrK5nu6IiIioE7DkHgQopb4C8FWtbS+avR7dwuMiIiKidsSVFImIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0GBCIiIhIgwGBiIiINBgQiIiISIMBgYiIiDQYEIiIiEiDAYGIiIg0LAoIIhIlImkiki4i8+vYbyci6437fxIRn5YeKBEREbWdRgOCiFgBWAwgGoAewEMioq/V7HEA+UqpgQD+AeCNlh4oERERtR1LZhAiAKQrpU4qpcoBrAMwvlab8QA+NL7eCOB/RERabphERETUlqwtaOMFINPsfRaA2+pro5SqEJECAO4ALpg3EpHpAKYb3xaJSFpzBm0pyxJKYk/UGqe52lMl2oN0jhzEc3FN46Ns+DwAPBfmeC6uaaNz0b8lOiFqjCUBoa6/0aoZbaCUWgZgmQXHbDMiYlBKhbf3ODoCnotqPA/X8Fxcw3NBNxtLLjFkAehn9r4vgLP1tRERawAuAC62xACJiIio7VkSEPYDGCQiviJiC2ASgM212mwG8Kjx9QMAvlNKaWYQiIiIqHNo9BKD8Z6CWQC2AbACsEIplSQirwAwKKU2A/gXgDUiko7qmYNJrTnoFtahLnm0M56LajwP1/BcXMNzQTcV4Rd9IiIiqo0rKRIREZEGAwIRERFpMCAQERGRBgMC3fREJEJEbjW+1ovIsyLy6/YeV0cgIqvbewxE1D4sWSiJuiARCUD1Cpg/KaWKzLZHKaW+ab+RtS0RWYDqOiPWIrID1auE/gfAfBEJVUq91p7ja0siUvvxZQEwSkR6AIBSalzbj6pjEJE7UL3sfKJSant7j4eoLfApBiMReUwptbK9x9EWRORpAL8HkAJgKIDZSqkvjfsOKKWGtef42pKIHEX1ObADkA2gr1Lqsog4oDo8DW7XAbYhETkAIBnAclSvhCoAPoHxsWWl1K72G13bEpF9SqkI4+tYVP97+QLAPQC2KKVeb8/xEbUFXmK45uX2HkAbigUQppS6H8DdAP4iIrON+zrHwvktp0IpVamUKgZwQil1GQCUUiUAqtp3aG0uHEACgD8BKFBK/QdAiVJq180UDoxszF5PBzBGKfUyqgPClPYZElHbuqkuMYjIkfp2AfBsy7G0MyvTZQWl1CkRuRvARhHpj5svIJSLiKMxIISZNoqIC26ygKCUqgLwDxH51PjfHNxk/48woxMRV1R/iRKl1HkAUEpdEZGK9h0aUdu42f7xewL4FYD8WtsFwJ62H067yRaRoUqpQwCglCoSkfsArAAQ0r5Da3N3KqXKgJofkCY2uLZ8+E1FKZUF4Hcici+Ay+09nnbigurZFAGgRKSXUipbRJxw84VoukndVPcgiMi/AKxUSv1Yx76PlVKT22FYbU5E+qJ6aj27jn0jlFK722FYRB2eiDgC8FRK/dzeYyFqbTdVQCAiIiLL8CZFIiIi0mBAIGojImIlIr8XEfv2HgsRUWMYEKjDEpFKETkkIoki8qnx+m9bHn9Oc48pIuEiEldr89sAUpRSpTc+OiKi1sV7EKjDEpEipZST8fVaAAlKqb9b+FkrpVTlDR7/FIBwpdSFG+mHiKgz4gwCdRY/ABgIACLysIjsM84uLBURK+P2IhF5RUR+AhApIqdEZKGI/FdEDCIyTES2icgJEZlh/MzdIrLVdBAReU9EphlXm+wDYKeI7DTuW2LsJ0lEXjb7zK0iskdEDhvH5Wzer4i4icgmETkiIntFZLBx+0siskJE/iMiJ43HJCLqEBgQqMMTEWtU10s4KiKBACYCGKGUGgqgEtdWtuuG6rXybzN7lDVTKRWJ6oCxCsADAIYDeKWhYyql4gCcBTBKKTXKuPlPSqlwAIMB3CUig0XEFsB6VC9XPQTAaAAltbp7GcBB47LNLwAwL4AUgOq1OSIALBARGxARdQA320JJ1Lk4iMgh4+sfAPwL1cvehgHYLyIA4AAg19imEsBntfowFSA6CsBJKVUIoFBESk1FiJrgQRGZjup/N70B6FFds+CcUmo/AJiWajaOzeQOABOM+78TEXfjSo0AEG9cqKlMRHJRvZhXVhPHRUTU4hgQqCMrMc4S1JDqn7wfKqX+WEf70jruOygz/rfK7LXpvTWAClw/k1bnEwYi4gvgeQC3KqXyRWSVsa2gOiQ0pK6V90yfMR9TJfhvkog6CF5ioM7mWwAPiMgtQM31/f430N9pAHoRsTN+q/8fs32FAJyNr7sDuAKgQEQ8UX3JAwBSAfQRkVuN43E2XhIx9z2Ml0GMdS8umGYaiIg6Kn5boU5FKZUsIn8GsF1EdACuoroU7+lm9pcpIhsAHAFwHMBBs93LAHwtIueUUqNE5CCAJAAnAew2fr5cRCYCWGQsEV2C6vsQzL0EYKWxWFgxbtIaD0TUufAxRyIiItLgJQYiIiLSYEAgIiIiDQYEIiIi0mBAICIiIg0GBCIiItJgQCAiIiINBgQiIiLS+H9lc3TFbBB/zAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "########################################################\n",
    "def get_scores(train_indexes, test_indexes, decision_tree_criterion=\"gini\", max_depth=3, metrics=[accuracy_score, roc_auc_score]):\n",
    "    X_train, X_test = X_dev_np[train_indexes], X_dev_np[test_indexes]\n",
    "    y_train, y_test = y_dev_np[train_indexes], y_dev_np[test_indexes]\n",
    "\n",
    "    iteration_classifier = tree.DecisionTreeClassifier(max_depth=max_depth, criterion=decision_tree_criterion)\n",
    "    iteration_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    metrics_scores = []\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric == accuracy_score:\n",
    "            y_test_prediction = iteration_classifier.predict(X_test)\n",
    "            metrics_scores.append(accuracy_score(y_test, y_test_prediction))\n",
    "\n",
    "            y_train_prediction = iteration_classifier.predict(X_train)\n",
    "            metrics_scores.append(accuracy_score(y_train, y_train_prediction))\n",
    "        elif metric == roc_auc_score:\n",
    "            #Devuelve un array con la probabilidad de la clase 0 y la clase 1.\n",
    "            #roc_auc_score pide solo la probobabilidad de la clase \"positiva\", asi que le paso el indice 1\n",
    "            y_test_proba_prediction = iteration_classifier.predict_proba(X_test)\n",
    "            metrics_scores.append(roc_auc_score(y_test, y_test_proba_prediction[:, 1]))\n",
    "\n",
    "            y_train_proba_prediction = iteration_classifier.predict_proba(X_train)\n",
    "            metrics_scores.append(roc_auc_score(y_train, y_train_proba_prediction[:, 1]))\n",
    "    \n",
    "    return metrics_scores\n",
    "    \n",
    "#    for metric in metrics:\n",
    "#        y_prediction = iteration_classifier.predict(X_test)\n",
    "#        metrics_scores.append(metric(y_test, y_prediction))\n",
    "        \n",
    "#        y_prediction = iteration_classifier.predict(X_train)\n",
    "#        metrics_scores.append(metric(y_train, y_prediction))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     accuracy_test = accuracy_score(y_test, y_prediction)\n",
    "#     auc_roc_test = roc_auc_score(y_test, y_prediction)\n",
    "\n",
    "#     y_prediction = iteration_classifier.predict(X_train)\n",
    "#     accuracy_train = accuracy_score(y_train, y_prediction)\n",
    "#     auc_roc_train = roc_auc_score(y_train, y_prediction)\n",
    "\n",
    "#    return metrics_scores\n",
    "\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "# Ejercicio 2.1\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=3)\n",
    "classifier = classifier.fit(X_dev_np, y_dev_np)\n",
    "\n",
    "#classifier.predict_proba([test])\n",
    "\n",
    "# Ejercicio 2.2\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X_dev_np):\n",
    "    [accuracy_test, accuracy_train, auc_roc_test, auc_roc_train] = get_scores(train_index, test_index)\n",
    "    \n",
    "    accuracies_validation.append(accuracy_test)\n",
    "    aucs_validation.append(auc_roc_test)\n",
    "    accuracies_training.append(accuracy_train)\n",
    "    aucs_training.append(auc_roc_train)\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = aucs_training\n",
    "df[\"AUC ROC (validación)\"] = aucs_validation\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>0.7133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.6521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.8772</td>\n",
       "      <td>0.7153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.6967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8744   \n",
       "1             5                            Gini                       0.9754   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.8772   \n",
       "4             5         Ganancia de Información                       0.9825   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.7133  \n",
       "1                         0.6521  \n",
       "2                         0.6382  \n",
       "3                         0.7153  \n",
       "4                         0.6967  \n",
       "5                         0.6873  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: resultados_training y resultados_validation asignadas\n",
    "#\n",
    "## Recomendamos seguir el siguiente esquema:\n",
    "np.random.seed(SEED)\n",
    "\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "    for altura in [3, 5, None]:\n",
    "        kf = KFold(n_splits=5)\n",
    "        auc_roc_test_list, auc_roc_train_list = [], []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_dev_np):\n",
    "            [auc_roc_test_fold, auc_roc_train_fold] = get_scores(train_index, test_index, decision_tree_criterion=criterio, max_depth = altura, metrics = [roc_auc_score])\n",
    "            \n",
    "            auc_roc_test_list.append(auc_roc_test_fold)\n",
    "            auc_roc_train_list.append(auc_roc_train_fold)\n",
    "        resultados_training.append( sum(auc_roc_train_list) / len(auc_roc_train_list) )\n",
    "        resultados_validation.append( sum(auc_roc_test_list) / len(auc_roc_test_list) )\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterio: gini, Altura: 3\n",
      "Probando fold: 1\n",
      "Atributo: 0\n",
      "Atributo: 1\n",
      "Atributo: 2\n",
      "Atributo: 3\n",
      "Atributo: 4\n",
      "Atributo: 5\n",
      "Atributo: 6\n",
      "Atributo: 7\n",
      "Atributo: 8\n",
      "Atributo: 9\n",
      "Atributo: 10\n",
      "Atributo: 11\n",
      "Atributo: 12\n",
      "Atributo: 13\n",
      "Atributo: 14\n",
      "Atributo: 15\n",
      "Atributo: 16\n",
      "Atributo: 17\n",
      "Atributo: 18\n",
      "Atributo: 19\n",
      "Atributo: 20\n",
      "Atributo: 21\n",
      "Atributo: 22\n",
      "Atributo: 23\n",
      "Atributo: 24\n",
      "Atributo: 25\n",
      "Atributo: 26\n",
      "Atributo: 27\n",
      "Atributo: 28\n",
      "Atributo: 29\n",
      "Atributo: 30\n",
      "Atributo: 31\n",
      "Atributo: 32\n",
      "Atributo: 33\n",
      "Atributo: 34\n",
      "Atributo: 35\n",
      "Atributo: 36\n",
      "Atributo: 37\n",
      "Atributo: 38\n",
      "Atributo: 39\n",
      "Atributo: 40\n",
      "Atributo: 41\n",
      "Atributo: 42\n",
      "Atributo: 43\n",
      "Atributo: 44\n",
      "Atributo: 45\n",
      "Atributo: 46\n",
      "Atributo: 47\n",
      "Atributo: 48\n",
      "Atributo: 49\n",
      "Atributo: 50\n",
      "Atributo: 51\n",
      "Atributo: 52\n",
      "Atributo: 53\n",
      "Atributo: 54\n",
      "Atributo: 55\n",
      "Atributo: 56\n",
      "Atributo: 57\n",
      "Atributo: 58\n",
      "Atributo: 59\n",
      "Atributo: 60\n",
      "Atributo: 61\n",
      "Atributo: 62\n",
      "Atributo: 63\n",
      "Atributo: 64\n",
      "Atributo: 65\n",
      "Atributo: 66\n",
      "Atributo: 67\n",
      "Atributo: 68\n",
      "Atributo: 69\n",
      "Atributo: 70\n",
      "Atributo: 71\n",
      "Atributo: 72\n",
      "Atributo: 73\n",
      "Atributo: 74\n",
      "Atributo: 75\n",
      "Atributo: 76\n",
      "Atributo: 77\n",
      "Atributo: 78\n",
      "Atributo: 79\n",
      "Atributo: 80\n",
      "Atributo: 81\n",
      "Atributo: 82\n",
      "Atributo: 83\n",
      "Atributo: 84\n",
      "Atributo: 85\n",
      "Atributo: 86\n",
      "Atributo: 87\n",
      "Atributo: 88\n",
      "Atributo: 89\n",
      "Atributo: 90\n",
      "Atributo: 91\n",
      "Atributo: 92\n",
      "Atributo: 93\n",
      "Atributo: 94\n",
      "Atributo: 95\n",
      "Atributo: 96\n",
      "Atributo: 97\n",
      "Atributo: 98\n",
      "Atributo: 99\n",
      "Atributo: 100\n",
      "Atributo: 101\n",
      "Atributo: 102\n",
      "Atributo: 103\n",
      "Atributo: 104\n",
      "Atributo: 105\n",
      "Atributo: 106\n",
      "Atributo: 107\n",
      "Atributo: 108\n",
      "Atributo: 109\n",
      "Atributo: 110\n",
      "Atributo: 111\n",
      "Atributo: 112\n",
      "Atributo: 113\n",
      "Atributo: 114\n",
      "Atributo: 115\n",
      "Atributo: 116\n",
      "Atributo: 117\n",
      "Atributo: 118\n",
      "Atributo: 119\n",
      "Atributo: 120\n",
      "Atributo: 121\n",
      "Atributo: 122\n",
      "Atributo: 123\n",
      "Atributo: 124\n",
      "Atributo: 125\n",
      "Atributo: 126\n",
      "Atributo: 127\n",
      "Atributo: 128\n",
      "Atributo: 129\n",
      "Atributo: 130\n",
      "Atributo: 131\n",
      "Atributo: 132\n",
      "Atributo: 133\n",
      "Atributo: 134\n",
      "Atributo: 135\n",
      "Atributo: 136\n",
      "Atributo: 137\n",
      "Atributo: 138\n",
      "Atributo: 139\n",
      "Atributo: 140\n",
      "Atributo: 141\n",
      "Atributo: 142\n",
      "Atributo: 143\n",
      "Atributo: 144\n",
      "Atributo: 145\n",
      "Atributo: 146\n",
      "Atributo: 147\n",
      "Atributo: 148\n",
      "Atributo: 149\n",
      "Atributo: 150\n",
      "Atributo: 151\n",
      "Atributo: 152\n",
      "Atributo: 153\n",
      "Atributo: 154\n",
      "Atributo: 155\n",
      "Atributo: 156\n",
      "Atributo: 157\n",
      "Atributo: 158\n",
      "Atributo: 159\n",
      "Atributo: 160\n",
      "Atributo: 161\n",
      "Atributo: 162\n",
      "Atributo: 163\n",
      "Atributo: 164\n",
      "Atributo: 165\n",
      "Atributo: 166\n",
      "Atributo: 167\n",
      "Atributo: 168\n",
      "Atributo: 169\n",
      "Atributo: 170\n",
      "Atributo: 171\n",
      "Atributo: 172\n",
      "Atributo: 173\n",
      "Atributo: 174\n",
      "Atributo: 175\n",
      "Atributo: 176\n",
      "Atributo: 177\n",
      "Atributo: 178\n",
      "Atributo: 179\n",
      "Atributo: 180\n",
      "Atributo: 181\n",
      "Atributo: 182\n",
      "Atributo: 183\n",
      "Atributo: 184\n",
      "Atributo: 185\n",
      "Atributo: 186\n",
      "Atributo: 187\n",
      "Atributo: 188\n",
      "Atributo: 189\n",
      "Atributo: 190\n",
      "Atributo: 191\n",
      "Atributo: 192\n",
      "Atributo: 193\n",
      "Atributo: 194\n",
      "Atributo: 195\n",
      "Atributo: 196\n",
      "Atributo: 197\n",
      "Atributo: 198\n",
      "Atributo: 199\n",
      "La mejor pregunta es ¿Es el valor para 122 menor o igual a 0.085797992426562?, con una ganancia de 0.09688185605626276\n",
      "Atributo: 0\n",
      "Atributo: 1\n",
      "Atributo: 2\n",
      "Atributo: 3\n",
      "Atributo: 4\n",
      "Atributo: 5\n",
      "Atributo: 6\n",
      "Atributo: 7\n",
      "Atributo: 8\n",
      "Atributo: 9\n",
      "Atributo: 10\n",
      "Atributo: 11\n",
      "Atributo: 12\n",
      "Atributo: 13\n",
      "Atributo: 14\n",
      "Atributo: 15\n",
      "Atributo: 16\n",
      "Atributo: 17\n",
      "Atributo: 18\n",
      "Atributo: 19\n",
      "Atributo: 20\n",
      "Atributo: 21\n",
      "Atributo: 22\n",
      "Atributo: 23\n",
      "Atributo: 24\n",
      "Atributo: 25\n",
      "Atributo: 26\n",
      "Atributo: 27\n",
      "Atributo: 28\n",
      "Atributo: 29\n",
      "Atributo: 30\n",
      "Atributo: 31\n",
      "Atributo: 32\n",
      "Atributo: 33\n",
      "Atributo: 34\n",
      "Atributo: 35\n",
      "Atributo: 36\n",
      "Atributo: 37\n",
      "Atributo: 38\n",
      "Atributo: 39\n",
      "Atributo: 40\n",
      "Atributo: 41\n",
      "Atributo: 42\n",
      "Atributo: 43\n",
      "Atributo: 44\n",
      "Atributo: 45\n",
      "Atributo: 46\n",
      "Atributo: 47\n",
      "Atributo: 48\n",
      "Atributo: 49\n",
      "Atributo: 50\n",
      "Atributo: 51\n",
      "Atributo: 52\n",
      "Atributo: 53\n",
      "Atributo: 54\n",
      "Atributo: 55\n",
      "Atributo: 56\n",
      "Atributo: 57\n",
      "Atributo: 58\n",
      "Atributo: 59\n",
      "Atributo: 60\n",
      "Atributo: 61\n",
      "Atributo: 62\n",
      "Atributo: 63\n",
      "Atributo: 64\n",
      "Atributo: 65\n",
      "Atributo: 66\n",
      "Atributo: 67\n",
      "Atributo: 68\n",
      "Atributo: 69\n",
      "Atributo: 70\n",
      "Atributo: 71\n",
      "Atributo: 72\n",
      "Atributo: 73\n",
      "Atributo: 74\n",
      "Atributo: 75\n",
      "Atributo: 76\n",
      "Atributo: 77\n",
      "Atributo: 78\n",
      "Atributo: 79\n",
      "Atributo: 80\n",
      "Atributo: 81\n",
      "Atributo: 82\n",
      "Atributo: 83\n",
      "Atributo: 84\n",
      "Atributo: 85\n",
      "Atributo: 86\n",
      "Atributo: 87\n",
      "Atributo: 88\n",
      "Atributo: 89\n",
      "Atributo: 90\n",
      "Atributo: 91\n",
      "Atributo: 92\n",
      "Atributo: 93\n",
      "Atributo: 94\n",
      "Atributo: 95\n",
      "Atributo: 96\n",
      "Atributo: 97\n",
      "Atributo: 98\n",
      "Atributo: 99\n",
      "Atributo: 100\n",
      "Atributo: 101\n",
      "Atributo: 102\n",
      "Atributo: 103\n",
      "Atributo: 104\n",
      "Atributo: 105\n",
      "Atributo: 106\n",
      "Atributo: 107\n",
      "Atributo: 108\n",
      "Atributo: 109\n",
      "Atributo: 110\n",
      "Atributo: 111\n",
      "Atributo: 112\n",
      "Atributo: 113\n",
      "Atributo: 114\n",
      "Atributo: 115\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1d2cae0e632b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Probando fold: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontador_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcontador_fold\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mauc_roc_test_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_roc_train_fold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dt_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_tree_criterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maltura\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mauc_roc_test_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_roc_test_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1d2cae0e632b>\u001b[0m in \u001b[0;36mget_dt_scores\u001b[0;34m(train_indexes, test_indexes, decision_tree_criterion, max_depth, metrics)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0miteration_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiClasificadorArbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0miteration_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision_tree_criterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mmetrics_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1d2cae0e632b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, max_depth, criterion)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruir_arbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumnas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0mimprimir_arbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1d2cae0e632b>\u001b[0m in \u001b[0;36mconstruir_arbol\u001b[0;34m(instancias, etiquetas, altura, criterio)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0maltura_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maltura\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0maltura\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Paso recursivo (consultar con el computador más cercano)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0msub_arbol_izquierdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruir_arbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstancias_cumplen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas_cumplen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltura_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0msub_arbol_derecho\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mconstruir_arbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstancias_no_cumplen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas_no_cumplen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maltura_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# los pasos anteriores crean todo lo que necesitemos de sub-árbol izquierdo y sub-árbol derecho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1d2cae0e632b>\u001b[0m in \u001b[0;36mconstruir_arbol\u001b[0;34m(instancias, etiquetas, altura, criterio)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mHoja\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metiquetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mganancia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpregunta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencontrar_mejor_atributo_y_corte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstancias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Criterio de corte: ¿Hay ganancia?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mganancia\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maltura\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maltura\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1d2cae0e632b>\u001b[0m in \u001b[0;36mencontrar_mejor_atributo_y_corte\u001b[0;34m(instancias, etiquetas, criterio)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mpregunta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPregunta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m#print('Pregunta: {}'.format(pregunta))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas_rama_izquierda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas_rama_derecha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartir_segun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpregunta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstancias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;31m#Ver como refactorizar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterio\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gini'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1d2cae0e632b>\u001b[0m in \u001b[0;36mpartir_segun\u001b[0;34m(pregunta, instancias, etiquetas)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# Esta función debe separar instancias y etiquetas según si cada instancia cumple o no con la pregunta (ver método 'cumple')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# COMPLETAR (recomendamos utilizar máscaras para este punto)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0minstancias_cumplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstancias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0minstancias_no_cumplen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstancias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;31m# GH10856\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# raise ValueError if only scalars in dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "#Ejercicio extra\n",
    "\n",
    "# Definición de la clase \"Pregunta\"\n",
    "class Pregunta:\n",
    "    def __init__(self, atributo, valor):\n",
    "        self.atributo = atributo\n",
    "        self.valor = valor\n",
    "    \n",
    "    def cumple(self, instancia):\n",
    "        return instancia[self.atributo] <= self.valor\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"¿Es el valor para {} menor o igual a {}?\".format(self.atributo, self.valor)\n",
    "\n",
    "# Definición de la estructura del árbol. \n",
    "\n",
    "class Hoja:\n",
    "    #  Contiene las cuentas para cada clase (en forma de diccionario)\n",
    "    #  Por ejemplo, {'Si': 2, 'No': 2}\n",
    "    def __init__(self, etiquetas):\n",
    "        self.cuentas = dict(Counter(etiquetas))\n",
    "\n",
    "\n",
    "class Nodo_De_Decision:\n",
    "    # Un Nodo de Decisión contiene preguntas y una referencia al sub-árbol izquierdo y al sub-árbol derecho\n",
    "    def __init__(self, pregunta, sub_arbol_izquierdo, sub_arbol_derecho):\n",
    "        self.pregunta = pregunta\n",
    "        self.sub_arbol_izquierdo = sub_arbol_izquierdo\n",
    "        self.sub_arbol_derecho = sub_arbol_derecho    \n",
    "\n",
    "def construir_arbol(instancias, etiquetas, altura, criterio):\n",
    "    # ALGORITMO RECURSIVO para construcción de un árbol de decisión binario. \n",
    "    # Suponemos que estamos parados en la raiz del árbol y tenemos que decidir cómo construirlo. \n",
    "    if rama_terminada(etiquetas):\n",
    "        return Hoja(etiquetas)\n",
    "    \n",
    "    ganancia, pregunta = encontrar_mejor_atributo_y_corte(instancias, etiquetas, criterio)\n",
    "    # Criterio de corte: ¿Hay ganancia?\n",
    "    if ganancia == 0 or (altura != None and altura == 0):\n",
    "        #  Si no hay ganancia en separar, o llegue a la altura requerida, corto la recursion. \n",
    "        return Hoja(etiquetas)\n",
    "    # Si hay ganancia en partir el conjunto en 2\n",
    "    instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen = partir_segun(pregunta, instancias, etiquetas)\n",
    "    # partir devuelve instancias y etiquetas que caen en cada rama (izquierda y derecha)\n",
    "\n",
    "    altura_rec = None if(altura == None) else altura - 1\n",
    "    # Paso recursivo (consultar con el computador más cercano)\n",
    "    sub_arbol_izquierdo = construir_arbol(instancias_cumplen, etiquetas_cumplen, altura_rec, criterio)\n",
    "    sub_arbol_derecho   = construir_arbol(instancias_no_cumplen, etiquetas_no_cumplen, altura_rec, criterio)\n",
    "    # los pasos anteriores crean todo lo que necesitemos de sub-árbol izquierdo y sub-árbol derecho\n",
    "\n",
    "    # sólo falta conectarlos con un nodo de decisión:\n",
    "    # Revisar esto!! no se construye bien\n",
    "    return Nodo_De_Decision(pregunta, sub_arbol_izquierdo, sub_arbol_derecho)\n",
    "\n",
    "def rama_terminada(etiquetas):\n",
    "    return len(etiquetas) <= 1 or len(set(etiquetas)) == 1\n",
    "    \n",
    "def encontrar_mejor_atributo_y_corte(instancias, etiquetas, criterio):\n",
    "    max_ganancia = 0\n",
    "    mejor_pregunta = None\n",
    "    for columna in instancias.columns:\n",
    "        #Generar valores borde\n",
    "        print(\"Atributo: {}\".format(columna))\n",
    "        bordes = generar_valores_borde(instancias, etiquetas, columna)\n",
    "        #print(\"Bordes {}\".format(bordes))\n",
    "        for valor in bordes:\n",
    "            # Probando corte para atributo y valor\n",
    "            pregunta = Pregunta(columna, valor)\n",
    "            #print('Pregunta: {}'.format(pregunta))\n",
    "            _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun(pregunta, instancias, etiquetas)\n",
    "            #Ver como refactorizar\n",
    "            if(criterio == 'gini'):\n",
    "                ganancia = ganancia_gini(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
    "            else:\n",
    "                ganancia = ganancia_entropia(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
    "            #print(\"La ganancia para la pregunta {}, es {}\".format(pregunta, ganancia))\n",
    "            if ganancia > max_ganancia:\n",
    "                max_ganancia = ganancia\n",
    "                mejor_pregunta = pregunta\n",
    "    print(\"La mejor pregunta es {}, con una ganancia de {}\".format(mejor_pregunta, max_ganancia))        \n",
    "    return max_ganancia, mejor_pregunta\n",
    "\n",
    "def generar_valores_borde(instancias, etiquetas, columna):\n",
    "    if len(instancias) <= 1:\n",
    "        return []\n",
    "    bordes = []\n",
    "    valores_y_etiquetas = pd.DataFrame(columns=[\"valor\", \"etiqueta\"])\n",
    "    valores_y_etiquetas[\"valor\"] = instancias.loc[:, columna]\n",
    "    valores_y_etiquetas[\"etiqueta\"] = etiquetas\n",
    "    valores_y_etiquetas.sort_values(\"valor\")            \n",
    "\n",
    "    anterior_etiqueta = valores_y_etiquetas.etiqueta.iloc[0]\n",
    "    anterior = valores_y_etiquetas.valor.iloc[0]\n",
    "    \n",
    "    for indice, fila in valores_y_etiquetas.iterrows():\n",
    "        actual = fila[\"valor\"]\n",
    "        actual_etiqueta = fila[\"etiqueta\"]\n",
    "        if actual_etiqueta != anterior_etiqueta:\n",
    "            bordes.append((anterior + actual)/2)\n",
    "        anterior = actual\n",
    "        anterior_etiqueta = actual_etiqueta\n",
    "    return bordes\n",
    "\n",
    "def partir_segun(pregunta, instancias, etiquetas):\n",
    "    # Esta función debe separar instancias y etiquetas según si cada instancia cumple o no con la pregunta (ver método 'cumple')\n",
    "    # COMPLETAR (recomendamos utilizar máscaras para este punto)\n",
    "    instancias_cumplen = pd.DataFrame(columns=instancias.columns)\n",
    "    instancias_no_cumplen = pd.DataFrame(columns=instancias.columns)\n",
    "     \n",
    "    columna_etiqueta = pd.DataFrame(data=etiquetas, index=instancias.index, columns=['etiqueta'])\n",
    "    instancias_con_etiqueta = pd.concat([instancias, columna_etiqueta], axis=1)\n",
    "    instancias_cumplen_etiqueta = instancias_con_etiqueta.where(pregunta.cumple(instancias_con_etiqueta)).dropna()\n",
    "    instancias_no_cumplen_etiqueta = instancias_con_etiqueta.mask(pregunta.cumple(instancias_con_etiqueta)).dropna()\n",
    "    etiquetas_cumplen = instancias_cumplen_etiqueta.loc[:,'etiqueta'].tolist()\n",
    "    etiquetas_no_cumplen = instancias_no_cumplen_etiqueta.loc[:,'etiqueta'].tolist()\n",
    "    \n",
    "    del instancias_cumplen_etiqueta['etiqueta']\n",
    "    del instancias_no_cumplen_etiqueta['etiqueta']\n",
    "    \n",
    "    instancias_cumplen = instancias_cumplen_etiqueta\n",
    "    instancias_no_cumplen = instancias_no_cumplen_etiqueta\n",
    "    \n",
    "    return instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen\n",
    "\n",
    "#Como hago para refactorizar esto?\n",
    "def gini(etiquetas):\n",
    "    diccionario = dict(Counter(etiquetas))\n",
    "    suma = 0\n",
    "    for etiqueta in diccionario.keys():\n",
    "        suma += (diccionario[etiqueta]/len(etiquetas))**2\n",
    "    impureza = 1 - suma\n",
    "    return impureza\n",
    "\n",
    "def ganancia_gini(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha):\n",
    "    etiquetas = np.concatenate((etiquetas_rama_izquierda, etiquetas_rama_derecha))\n",
    "    n_izq = len(etiquetas_rama_izquierda)\n",
    "    n_der = len(etiquetas_rama_derecha)\n",
    "    n = len(etiquetas)\n",
    "    \n",
    "    gini_total = gini(etiquetas)\n",
    "    gini_izq = gini(etiquetas_rama_izquierda)\n",
    "    gini_der = gini(etiquetas_rama_derecha)\n",
    "    \n",
    "    ganancia_gini = gini_total - ((n_izq/n)*gini_izq + (n_der/n)*gini_der)\n",
    "    \n",
    "    return ganancia_gini\n",
    "\n",
    "def entropia(etiquetas):\n",
    "    diccionario = dict(Counter(etiquetas))\n",
    "    entropia = 0\n",
    "    for etiqueta in diccionario.keys():\n",
    "        proporcion = diccionario[etiqueta]/len(etiquetas)\n",
    "        entropia += -proporcion*log(proporcion,2)\n",
    "    return entropia\n",
    "\n",
    "def ganancia_entropia(instancias, etiquetas_rama_izquierda, etiquetas_rama_derecha):\n",
    "    etiquetas = np.concatenate((etiquetas_rama_izquierda, etiquetas_rama_derecha))\n",
    "    n_izq = len(etiquetas_rama_izquierda)\n",
    "    n_der = len(etiquetas_rama_derecha)\n",
    "    n = len(etiquetas)\n",
    "    \n",
    "    entropia_total = entropia(etiquetas)\n",
    "    entropia_izq = entropia(etiquetas_rama_izquierda)\n",
    "    entropia_der = entropia(etiquetas_rama_derecha)\n",
    "    \n",
    "    ganancia_entropia = entropia_total - ((n_izq/n)*entropia_izq + (n_der/n)*entropia_der)\n",
    "    \n",
    "    return ganancia_gini\n",
    "\n",
    "def imprimir_arbol(arbol, spacing=\"\"):\n",
    "    if isinstance(arbol, Hoja):\n",
    "        print (spacing + \"Hoja:\", arbol.cuentas)\n",
    "        return\n",
    "\n",
    "    print (spacing + str(arbol.pregunta))\n",
    "\n",
    "    print (spacing + '--> True:')\n",
    "    imprimir_arbol(arbol.sub_arbol_izquierdo, spacing + \"  \")\n",
    "\n",
    "    print (spacing + '--> False:')\n",
    "    imprimir_arbol(arbol.sub_arbol_derecho, spacing + \"  \")\n",
    "\n",
    "\n",
    "def predecir(arbol, x_t):\n",
    "    if isinstance(arbol, Hoja):\n",
    "        return max(arbol.cuentas, key=arbol.cuentas.get)\n",
    "    \n",
    "    if(arbol.pregunta.cumple(x_t)):\n",
    "        return predecir(arbol.sub_arbol_izquierdo, x_t)\n",
    "    else:\n",
    "        return predecir(arbol.sub_arbol_derecho, x_t)\n",
    "\n",
    "def predecir_proba(arbol, x_t):\n",
    "    if isinstance(arbol, Hoja):\n",
    "        #Retorno la probabilidad de que la clase sea 'Si'\n",
    "        return arbol.cuentas[1]/(arbol.cuentas[1] + arbol.cuentas[0])\n",
    "    \n",
    "    if(arbol.pregunta.cumple(x_t)):\n",
    "        return predecir(arbol.sub_arbol_izquierdo, x_t)\n",
    "    else:\n",
    "        return predecir(arbol.sub_arbol_derecho, x_t)\n",
    "    \n",
    "class MiClasificadorArbol(): \n",
    "    def __init__(self, columnas=None):\n",
    "        self.arbol = None\n",
    "        self.columnas = columnas\n",
    "    \n",
    "    def fit(self, X_train, y_train, max_depth=None, criterion='gini'):\n",
    "        self.arbol = construir_arbol(pd.DataFrame(X_train, columns=self.columnas), y_train, max_depth, criterion)\n",
    "        imprimir_arbol(self.arbol)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for x_t in X_test:\n",
    "            x_t_df = pd.DataFrame([x_t], columns=self.columnas).iloc[0]\n",
    "            prediction = predecir(self.arbol, x_t_df) \n",
    "            #print(x_t, \"predicción ->\", prediction)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    #Revisar esto: el arbol no se construye bien\n",
    "    def predict_proba(self, X_test):\n",
    "        predictions = []\n",
    "        for x_t in X_test:\n",
    "            x_t_df = pd.DataFrame([x_t], columns=self.columnas).iloc[0]\n",
    "            prediction = predecir_proba(self.arbol, x_t_df) \n",
    "            #print(x_t, \"predicción ->\", prediction)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        \n",
    "        accuracy = sum(y_i == y_j for (y_i, y_j) in zip(y_pred, y_test)) / len(y_test)\n",
    "        return accuracy\n",
    "\n",
    "def get_dt_scores(train_indexes, test_indexes, decision_tree_criterion=\"gini\", max_depth=3, metrics=[roc_auc_score]):\n",
    "    X_train, X_test = X_dev_np[train_indexes], X_dev_np[test_indexes]\n",
    "    y_train, y_test = y_dev_np[train_indexes], y_dev_np[test_indexes]\n",
    "\n",
    "    iteration_classifier = MiClasificadorArbol()\n",
    "    iteration_classifier.fit(X_train, y_train, max_depth, decision_tree_criterion)\n",
    "    \n",
    "    metrics_scores = []\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric == accuracy_score:\n",
    "            y_test_prediction = iteration_classifier.predict(X_test)\n",
    "            metrics_scores.append(accuracy_score(y_test, y_test_prediction))\n",
    "\n",
    "            y_train_prediction = iteration_classifier.predict(X_train)\n",
    "            metrics_scores.append(accuracy_score(y_train, y_train_prediction))\n",
    "        elif metric == roc_auc_score:\n",
    "            #Nuestro predictor solamente devuelve la probabilidad de la clase positiva\n",
    "            y_test_proba_prediction = iteration_classifier.predict_proba(X_test)\n",
    "            metrics_scores.append(roc_auc_score(y_test, y_test_proba_prediction))\n",
    "\n",
    "            y_train_proba_prediction = iteration_classifier.predict_proba(X_train)\n",
    "            metrics_scores.append(roc_auc_score(y_train, y_train_proba_prediction))\n",
    "    \n",
    "    return metrics_scores\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: resultados_training y resultados_validation asignadas\n",
    "#\n",
    "## Recomendamos seguir el siguiente esquema:\n",
    "\n",
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "    for altura in [3, 5, None]:\n",
    "        kf = KFold(n_splits=5)\n",
    "        auc_roc_test_list, auc_roc_train_list = [], []\n",
    "        print(\"Criterio: {}, Altura: {}\".format(criterio, altura))\n",
    "        contador_fold = 1\n",
    "        for train_index, test_index in kf.split(X_dev_np):\n",
    "            print(\"Probando fold: {}\".format(contador_fold))\n",
    "            contador_fold+=1\n",
    "            [auc_roc_test_fold, auc_roc_train_fold] = get_dt_scores(train_index, test_index, decision_tree_criterion=criterio, max_depth = altura, metrics = [roc_auc_score])\n",
    "            \n",
    "            auc_roc_test_list.append(auc_roc_test_fold)\n",
    "            auc_roc_train_list.append(auc_roc_train_fold)\n",
    "        resultados_training.append( sum(auc_roc_train_list) / len(auc_roc_train_list) )\n",
    "        resultados_validation.append( sum(auc_roc_test_list) / len(auc_roc_test_list) )\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "   \n",
    "display(HTML(\"<h3> TABLA EJERCICIO EXTRA </h3>\"))\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def top_resultados(grid, method, top=25):\n",
    "    print(\"Top {} combinaciones para \".format(top) + method)\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    \n",
    "    # Este sorting score se considero una mejor opción comparado con buscar el mayor mean_score_validation\n",
    "    # porque de esta manera cobra algo de influencia la posibilidad de que el modelo elegido\n",
    "    # presente overfitting, dándole algo de peso a la cercanía entre su validation y training score\n",
    "    sorting_score = df['mean_score_validation'] - (df['mean_score_validation'] - df['mean_score_training'])**2\n",
    "    \n",
    "    df = df \\\n",
    "        .assign(sorting_score = sorting_score) \\\n",
    "        .sort_values('sorting_score', ascending=False) \\\n",
    "        .drop('sorting_score', axis=1)\n",
    "    \n",
    "    pd.options.display.max_rows = 50\n",
    "    display(df.head(top))\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: comparar y explorar distintas combinaciones de parámetros para los algoritmos importados arriba\n",
    "\n",
    "iteraciones = 50\n",
    "\n",
    "def doSearch(searchType, clasiffier, parameters):\n",
    "    if searchType == 'grid':\n",
    "        gridSearch = GridSearchCV(clasiffier, parameters, cv=5, scoring=make_scorer(roc_auc_score), return_train_score=True)\n",
    "        gridSearch.fit(X_dev_np, y_dev_np)\n",
    "        return gridSearch\n",
    "\n",
    "    if searchType == 'random':\n",
    "        randomSearch = RandomizedSearchCV(clasiffier, param_distributions=parameters, n_iter=iteraciones, cv=5, scoring=make_scorer(roc_auc_score), refit=True)\n",
    "        randomSearch.fit(X_dev_np, y_dev_np)\n",
    "        return randomSearch\n",
    "\n",
    "#searchs = [{'grid'},{'random'}]\n",
    "#lda_parameters_grid = [{'solver': ['lsqr'], 'shrinkage': [0, 1]}, {'solver': ['lsqr']},\n",
    "#                        {'solver': ['eigen'], 'shrinkage': [0, 1]}, {'solver': ['eigen']}]\n",
    "#shrinkage: solo esta disponible para lsqr y eigen. Por defecto: 'shrinkage':None \n",
    "#lda_parameters_random = {'solver': ['lsqr','eigen','svd'], 'shrinkage': [np.arange(0, 1, 0.000001)]}\n",
    "\n",
    "#lda_parameters_random = {'solver': ['lsqr'], 'shrinkage': np.arange(0, 1, 0.000001)}\n",
    "\n",
    "#tree_parameters_grid = [{'class_weight': ['balanced', None], 'max_features': [None, 100, 'auto'], 'max_depth':  np.arange(1, 50, 2),'criterion': ('gini','entropy') }]\n",
    "#tree_parameters_random = {'class_weight': ['balanced', None], 'max_features': [None, 100, 'auto'], 'max_depth': np.arange(1, 50, 2),'criterion': ('gini','entropy') }\n",
    "\n",
    "# tree_parameters_random = {'max_depth':np.append(np.arange(1, 41), None),'criterion': ('gini','entropy') }\n",
    "#knn_parameters_grid = {'n_neighbors': [1,2,3,5,10,20,30,40,100],'p': np.arange(1,3), \"weights\" : ['uniform', 'distance']}\n",
    "#knn_parameters_random = {'n_neighbors': np.arange(1, 101), 'p': np.arange(1,3), \"weights\" : ['uniform', 'distance']}\n",
    "#svm_parameters_grid = [{'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma': [1e-1, 1e-2,1e-3, 1e-4], 'C': [1, 10, 100]}, {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "#svm_parameters_random = {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':sp.stats.expon(scale=.1),'C': sp.stats.expon(scale=10)}\n",
    "\n",
    "#KNN\n",
    "#grid_KNN_result = doSearch('grid', KNeighborsClassifier(), knn_parameters_grid)\n",
    "#top_resultados(grid_KNN_result, \"KNN GridSearch\")\n",
    "#random_KNN_result =  doSearch('random', KNeighborsClassifier(), knn_parameters_random)\n",
    "#top_resultados(random_KNN_result, \"KNN RandomSearch\")\n",
    "\n",
    "#Arbol\n",
    "#grid_tree_result = doSearch('grid', DecisionTreeClassifier(), tree_parameters_grid)\n",
    "#top_resultados(grid_tree_result, \"Decision Tree GridSearch\")\n",
    "#random_tree_result = doSearch('random', DecisionTreeClassifier(), tree_parameters_random)\n",
    "#top_resultados(random_tree_result, \"Decision Tree RandomSearch\")\n",
    "\n",
    "#LDA\n",
    "#grid_LDA_result = doSearch('grid', LinearDiscriminantAnalysis(), lda_parameters_grid)\n",
    "#top_resultados(grid_LDA_result, \"LDA GridSearch\")\n",
    "#random_LDA_result = doSearch('random', LinearDiscriminantAnalysis(), lda_parameters_random)\n",
    "#top_resultados(random_LDA_result, \"LDA RandomSearch\")\n",
    "\n",
    "#Naive Bayes Gaussiana\n",
    "#grid_gauss_result = doSearch('grid', GaussianNB(), {})\n",
    "#top_resultados(grid_gauss_result, \"Naive Gauss GridSearch\")\n",
    "#iteraciones = 1\n",
    "#random_gauss_result = doSearch('random', GaussianNB(), {})\n",
    "#top_resultados(random_gauss_result, \"Naive Gauss RandomSearch\")\n",
    "\n",
    "#SVM\n",
    "#grid_SVM_result = doSearch('grid', SVC(), svm_parameters_grid)\n",
    "#top_resultados(grid_SVM_result, \"SVM GridSearch\")\n",
    "#random_SVM_result = doSearch('random', SVC(), svm_parameters_random)\n",
    "#top_resultados(random_SVM_result, \"SVM RandomSearch\")\n",
    "\n",
    "\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección de Parametros para KNN:\n",
    "\n",
    "GridSearch:\n",
    "- n: Cantidad de vecinos: elegimos un rango entre 3 y 150 vecinos. Decidimos un valor impar como inicial para evitar problemas de empate en la frontera. Elegir un rango tan amplio nos permite ver en más detalle la interacción de los distintos parámetros. #comentar despues diferencias entre cantidad de vecinos alta ponderados por su distancia.\n",
    "- weights: para predecir los valores utilizaremos uniform y distance para asignarle pesos a los vecinos.\n",
    "- p: forma de calcular la distancia, utilizaremos la distancia euclidiana y la manhattan\n",
    "\n",
    "RandomSearch:\n",
    "La diferencia es que utilizaremos un rango de vecindad entre 3 y 200 de forma aleatoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para KNN GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7590</td>\n",
       "      <td>0.7525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.7746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.7557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.7626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>0.7562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>0.7572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7394</td>\n",
       "      <td>0.7391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.7784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.7630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7336</td>\n",
       "      <td>0.7504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.7873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.8155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.7413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7162</td>\n",
       "      <td>0.7899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7213</td>\n",
       "      <td>0.8446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7062</td>\n",
       "      <td>0.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7508</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7486</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  p   weights  mean_score_validation  mean_score_training\n",
       "18           30  2   uniform                 0.7603               0.7742\n",
       "28          110  1   uniform                 0.7590               0.7525\n",
       "22           40  2   uniform                 0.7579               0.7746\n",
       "14           20  2   uniform                 0.7541               0.7792\n",
       "16           30  1   uniform                 0.7511               0.7740\n",
       "32          120  1   uniform                 0.7480               0.7557\n",
       "30          110  2   uniform                 0.7466               0.7626\n",
       "26          100  2   uniform                 0.7459               0.7562\n",
       "24          100  1   uniform                 0.7432               0.7572\n",
       "36          150  1   uniform                 0.7394               0.7391\n",
       "12           20  1   uniform                 0.7393               0.7784\n",
       "20           40  1   uniform                 0.7363               0.7630\n",
       "34          120  2   uniform                 0.7336               0.7504\n",
       "8            10  1   uniform                 0.7315               0.7873\n",
       "6             5  2   uniform                 0.7343               0.8155\n",
       "38          150  2   uniform                 0.7232               0.7413\n",
       "10           10  2   uniform                 0.7162               0.7899\n",
       "19           30  2  distance                 0.7631               1.0000\n",
       "2             3  2   uniform                 0.7213               0.8446\n",
       "23           40  2  distance                 0.7565               1.0000\n",
       "4             5  1   uniform                 0.7062               0.8265\n",
       "27          100  2  distance                 0.7514               1.0000\n",
       "29          110  1  distance                 0.7508               1.0000\n",
       "31          110  2  distance                 0.7500               1.0000\n",
       "17           30  1  distance                 0.7486               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 25 combinaciones para KNN RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7607</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>0.7655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.7712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>0.7856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.7606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.7612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.7603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.7688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>0.7573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>170</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>0.7588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.7390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.7345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>0.7414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.7793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>0.7405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7367</td>\n",
       "      <td>0.7475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7359</td>\n",
       "      <td>0.7413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7349</td>\n",
       "      <td>0.7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.7216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  p  weights  mean_score_validation  mean_score_training\n",
       "20           56  2  uniform                 0.7607               0.7660\n",
       "1            83  2  uniform                 0.7600               0.7652\n",
       "44           61  2  uniform                 0.7580               0.7655\n",
       "19           76  2  uniform                 0.7566               0.7712\n",
       "24           22  2  uniform                 0.7569               0.7856\n",
       "12           60  2  uniform                 0.7560               0.7606\n",
       "4            85  2  uniform                 0.7528               0.7612\n",
       "6            85  1  uniform                 0.7494               0.7603\n",
       "33           43  1  uniform                 0.7483               0.7633\n",
       "40           34  1  uniform                 0.7480               0.7688\n",
       "16          104  2  uniform                 0.7466               0.7613\n",
       "13          126  1  uniform                 0.7456               0.7514\n",
       "30          101  2  uniform                 0.7452               0.7573\n",
       "28          170  2  uniform                 0.7445               0.7373\n",
       "48           42  1  uniform                 0.7428               0.7588\n",
       "0            33  1  uniform                 0.7436               0.7789\n",
       "17          137  1  uniform                 0.7422               0.7390\n",
       "11          156  1  uniform                 0.7415               0.7345\n",
       "14          132  2  uniform                 0.7404               0.7414\n",
       "49           21  1  uniform                 0.7410               0.7793\n",
       "22          162  1  uniform                 0.7391               0.7405\n",
       "32          121  2  uniform                 0.7367               0.7475\n",
       "2           130  2  uniform                 0.7359               0.7413\n",
       "38          189  1  uniform                 0.7349               0.7217\n",
       "7           187  1  uniform                 0.7325               0.7216"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_parameters_grid = {'n_neighbors': [3,5,10,20,30,40,100,110,120,150],'p': np.arange(1,3), \"weights\" : ['uniform', 'distance']}\n",
    "knn_parameters_random = {'n_neighbors': np.arange(3, 201), 'p': np.arange(1,3), \"weights\" : ['uniform', 'distance']}\n",
    "\n",
    "\n",
    "grid_KNN_result = doSearch('grid', KNeighborsClassifier(), knn_parameters_grid)\n",
    "top_resultados(grid_KNN_result, \"KNN GridSearch\")\n",
    "\n",
    "random_KNN_result =  doSearch('random', KNeighborsClassifier(), knn_parameters_random)\n",
    "top_resultados(random_KNN_result, \"KNN RandomSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones de KNN\n",
    "\n",
    "En general pareciera que usar pesos uniformes ha tenido más éxito tanto para Grid Search como para Random Search.\n",
    "\n",
    "Ni en Grid Search ni en Random Search se nota algún tipo de valor n_neighbors que supere por mucho al resto, aunque a simple vista pareciera que los valores mayores o iguales a 20 tienen más éxito.\n",
    "\n",
    "Las distancias Manhattan y euclideanas (p = 1 y 2) parecen ser claramente mejores que el p = 3 para este dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección de Parametros para Tree:\n",
    "\n",
    "GridSearch:\n",
    "- criterion: utilizaremos gini y entropy para decidir los splits\n",
    "- splitter: evaularemos con los criterios de best y random\n",
    "- max_depth: la altura del arbol la iniciaremos en 3, aumentandolo hasta 50. No consideramos arboles de altura mayor ya que se corre el riesgo de caer en overfitting. El objetivo seria buscar uno no tan alto pero que generalice bien.\n",
    "- max_features: la cantidad de instancias que se consideraran en un split inicial en 10 se ira aumentando hasta 100 y en auto\n",
    "\n",
    "RandomSearch:\n",
    "La diferencia es que utilizaremos valores random en la altura de 5 hasta 50 y para el split se consideraran valores random entre 1 y 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para Decision Tree GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.7490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.7857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.7923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.7941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6956</td>\n",
       "      <td>0.7812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>0.7928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6920</td>\n",
       "      <td>0.7846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6885</td>\n",
       "      <td>0.7690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.7278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.7599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6806</td>\n",
       "      <td>0.7051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6816</td>\n",
       "      <td>0.7435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.7767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6798</td>\n",
       "      <td>0.7449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.7254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.7869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6729</td>\n",
       "      <td>0.6965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6758</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.7437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.8563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.8203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_weight criterion  max_depth max_features splitter  \\\n",
       "110     balanced   entropy          3         auto     best   \n",
       "296         None   entropy          3           40     best   \n",
       "200         None      gini          3           40     best   \n",
       "121     balanced   entropy          5           40   random   \n",
       "294         None   entropy          3           30     best   \n",
       "6       balanced      gini          3           30     best   \n",
       "8       balanced      gini          3           40     best   \n",
       "100     balanced   entropy          3           20     best   \n",
       "223         None      gini          5         auto   random   \n",
       "1       balanced      gini          3         None   random   \n",
       "103     balanced   entropy          3           30   random   \n",
       "201         None      gini          3           40   random   \n",
       "301         None   entropy          3          100   random   \n",
       "289         None   entropy          3         None   random   \n",
       "298         None   entropy          3           50     best   \n",
       "213         None      gini          5           20   random   \n",
       "299         None   entropy          3           50   random   \n",
       "313         None   entropy          5           40   random   \n",
       "3       balanced      gini          3           10   random   \n",
       "97      balanced   entropy          3         None   random   \n",
       "211         None      gini          5           10   random   \n",
       "123     balanced   entropy          5           50   random   \n",
       "206         None      gini          3         auto     best   \n",
       "308         None   entropy          5           20     best   \n",
       "12      balanced      gini          3          100     best   \n",
       "\n",
       "     mean_score_validation  mean_score_training  \n",
       "110                 0.6940               0.7490  \n",
       "296                 0.6982               0.7857  \n",
       "200                 0.6991               0.7923  \n",
       "121                 0.6979               0.7941  \n",
       "294                 0.6956               0.7812  \n",
       "6                   0.6959               0.7928  \n",
       "8                   0.6920               0.7846  \n",
       "100                 0.6885               0.7690  \n",
       "223                 0.6831               0.7278  \n",
       "1                   0.6856               0.7599  \n",
       "103                 0.6806               0.7051  \n",
       "201                 0.6787               0.7060  \n",
       "301                 0.6816               0.7435  \n",
       "289                 0.6803               0.7351  \n",
       "298                 0.6850               0.7767  \n",
       "213                 0.6798               0.7449  \n",
       "299                 0.6762               0.7254  \n",
       "313                 0.6839               0.7869  \n",
       "3                   0.6729               0.6965  \n",
       "97                  0.6764               0.7403  \n",
       "211                 0.6758               0.7403  \n",
       "123                 0.6840               0.7995  \n",
       "206                 0.6740               0.7437  \n",
       "308                 0.6945               0.8563  \n",
       "12                  0.6858               0.8203  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 25 combinaciones para Decision Tree RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>0.6644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6568</td>\n",
       "      <td>0.7931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.8772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>37</td>\n",
       "      <td>166</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7117</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.7076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>15</td>\n",
       "      <td>153</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7042</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.7791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.9244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>188</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6431</td>\n",
       "      <td>0.8498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>189</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.9475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>188</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>126</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6860</td>\n",
       "      <td>0.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6550</td>\n",
       "      <td>0.9151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>35</td>\n",
       "      <td>154</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6821</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>37</td>\n",
       "      <td>170</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6446</td>\n",
       "      <td>0.9013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>0.9376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>35</td>\n",
       "      <td>78</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6734</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>103</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6680</td>\n",
       "      <td>0.9868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>173</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6729</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>177</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6712</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_weight criterion  max_depth  max_features splitter  \\\n",
       "15     balanced   entropy          1            60   random   \n",
       "69     balanced   entropy          3           138     best   \n",
       "32         None      gini          5           194   random   \n",
       "70     balanced   entropy         37           166   random   \n",
       "46     balanced      gini          3            12   random   \n",
       "63     balanced   entropy         15           153   random   \n",
       "87         None      gini          7            12   random   \n",
       "27         None      gini          9            70   random   \n",
       "76     balanced      gini          5            63     best   \n",
       "68     balanced   entropy          5           188   random   \n",
       "18     balanced      gini          5           189     best   \n",
       "56         None   entropy         19           188     best   \n",
       "64         None      gini         15            45     best   \n",
       "35     balanced   entropy         11           126     best   \n",
       "86         None   entropy          5           127     best   \n",
       "53         None      gini         35           154     best   \n",
       "85     balanced   entropy         27            24     best   \n",
       "54         None   entropy         37           170     best   \n",
       "6      balanced   entropy          5            90     best   \n",
       "28         None      gini          5           116     best   \n",
       "4          None      gini         35            78     best   \n",
       "90     balanced   entropy         27            55   random   \n",
       "43     balanced   entropy         11           103   random   \n",
       "72         None   entropy         19           173   random   \n",
       "62         None   entropy         19           177   random   \n",
       "\n",
       "    mean_score_validation  mean_score_training  \n",
       "15                 0.6836               0.6644  \n",
       "69                 0.6568               0.7931  \n",
       "32                 0.6717               0.8772  \n",
       "70                 0.7117               1.0000  \n",
       "46                 0.6281               0.7076  \n",
       "63                 0.7042               1.0000  \n",
       "87                 0.6366               0.7791  \n",
       "27                 0.6954               0.9778  \n",
       "76                 0.6680               0.9244  \n",
       "68                 0.6431               0.8498  \n",
       "18                 0.6732               0.9475  \n",
       "56                 0.6901               1.0000  \n",
       "64                 0.6870               1.0000  \n",
       "35                 0.6860               0.9995  \n",
       "86                 0.6550               0.9151  \n",
       "53                 0.6854               1.0000  \n",
       "85                 0.6821               1.0000  \n",
       "54                 0.6815               1.0000  \n",
       "6                  0.6446               0.9013  \n",
       "28                 0.6534               0.9376  \n",
       "4                  0.6764               1.0000  \n",
       "90                 0.6734               1.0000  \n",
       "43                 0.6680               0.9868  \n",
       "72                 0.6729               1.0000  \n",
       "62                 0.6712               1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_parameters_grid = [{ 'class_weight': ['balanced', None], 'splitter': ['best', 'random'], 'max_features': [None, 10, 20, 30, 40, 50, 100, 'auto'], 'max_depth': [3, 5, 10, 15, 20, 50],'criterion': ('gini','entropy') }]\n",
    "tree_parameters_random = {'class_weight': ['balanced', None], 'splitter': ['best', 'random'], 'max_features': np.arange(10, 200, 1), 'max_depth': np.arange(1, 50, 2),'criterion': ('gini','entropy') }\n",
    "\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(), tree_parameters_grid, cv=5, scoring=make_scorer(roc_auc_score), return_train_score=True)\n",
    "gridSearch.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(gridSearch, \"Decision Tree GridSearch\")\n",
    "\n",
    "\n",
    "randomSearch = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=tree_parameters_random, n_iter=100, cv=5, scoring=make_scorer(roc_auc_score), refit=True)\n",
    "randomSearch.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(randomSearch, \"Decision Tree RandomSearch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones de Tree:\n",
    "\n",
    "Los mejores resultados obtenidos tanto en grid como en random search es para arboles de altura entre 3 y 5. Además encontramos que para arboles de profundidad mayor a 10, el árbol que se obtiene esta overfitteado, para cualquiera de los otros parametros. El splitter random da una mejor relación entre sesgo y varianza. Los criterios para decidir el slipt no mostraron influir demasiado en los resultados.\n",
    "\n",
    "Analizando los resultados obtenidos observamos que el factor que más influye es la profundidad del árbol.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección de Parametros para LDA:\n",
    "\n",
    "GridSearch:\n",
    "- solver: utilizaremos los criterios de descomposición en valores singulares'svd', cuadrados minimos 'lsqr' y autovectores 'eigen'\n",
    "- shrinkage: se combinará con lsqr y eigen con valores de 0.1, 0.5, 1 y none\n",
    "- n_components: es la cantidad de classes sobre las que se hará reducción de la dimensionalidad\n",
    "\n",
    "RandomSearch:\n",
    "Se agregarán intancias al azar para shrinkage y n_components\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para LDA GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components  shrinkage solver  mean_score_validation  mean_score_training\n",
       "15          10.0        0.5  eigen                 0.7730               0.9131\n",
       "21          20.0        0.5  eigen                 0.7730               0.9131\n",
       "3            1.0        0.5  eigen                 0.7730               0.9131\n",
       "27          50.0        0.5  eigen                 0.7730               0.9131\n",
       "33         100.0        0.5  eigen                 0.7730               0.9131\n",
       "39         150.0        0.5  eigen                 0.7730               0.9131\n",
       "9            5.0        0.5  eigen                 0.7730               0.9131\n",
       "32         100.0        0.5   lsqr                 0.7726               0.9142\n",
       "14          10.0        0.5   lsqr                 0.7726               0.9142\n",
       "20          20.0        0.5   lsqr                 0.7726               0.9142\n",
       "8            5.0        0.5   lsqr                 0.7726               0.9142\n",
       "26          50.0        0.5   lsqr                 0.7726               0.9142\n",
       "2            1.0        0.5   lsqr                 0.7726               0.9142\n",
       "38         150.0        0.5   lsqr                 0.7726               0.9142\n",
       "35         100.0        1.0  eigen                 0.7290               0.7549\n",
       "17          10.0        1.0  eigen                 0.7290               0.7549\n",
       "23          20.0        1.0  eigen                 0.7290               0.7549\n",
       "29          50.0        1.0  eigen                 0.7290               0.7549\n",
       "11           5.0        1.0  eigen                 0.7290               0.7549\n",
       "41         150.0        1.0  eigen                 0.7290               0.7549\n",
       "5            1.0        1.0  eigen                 0.7290               0.7549\n",
       "16          10.0        1.0   lsqr                 0.7290               0.7561\n",
       "40         150.0        1.0   lsqr                 0.7290               0.7561\n",
       "10           5.0        1.0   lsqr                 0.7290               0.7561\n",
       "34         100.0        1.0   lsqr                 0.7290               0.7561"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 25 combinaciones para LDA RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>27</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7723</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.8908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24</td>\n",
       "      <td>0.6235</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.8911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>49</td>\n",
       "      <td>0.6223</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.8914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46</td>\n",
       "      <td>0.6196</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.8916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>39</td>\n",
       "      <td>0.6863</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7713</td>\n",
       "      <td>0.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10</td>\n",
       "      <td>0.6820</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7713</td>\n",
       "      <td>0.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.5964</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.8976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10</td>\n",
       "      <td>0.7895</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>0.8582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10</td>\n",
       "      <td>0.7830</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>0.8597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>38</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.8838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7058</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>0.8747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5508</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.9049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5536</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.9049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.8518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.8879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>0.4745</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.9065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>41</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>0.8547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7561</td>\n",
       "      <td>0.8221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7575</td>\n",
       "      <td>0.8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>47</td>\n",
       "      <td>0.8778</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>0.8269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>0.8293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components  shrinkage solver  mean_score_validation  mean_score_training\n",
       "45            27     0.7495  eigen                 0.7723               0.8660\n",
       "29            27     0.6237  eigen                 0.7737               0.8908\n",
       "15            24     0.6235   lsqr                 0.7737               0.8911\n",
       "41            49     0.6223  eigen                 0.7737               0.8914\n",
       "20            46     0.6196   lsqr                 0.7737               0.8916\n",
       "14            25     0.5837  eigen                 0.7751               0.9000\n",
       "42            39     0.6863   lsqr                 0.7713               0.8800\n",
       "46            10     0.6820   lsqr                 0.7713               0.8800\n",
       "2             38     0.5964  eigen                 0.7733               0.8966\n",
       "4              2     0.5910   lsqr                 0.7730               0.8976\n",
       "44            10     0.7895  eigen                 0.7655               0.8582\n",
       "26            10     0.7830  eigen                 0.7655               0.8597\n",
       "25            38     0.6532  eigen                 0.7692               0.8838\n",
       "33             2     0.7058  eigen                 0.7672               0.8747\n",
       "13            15     0.5508  eigen                 0.7727               0.9049\n",
       "35            20     0.5536  eigen                 0.7727               0.9049\n",
       "11             5     0.8100  eigen                 0.7630               0.8518\n",
       "6             27     0.6435   lsqr                 0.7692               0.8879\n",
       "34            33     0.4745   lsqr                 0.7726               0.9154\n",
       "1             20     0.5457  eigen                 0.7706               0.9065\n",
       "32            41     0.8052   lsqr                 0.7606               0.8547\n",
       "3             45     0.8867   lsqr                 0.7561               0.8221\n",
       "5             17     0.8401   lsqr                 0.7575               0.8414\n",
       "28            47     0.8778   lsqr                 0.7516               0.8269\n",
       "38            10     0.8641  eigen                 0.7517               0.8293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_parameters_grid = [{'solver': ['lsqr', 'eigen'], 'shrinkage': [0, 0.5, 1], 'n_components': [1, 5, 10, 20, 50, 100, 150]}, {'solver': ['lsqr']},\n",
    "                       {'solver': ['eigen']}]\n",
    "\n",
    "lda_parameters_random = {'solver': ['lsqr', 'eigen'], 'shrinkage': np.arange(0, 1, 0.000001), 'n_components': np.arange(1, 50, 1)}\n",
    "\n",
    "\n",
    "grid_LDA_result = doSearch('grid', LinearDiscriminantAnalysis(), lda_parameters_grid)\n",
    "top_resultados(grid_LDA_result, \"LDA GridSearch\")\n",
    "\n",
    "\n",
    "random_LDA_result = doSearch('random', LinearDiscriminantAnalysis(), lda_parameters_random)\n",
    "top_resultados(random_LDA_result, \"LDA RandomSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluciones de LDA:\n",
    "\n",
    "Los resultados que se presentan como los mejores resultados en la grid search, alcanzan valores de casi overfitting en los datos de entrenamiento y tienen una gran diferencia con los resultados obtenidos en validación, por lo que ampliando la busqueda en los resultados, puede verse que los solver de eigen y lsqr, coincidiendo con los mejores resultados de la busqueda random. Los valores de shrinkage que mejor resultado dieron son para > 0.7 Para este dataset aplicar la reduccion de n_components no dió grandes mejorías.\n",
    "\n",
    "En conclusión los parametros que mejor resultado dieron, manteniendo una adecuada relación de sesgo vs varianza son eigen y lsqr con valores de shrinkage > 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para Naive Gauss GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7286</td>\n",
       "      <td>0.7732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_score_validation  mean_score_training\n",
       "0                 0.7286               0.7732"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_gauss_result = doSearch('grid', GaussianNB(), {})\n",
    "top_resultados(grid_gauss_result, \"Naive Gauss GridSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones de Naive Bayes:\n",
    "Los resultados obtenidos para Naive Bayes son relativamente buenos, esto nos da una intuición de cuánta dependencia existe entre los atributos (dado que naive bayes asume una independencia total entre los atributos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección de Parametros para SVM:\n",
    "\n",
    "GridSearch:\n",
    "- C: es el parametro de penalización a los errores se probaremos con 0.1 daremos poca tolerancia al error a fin de que encuentre un mejor hiperplano, 1.0 es el valor por deafult y 1000 para dejar poca tolerancia a los errores\n",
    "- kernel : probaremos con ‘linear’, ‘poly’, ‘rbf’ y ‘sigmoid’\n",
    "- gamma: se usará en auto\n",
    "- degree: para 'poly' se tomará de grado 3\n",
    "\n",
    "RandomSearch:\n",
    "Se generan modelos con una cobertura más alta y más detallada de gammas y C, pero se mantiene el resto de los hiperparámetros parecidos a los de grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para SVM GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7731</td>\n",
       "      <td>0.6847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>0.7866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.8379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.7505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.8807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.7433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7171</td>\n",
       "      <td>0.6998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.9958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.6156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.5947</td>\n",
       "      <td>0.6233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C   gamma   kernel  mean_score_validation  mean_score_training\n",
       "2      0.1  0.1000  sigmoid                 0.7731               0.6847\n",
       "5      0.1  0.0100  sigmoid                 0.7531               0.7866\n",
       "20     1.0  0.0010  sigmoid                 0.7576               0.8379\n",
       "17     1.0  0.0100  sigmoid                 0.7455               0.7505\n",
       "18     1.0  0.0010      rbf                 0.7596               0.8807\n",
       "21     1.0  0.0001      rbf                 0.7326               0.7433\n",
       "29  1000.0  0.0100  sigmoid                 0.7171               0.6998\n",
       "27  1000.0  0.0100      rbf                 0.7696               1.0000\n",
       "15     1.0  0.0100      rbf                 0.7555               0.9958\n",
       "26  1000.0  0.1000  sigmoid                 0.6841               0.6156\n",
       "14     1.0  0.1000  sigmoid                 0.6841               0.6129\n",
       "30  1000.0  0.0010      rbf                 0.7404               1.0000\n",
       "16     1.0  0.0100     poly                 0.7322               1.0000\n",
       "25  1000.0  0.1000     poly                 0.7322               1.0000\n",
       "31  1000.0  0.0010     poly                 0.7322               1.0000\n",
       "1      0.1  0.1000     poly                 0.7322               1.0000\n",
       "28  1000.0  0.0100     poly                 0.7322               1.0000\n",
       "13     1.0  0.1000     poly                 0.7322               1.0000\n",
       "35  1000.0  0.0001  sigmoid                 0.7201               0.9900\n",
       "36     0.1     NaN   linear                 0.7201               0.9900\n",
       "37     1.0     NaN   linear                 0.7128               1.0000\n",
       "38  1000.0     NaN   linear                 0.7128               1.0000\n",
       "32  1000.0  0.0010  sigmoid                 0.7124               1.0000\n",
       "33  1000.0  0.0001      rbf                 0.7090               1.0000\n",
       "6      0.1  0.0010      rbf                 0.5947               0.6233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 25 combinaciones para SVM RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>331.97</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.6815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>280.35</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7354</td>\n",
       "      <td>0.6747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>510.40</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>0.7460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22.27</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>0.6673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>596.04</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>608.25</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.6364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>958.29</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>844.62</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>0.6441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>722.72</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.6308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>698.42</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.8420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>92.94</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6934</td>\n",
       "      <td>0.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>589.10</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>0.6306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>903.27</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>945.04</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>0.6447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>891.26</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7098</td>\n",
       "      <td>0.8858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>696.76</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6741</td>\n",
       "      <td>0.6267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>917.37</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.6227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.87</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.6239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>963.45</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>717.20</td>\n",
       "      <td>0.4886</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>791.49</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>606.49</td>\n",
       "      <td>0.0773</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>412.22</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>363.28</td>\n",
       "      <td>0.3625</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>595.59</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C   gamma   kernel  mean_score_validation  mean_score_training\n",
       "42  331.97  0.0124  sigmoid                 0.7426               0.6815\n",
       "5   280.35  0.0183  sigmoid                 0.7354               0.6747\n",
       "34  510.40  0.0072  sigmoid                 0.7252               0.7460\n",
       "17   22.27  0.0209  sigmoid                 0.7180               0.6673\n",
       "2   596.04  0.0127      rbf                 0.7634               1.0000\n",
       "43  608.25  0.0355  sigmoid                 0.7107               0.6364\n",
       "33  958.29  0.0044      rbf                 0.7600               1.0000\n",
       "13  844.62  0.0374  sigmoid                 0.7044               0.6441\n",
       "0   722.72  0.0864  sigmoid                 0.7043               0.6308\n",
       "44  698.42  0.0044  sigmoid                 0.7140               0.8420\n",
       "29   92.94  0.0775  sigmoid                 0.6934               0.6267\n",
       "19  589.10  0.0744  sigmoid                 0.6907               0.6306\n",
       "25  903.27  0.0784  sigmoid                 0.6889               0.6267\n",
       "35  945.04  0.0367  sigmoid                 0.6848               0.6447\n",
       "32  891.26  0.0038  sigmoid                 0.7098               0.8858\n",
       "28  696.76  0.0940  sigmoid                 0.6741               0.6267\n",
       "9   917.37  0.1344  sigmoid                 0.6744               0.6227\n",
       "7    25.87  0.0940  sigmoid                 0.6665               0.6239\n",
       "38  963.45  0.0828     poly                 0.7322               1.0000\n",
       "8   717.20  0.4886     poly                 0.7322               1.0000\n",
       "36  791.49  0.0448     poly                 0.7322               1.0000\n",
       "37  606.49  0.0773     poly                 0.7322               1.0000\n",
       "31  412.22  0.0924     poly                 0.7322               1.0000\n",
       "41  363.28  0.3625     poly                 0.7322               1.0000\n",
       "6   595.59  0.2027     poly                 0.7322               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_parameters_grid = [{'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma': [1e-1, 1e-2,1e-3, 1e-4], 'C': [0.1, 1, 1000]}, {'kernel': ['linear'], 'C': [0.1, 1, 1000]}]\n",
    "svm_parameters_random = {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':sp.stats.expon(scale=.1),'C': np.arange(0.1, 1000, 0.01)}\n",
    "\n",
    "\n",
    "grid_SVM_result = doSearch('grid', SVC(), svm_parameters_grid)\n",
    "top_resultados(grid_SVM_result, \"SVM GridSearch\")\n",
    "\n",
    "random_SVM_result = doSearch('random', SVC(), svm_parameters_random)\n",
    "top_resultados(random_SVM_result, \"SVM RandomSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones de SVM:\n",
    "\n",
    "Observando los resultados vemos que tomando un kernel sigmoide se obtienen buenos resultados con una"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ESTO DE ACA ABAJO YA NO VA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Conclusiones Grid Search\n",
    "\n",
    "##### KNN \n",
    "    Se buscó probar variando la forma en que se determinan los pesos de los vecinos mas cercanos, para determinar cuál es más performante, uniform parece superar ampliamente a distance en este caso, aparte se testeó con varios números de vecinos más cercanos, y por lo que se ve los mejores resultados se dan cuando se tiene un número de vecinos más cercanos relativamente grande (los buenos resultados se obtienen combinando uniform con numeros grandes de vecinos, entre 20 - 100)\n",
    "    En cuanto al parametro p, que define la fórmula de distancia a utilizar, no encontramos diferencias significativas entre la distancia manhattan y la euclidiana.\n",
    "    \n",
    "    El GridSearch parece presentar mejores resultados, aunque extrañamente el training score supera en muchos casos al validation.\n",
    "    \n",
    "    \n",
    "##### Árboles de Decisión \n",
    "\n",
    "    Se decidió hacer un intento de testear asignar pesos balanceados las clases testeadas (class_weight=\"balanced\"), si bien no pareció influir mucho en el resultado final. Sin embargo se podría suponer que el uso de este parámetro tiene una influencia significativa si se tiene un conocimiento más en profundidad acerca de los atributos analizados y su influencia en el resultado final (maldad o no).\n",
    "\n",
    "    Se decidió probar variar los max_features para decidir si con esto se podría volver más manejable la posibilidad de overfitting en los árboles más altos, sin embargo no se notó ninguna diferencia significativa, ya que parece que max_features parece mantenerse como el superior.\n",
    "\n",
    "    Los árboles con alturas más bajas parecen tener mejores resultados, mientras que los de mayor altura presentan un overfitting cada vez más pronunciado\n",
    "    \n",
    "    Usar GridSearch no provee mejoras significativas en los casos observados.\n",
    "\n",
    "##### LDA \n",
    "    \n",
    "    Los solvers, sin embargo, no parecen afectar en este caso\n",
    "\n",
    "    LDA presenta una mejora significativa cuando se cuenta con shrinkage = 1.0\n",
    "\n",
    "##### Naive Bayes\n",
    "    Si bien Naive-Bayes no ofrece uno de los mejores resultados y no es capaz de detectar ni incorporar ninguna dependencia entre atributos a sus predicciones, se puede ver que es preferible respecto a los árboles de decisión (por ejemplo), dado que no sólo predice mejor al conjunto de testeo, si no que es un algoritmo altamente escalable con una implementación simple. Se lo podría utilizar como una heurística para explorar el conjunto de entrenamiento. Si los atributos son muy dependientes entre sí, en teoría el modelo no debería ser bueno prediciendo.\n",
    "##### SVM \n",
    "\n",
    "    Para SVM variamos los hiperparámetros kernel, gamma y C.\n",
    "    En primer lugar podemos ver que el kernel polinomial genera una curva que se ajusta demasiado a las instancias de entrenamiento, perdiendo frente a los otros dos tipos de kernel.\n",
    "    Por otra parte podemos ver que aumentar C hasta cierto punto suele verse acompañado de una mejora en la validación. Un C demasiado grande únicamente logra ajustar de más a los datos de entrenamiento. Pareciera ser que un C entre 10 y 100 sería el ideal.\n",
    "    Un valor de gamma bajo genera más estabilidad en la frontera de divisón, dado que más puntos se toman en cuenta para calcularla. Para los gammas testeados, parecería ser que el 0.001 es el mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAFjCAYAAACE1xI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4FWXax/Hvk0IghFBDDy0kIYUmCCJIEZUOrggIAtYVZNX1VdZeUUTXVdcuNlRQWLBgAQtSVQSlBVIIHQIkEEoSQgKkPO8fc4IxJJSYw4Hw+1zXuU6ZZ2buKSc59zxljLUWERERERERKV+8PB2AiIiIiIiIlD0leyIiIiIiIuWQkj0REREREZFySMmeiIiIiIhIOaRkT0REREREpBxSsiciIiIiIlIO+Xg6ABERERGR8mblypW1fXx83gWiUQWLlE4+EJubm3tru3bt9pZmAUr2RERERETKmI+Pz7t169aNCAoKOujl5aUbW8sZy8/PN6mpqZEpKSnvAgNLswxdZRARERERKXvRQUFBGUr0pLS8vLxsUFBQOk7tcOmWUYbxiIiIiIiIw0uJnvxVrnOo1Dmbkj0RERERkXImJSXFu0WLFpEtWrSIrFWrVuvatWu3Knh/5MgRczrLuPbaa5vExMT4nazMpEmTgt58880aZRO1lDVjrS44iIiIiIiUpZiYmG2tW7fe5+k4AO655576AQEBeRMmTNhT+PP8/HystXh7e3sqNLcpT9sWExNTq3Xr1k1KM69q9kRERERELhCxsbF+oaGhUSNGjGgUFRUVuWPHDt/hw4c3jo6OjmjevHnU+PHj6xWUbdeuXfjSpUsr5eTkUKVKlTbjxo1rEB4eHtmmTZsWu3bt8gG466676k+YMKF2Qflx48Y1aNmyZUSTJk2i582bVxkgIyPDq1evXiHh4eGRAwYMaBodHR2xdOnSSkVjGzNmTMOQkJCosLCwyNtvv70BwI4dO3x69uwZEhYWFhkeHh65YMGCygCPPPJIndDQ0KjQ0NCoiRMn1i5p22bOnBnYpk2bFpGRkRH9+vVrlpGRcUHlPxfUxoqIiIiIXOg2b95cccyYMfsSEhLimzZtmvPf//53Z2xsbEJCQkLcwoULA1euXFmx6DyZmZne3bt3P5SYmBjfvn37zNdff71Wccu21rJu3bqEiRMnJk2YMKE+wLPPPlu7du3aOYmJifEPPfRQSkJCgn/R+ZKSknzmz59fdePGjXEbNmyIf+qpp1IA/v73vzfu2bNnxoYNG+JjY2Pj27Rpk71w4UL/WbNm1Vy1alXCb7/9lvDee+8FLV++vFLRbatQoYJ9/vnn6/30008b4uPjE6Kjo7OeeeaZ2mW7N89tuvWCiIiIiIg7fX9zMPtiT0hw/pJa0Vn0ej+pNLMGBwcf7datW1bB+/fff7/G1KlTa+Xm5prU1FTftWvXVmrXrt2RwvNUrFgxf+jQoRkA7dq1y/rpp58Cilv2kCFD0gAuvfTSrEceeaQCwK+//hpw//33pwB06tQpOyQkJLvofLVr187z8vKyw4cPb9yvX7/0YcOGpQMsX768yldffbUFwNfXlxo1auQvWrSoyoABAw5WqVIlH6BPnz5pCxcuDOjfv39G4W1bsGBBwKZNmypefPHFLQBycnJMhw4dMkuzz85XSvZERERERC4glSpVyi94vW7dOr/JkyfXWbFiRUKtWrXyBg0a1DQ7O/uEAVx8fHyOD/Th7e1t8/Lyih3kpWLFivlFy5zOGCF+fn42JiYmYfbs2YEzZsyoMXny5KBffvllIxwfkfK4ky2v8LZZa+nWrVvG7Nmzt54ygHJKyZ6IiIiIiDuVsgbubEhLS/OuXLlyXvXq1fO2b9/uu2TJksBevXqll+U6OnXqlDl9+vTqvXv3zvztt98qbdmy5YT+egcPHvTKzs72Gj58eHq3bt0OR0VFRQFccsklGc8//3zQQw89lJqbm0tGRoZXjx49Do0bN67JE088kZKXl2e+++67atOnT99SdJk9evTIvP/++4Pj4+MrREZGHsvIyPDavn27b8uWLY+W5fady5TsiYiIiIhcoDp37pwVGhp6JCwsLKpRo0ZH27VrV+bNHB944IG9Q4YMaRoWFhbZsmXLrObNm2fXqFEjr3CZAwcOeF999dXNjx07Zqy1PP3000kAb7/99o4bb7yxyQcffBDk7e3NG2+8sa1Hjx5ZgwcP3t+2bdtIgJtvvjm1Q4cO2bGxsX+6TURwcHDuG2+8sX3o0KEhOTk5BuDJJ5/cdSEle7r1goiIiIhIGTuXbr3gaTk5OeTk5Bh/f3+7bt06v969e4dt27Ztna+vr6dDOy/8lVsvqGZPRERERETcJj093btbt25hubm5xlrLq6++ul2J3tmhZE9ERERERNymVq1aeXFxcQmejuNCpPvsiYiIiIiIlENK9kRERERERMohJXsiIiIiIiLlkJI9ERERERGRckjJnoiIiIhIObRjxw6f/v37NwsODo4OCQmJ6tatW/O1a9f6nXrOs69BgwYtk5OTfQDatm3borgygwcPbjJlypTqJ1vOK6+8UnPbtm3Hh/ocNmxY45UrV1Ys22jPH0r2RERERETKmfz8fAYOHNi8a9euh5KSkmI3b94cN2nSpF27d+/+0z0PcnNzPRViiVavXr2+tPNOmzat1o4dO45v4//+97/t7dq1O1I2kZWdnJycs7IeJXsiIiIiIuXMN998U8XHx8fed999qQWfXXrppdm9e/fO/Oabb6p07NgxbMCAAU3Dw8OjAJ544ok6oaGhUaGhoVETJkyoDZCRkeHVvXv35uHh4ZGhoaFR77zzTnWAcePGNQgJCYkKCwuLvO222xoWXfdzzz0XNHbs2OOfv/LKKzVvuOGGYIArrrgiJCoqKqJ58+ZR//nPf2oVF7u/v39bcBLW0aNHNwoJCYnq3r1783379h2/bdz48ePrRUdHR4SGhkYNHz68cX5+PlOmTKkeGxvrP3r06GYtWrSIzMzMNB06dAhfsmSJP8DkyZNrhIWFRYaGhkbdfvvtDQqv784772wQHh4e2bp16xZJSUkn3J5uzpw5AS1atIhs0aJFZEREROTBgwe9AB555JE6YWFhkeHh4ZHjxo1rALB06dJKrVu3bhEWFhZ55ZVXhqSmpnoDdOjQIfyOO+5ocPHFF4c//fTTdXbv3u3Tq1evkOjo6Ijo6OiIH374ofLpH+HTo2RPROQcYYxpYoyxxpjz+h6oxpgnjDHTTrPst8aYG1yvrzfG/HCSsouMMbeWMqYPjDFPl2ZeTzLGbDPGXFHKea0xpnlZx1RkHaU+Jue6wvvPGPOWMebRv7i8h4wx75ZNdCKntnbt2kqtW7fOOsn0ys8///yuzZs3x/3000/+n3zySc2VK1cmrFixIuGjjz4K+uWXXyp9/vnngXXr1s1JTEyM37hxY9w111yTsWfPHu+5c+dW37hxY9yGDRvin3nmmeSiyx41atTBuXPnVit4/+mnn9YYMWLEQYCPP/54W1xcXMKaNWviJ0+eXCclJcW7pBinTp1abdOmTX6JiYlxH3zwwfZVq1YFFEz717/+tTc2NjZh48aNcdnZ2V4zZsyoetNNNx2Mjo7O+uijj7asX78+PiAgwBaU37Ztm+8TTzzRYNGiRRvi4+PjVq9eXXnq1KnVALKzs706deqUmZiYGN+pU6fMV199NahoLC+88ELdV155Zfv69evjly1btj4gICB/5syZgXPmzKm+cuXK9YmJifGPP/54CsCNN97Y9Jlnntm5YcOG+KioqOz777+/fsFy0tLSvH///ffEJ598cs+YMWOC77nnnj2xsbEJX3zxxeaxY8c2OckhLZXz+geFiMjpMMaMAO4BWgCHgDXARGvtzx4NrIwZY8KAiUAPwBfYDnwAvGytzfNgaCWy1vYp9Ppj4GMPhuN2xpjKwB5gibW2r6fj8bTzZX9Ya8eWwTKeKYtY5Px0881fBsfG7vUvy2VGR9fOev/9QUmlnb9Vq1aHW7RocQxg0aJFAX379k0LDAzMB+jXr9/BhQsXVhk4cGD6ww8/HHz77bc3GDRoUHrv3r0zc3Jy8PPzy7/uuusa9+vXL33YsGHpRZddv3793ODg4KPz58+vHBUVdWTLli0Vr7zyykyA5557rs6cOXOqAaSkpPjGxcVVrFu37uHiYly8eHGVoUOHHvDx8aFJkyY5nTp1OlQw7dtvv63y4osv1j1y5IhXWlqaT2RkZDZwQiwFfv7558qXXHLJofr16+cCDBs27MDixYsDRo0alebr62uvu+66dIB27dod/vHHHwOLzn/JJZdkjh8/Pnjo0KEHhg8ffjAkJCR/3rx5gSNHjtxXpUqVfIA6derk7d+/3/vQoUPe/fr1ywT4+9//vn/IkCHNCpYzfPjwAwWvf/nll8CNGzdWKnifmZnpffDgQa/q1avnl7QdZ0o1eyJSrhlj7gH+CzwD1AEaAW8Ag0qxrHP2ApkxJgRYDiQBLa21VYEhQHugiidjkz+5FjgKXGWMqVdSoXP5XCtjp7U/TuUC2l8ip61ly5bZMTExJSaY/v7+xxMKa22xZVq1anV01apV8S1btsx++OGHG4wfP76er68va9asSRg8eHDa7Nmzq3Xv3j00NzeXgiaOd999d32Aa6+99uD06dOrT5s2rXqfPn0Oenl58c0331RZvHhxlRUrVqxPTEyMj4iIyM7Ozj5pPmKMOeGzrKwsc++99zb+/PPPN2/YsCF+5MiR+44cOXLS5ZS0jQA+Pj7Wy8ur4DW5ubknrPSZZ55Jeffdd7dnZ2d7XXrppRGrV6+uaK0tNr6TKUgMC2JasWJFwvr16+PXr18fv3fv3rVlmeiBkj0RKceMMVWBCcA/rLWfW2sPW2tzrLVfW2v/5Srzp+Z9xpjuxpidhd5vM8bcb4xZCxw2xjxijPm0yHpeNsa84np9kzEmwRhzyBizxRgz5iTxeRtj/mOM2WeM2QL0Kxq/MeY9Y0yyMWaXMeZpY0xJzV2eBJZaa++x1iYDWGsTrbUjrLVpruUNNMbEGWPSXM3vIops57+MMWuNMYdd663jamZ5yBjzozGmuqtsQXPT24wxu13x3XuS7bzEGLPUtd4YY0z3QtOONwM0xtxojPm50LQrjTHrjTHpxpjXAFNoWogxZoExZr9r/31sjKlWaHpbY8wqV+z/A046Epsx5u+Fjlu8MeYi1+cRrhjTXPtuYKF5PjDGvG6MmeOab7kr6T6ZG4C3gLXA9UViKHquFSQwF7tiOmiMmWKMqVhonr8bYzYZYw4YY74yxtSnGMYYP9e5tsMYs8fVLLGSa1otY8w3rm08YIz5yRhT7O+Dkx0T1/SbXfvxoDHme2NM47+4Px4sbtsLvqeu/ZUCTHF93t8Ys8a1LUuNMa2KLG+86xxPN8b8r8i+/JfrXN5tjLm5SCzH/04YY742xmQWeuQbY250TXvZGJNkjMkwxqw0xlxWaBl/at58su+FlD/vvz8o6bff/p5Ylo9T1eoNGDDg0LFjx8wLL7xwvF/c4sWL/efMmRNQtOzll1+eOXfu3GqHDh3yysjI8Jo7d271Hj16HNq2bZtvlSpV8seNG3fg7rvv3rNmzRr/9PR0rwMHDngPGzYs/a233kpKSEjw9/HxoSBh+e9//7sbYOTIkQe/++676rNmzaoxYsSIA+A0YaxatWpelSpV8levXl0xJibmpH3UunXrdmjWrFk1cnNz2b59u++yZcuqAGRlZXkB1K1bNzc9Pd3r66+/Pj5CZ0BAQF56evoJ/yu7du16ePny5VWSk5N9cnNzmTVrVo3u3btnnvzI/SEuLs6vQ4cO2RMnTkxp2bLl4djY2Iq9e/fOmDp1aq1Dhw55AezZs8e7Zs2aeYGBgXnfffddAMB7771Xs1OnTsWup0uXLhnPPfdc7YL3S5curVRcub9CyZ6IlGedcH7kf/EXlzMcJxGrBkwF+hpjAsFJ2IChwCeusnuB/kAgcBPwUkHiUIy/u8q2xamBu7bI9A+BXKC5q8xVQEn9o64APi1hWkETz+nA3UAQMBf42hhToVCxwcCVQBgwAPgWeAiohfP/4q4ii+0BhLriesAU07fMGNMAmAM8DdQAxgOfGWNO6A9RZL5awGfAI671bwY6Fy4CTALqAxFAMPCEa94KwGycY1UDmOXatpLWNcQ172ic4zYQ2G+M8QW+Bn4AagN3Ah8bY8ILzT4cJ9GuDmzCaUZb0noaAd1xmqp+7FpfUcfPNWttwRB51wO9gBCcY/OIa3mXu/bBUKAeTrPdGSWs/jnXvG1wzqcGwGOuafcCO3HOizo4x/yES+CnOibGmKtd817jWtZPOOfcX9kfxW67S12c49sYuM31PXsfGAPUBCYDXxljCg8zPxToDTQFWgE3umLpjXNuXolzTpfYT9JaO8BaG2CtDcD5zqYA812Tf8fZxzVw/ibMKpxQFtr2Un0vRM6El5cXX3311eb58+cHBgcHRzdv3jzq8ccfr9+oUaMThoHs0qVL1ogRI/ZfdNFFEe3atYsYNWpUaufOnbNXrlxZqU2bNhEtWrSIfO655+o99thjyWlpad69e/cODQsLi7zsssvCn3766WKTzqCgoLzQ0NDsXbt2+fXo0SMLYPDgwem5ubkmLCws8qGHHqrfunXrYptvFhg1alRas2bNjoaHh0fdcsstjTp06HAIoFatWnnXX399amRkZFSfPn2aF17O6NGj9915552NCwZoKfi8cePGOY899tiubt26hUVERES1atUqa+TIkWmnuz///e9/1w4NDY0KDw+PrFSpUv61116bfu2112b06dMnrWAfPfXUU3UBpkyZsvX+++9vGBYWFrl27dpKzz777O7ilvn2228nrVq1qnJYWFhkSEhI1GuvvVbmfwPMyao0RUTOZ8aY64EXrLV1T1LmA2CntbbgB3R3YJq1tqHr/TZggrX2/ULz/Ay8ba39yBhzJfCWtbbYGh1jzGxgobX25WKmLQBmWmvfcr2/Cvgep79dTWAHzo/+bNf04cBt1toexSwrBxhgrf2uhDgexWneOdT13gunyef11tpFru182NVvDmPMZ8Bea+3trvd3Aj2ttVcbY5oAW4EIa+161/R/AzWttbcYY54AmltrRxpj7geirbWjCsXyPfCJtfZDY8wi1/5+11U7cqu1tosxZjQwzlp7iWse44r3CWvtCYNcuBKNx621bY0xXXGSngbW9U/OGLMUWFBwnIvM+z0wt+gxctXKzALqW2vzXZ9NBxKttU+4zp1ca21BzWRf4EVrbbH3hzLGPAJca61t46qBSwLaW2tXu6Zv48RzbRvwbKFzpC/wqrU2xBjzHrDfWnufa1oAcBAItdZuM8ZYnMRlM5AJtLLWbnaV7eQ6Bk2NMROA1sC91tpNxcXumuekx8QY8y3wqbX2Pdd0L9d6I6y120u5P0ra9u44SXigtfaIa/qbwD5r7aOF1pGI851Z7FreI9baaa5p/3bNP9YY8z7O+f6Aa1oYkOjal5uK/p0oVOZnYLC19qcS9tlBoLu1NuZMvhclHQM5v8TExGxr3br1Pk/HIee/mJiYWq1bt25SmnlVsyci5dl+oJb56/15il61/ASnBgZgBH/U6mGM6WOMWWac5nBpQF+cWpDiFPzALVD4B3FjnKQv2dXMKw2npqI2xduPU7tTkvqFl+9KXpJwangK7Cn0OruY90Wb/hSNvbgmhI2BIQXb4NqOLqeItSDe48t3JW3H3xtjahtjZhineWsGMI0/9nN9YFdBolcovpIE4yRExcZQkOgVWk7hfZZS6HUWJ+6jwkbjGoDGWrsbWIzTjLGw4q6Ql7Sfix7TTJzzoHB84NSy+QMrCx2D71yfAzyPUyv5g3GaHj9QQvwnPSY4x/rlQus4gFMDWzSeAme6P4qeY6kFiV6h9d9b5FwLLjJPScfrZN/FExinifiXwKOFEz1jzL3Gacaa7lp/VYr//pf2eyEickaU7IlIefYrcAS4+iRlDuP8EC5QXC1g0SYQs4DuxpiGwN9wJXuu5mKfAf8B6lhrq+E0lyyp93Yyzo/RAo0KvU7CGbiilrW2musRaK2NKmFZP3KSporAbpwfmLhiNa517zrJPKdSNPbimqkkAVMLbUM1a21la+2zp1j2n/ZNoXgLTMI5Lq2stYHASP7Yz8lAA9c8heMrSRJOM8GidgPB5s/91xpRin1mjLkUp5btQWNMinH6mXUEhhe5GFFcc5uS9nPRY1oZp0a4aHz7cJL1qELHoKqrGSLW2kPW2nuttc1wmu/eY4zpWUwcpzomScCYIse6krV26V/YHyc7x4ruqyScUXYLr9/fWltiU9KSto2TnC+u8+ETnBr7yYU+vwy4H6epaHXX9z+d4r//pf1eiIicESV7IlJuWWvTcfolvW6MudoY42+M8XXVvv3bVWwNTh+8GsaYujh92k613FRgEc6gEFuttQmuSRUAPyAVyDXG9MHpz1aSmcBdxpiGxhn85HiNinUGWfkBeMEYE2iM8TLOoCTdSljW48ClxpjnXduBMaa5MWaacQYumQn0M8b0NE5ftHtxkskTfoifgUdd+zQKp3/i/4opMw0YYIzpZZwBaSoaZ3CNE27CW8QcIMoYc43rx/9d/DkRr4LTRDDNOP2f/lVo2q84fR3vMsb4GGOuATqcZF3vAuONMe2Mo7lxBhZZjnMx4D7XedMdJxkqqV/cydwAzAMicfp0tQGicS409DnJfAD/cJ0jNXD6xBXs50+Am4wxbVwXGp4BlltrtxWe2VUz+Q5O/9Ha4PQZM8b0cr3u79pmA2QAea5HUac6Jm/hJG9RruVWNU5/yL+yP0ra9uK8A4w1xnR0HcfKxph+xpjTGY12JnCjMSbSGOOP830qyUSgMvDPIp9XwTnvUgEfY8xjOH1Ai1Pa74WIyBlRsici5Zq19kWce+w9gvMjLAm4A2cAD3AG8YgBtuEkVyf7MVnYJziDOBxvwmmtPYTzA3gmTt+pEcBXJ1nGOzh99GKAVcDnRaaPxkkg413L+5QSmnm5+mJ1ApoAccaYdJxaxhXAIWttIk7t16s4NT0DcPr4HTvN7S3OYpzmf/OB/1hrT7ghurU2Cec2Fw/xx/7/F6f4/2Ot3Ydz64hncZomhgK/FCryJHARTs3JHArtO9c2XYMz+MZBYBgn7tvC65qF8wP+E5z7MM4GariWMxAn+diHc8uO0QX9FE+XcQboGIrT3yyl0GMrzvlXtOliUZ/gnJtbXI+nXXHPBx7FOc7JOLWT15WwjPtxjtUyV7PXH4GCgWZCXe8zcRLlN6y1i4ou4FTHxFr7Bc5AMDNc64ilmET2DPdHsdteHGvtCpxBj17DOe6bcA3AcirW2m9xbtGywDXfgpMUHw5cAhw0f4zIeT3Od/lbYANOM9AjFN8st9TfCznv5Ofn55/ZuPwiRbjOoVLfjkEDtIiIyBkxfwzQ4mv/GDGytMtaArxrrf2oDEKTcsQ4A6rcaq390dOxlAXjDITT0Fp78ykLS7kQExPzVd26dSODgoLSvby89INbzlh+fr5JTU2tmpKSEt+6deuBp57jRLoJqYiIeISruVwznMRRpNxyNZGNxKnFlwtEbm7urSkpKe+mpKREo1pbKZ18IDY3N7ek2y6dkpI9ERE561x9xzbh3Mfu51MUFznfrcLpI3uHpwORs6ddu3Z7cZqCi3iMmnGKiIiIiIiUQ6pSFhERERERKYeU7ImIiIiIiJRD512fvVq1atkmTZp4OgwRERERERGPWLly5T5rbdCpyp13yV6TJk1YsWKFp8MQERERERHxCGPM9tMpp2acIiIiIiIi5ZCSPRERERERkXJIyZ6IiIiIiEg5pGRPRERERESkHFKyJyIiIiIiUg4p2RMRERERESmHlOyJiIiIiIiUQ0r2REREREREyiEleyIiIiIiIuWQkj0REREREZFySMmeiIiIiIhIOaRkT0REREREpBxSsiciIiIiIlIOKdkTEREREREph5TsiYiIiIiIlENK9kRERERERMohJXsiIiIiIiLlkJI9ERERERGRckjJnoiIiIiISDnktmTPGPO+MWavMSa2hOnGGPOKMWaTMWatMeYid8UiIiIiIiJyoXFnzd4HQO+TTO8DhLoetwFvujEWERERERGRC4qPuxZsrV1ijGlykiKDgI+stRZYZoypZoypZ61NdldMIuJiLeTnQH6upyMREREROXcZL/Cp6OkoSs1tyd5paAAkFXq/0/WZkj05v1kLuUfgWMYfj6MneZ2fAzYPbH6h53zIzwNczwWfnVAuz0nY8nMgLwdsrvOcX/hRaHrBZzbf03tJRERE5NxXryOMWObpKErNk8meKeYzW2xBY27DaepJo0aN3BmTyOk5mgHbvoetcyBt84lJ3OnUmHn5QIVA8PZzrhoZb+fZy/VModcF0/70uqC8L/j4g7ev89rLx/Xsenj7gvEpNL1wGR+K/yqKiIiICAH1PB3BX+LJZG8nEFzofUNgd3EFrbVvA28DtG/fvtiEUMTt0rfB5q9hy9eQtMipIatYA4JaQWBT8At0kreCh98pXnv7gVGiJSIiIiLu4clk7yvgDmPMDKAjkK7+enJOyc+DlN/+SPD2uQaWrdECLrobQgZA/U6u2jERERERkXOL236lGmOmA92BWsaYncDjgC+AtfYtYC7QF9gEZAE3uSsWkdN2LBO2z3MSvK1zIGuv01yyYVfo/iI0GwDVm3s6ShERERGRU3LnaJzDTzHdAv9w1/pFTltGklNzt/lrSFoIeUfBrxo07eMkd017Q8Xqno5SREREROSMqP2ZXJhyj8LGT2HNG7B7qfNZ9VBo8w9X88zOzoAmIiIiIiLnKSV7cmE5tBPWToa1bztNNKuHwmXPQvOroUa4p6MTERERESkzSvak/LPWGT1zzeuwabZzj7lm/aHtHdD4CtdtDkREREREyhcle1J+HTsE8VOdJG9/vHObhPb3QuuxULWpp6MTEREREXErJXtS/uxf7yR48R86CV+ddtBrCoQPA99Kno5OREREROSsULIn5UN+Lmz+Bta8Bjvmg3cFCBvqNNWs20E3LxcRERGRC46SPTm/HU6B2CkQ8xYc2gFVgqHLRGivTX3XAAAgAElEQVR5K/jX9nR0IiIiIiIeo2RPzj/HDsHGzyHhY6cWz+ZDo57Q47/ObRO8dFqLiIiIiOhXsZwf8o7Btu+dBG/zV5Cb7Qyy0vEhiBip2yaIiIiIiBShZE/OXdY6NzxPmAaJM+HIAahYE6JugojroX4n9cUTERERESmBkj059+yPd2rwEj6BjG3gUwlCBkHkSGh8FXj7ejpCEREREZFznpI9OTcc2gWJMyB+GqSucW503ugK6DwBml8NFap4OkIRERERkfOKkj3xrOTl8PPDsGMBYKHuxc5AK+HDoHJdT0cnIiIiInLeUrInnpF7FJZNgN+ehcr14JJHnX54NcI8HZmIiIiISLmgZE/Ovr0x8N1oSF0L0bdA9xfBL9DTUYmIiIiIlCtK9uTsyc+F356DX5+ESjXh6q8hpL+noxIRERERKZe83LlwY0xvY0yiMWaTMeaBYqY3NsbMN8asNcYsMsY0dGc84kH718P0zvDLIxA6GG6IVaInIiIiIuJGbkv2jDHewOtAHyASGG6MiSxS7D/AR9baVsAEYJK74hEPsfmw8r8wrS2kbYb+/4P+052aPRERERERcRt3NuPsAGyy1m4BMMbMAAYB8YXKRAL/53q9EJjtxnjkbEvfCt/dBDsXQ7P+cNU7GmFTREREROQscWczzgZAUqH3O12fFRYDDHa9/htQxRhzQpWPMeY2Y8wKY8yK1NRUtwQrZchaWPsOfNgK9q6GXlPg6q+U6ImIiIiInEXuTPZMMZ/ZIu/HA92MMauBbsAuIPeEmax921rb3lrbPigoqOwjlbJzaBd83hfm3Qb1OsAN6yD6RjDFnQ4iIiIiIuIu7mzGuRMILvS+IbC7cAFr7W7gGgBjTAAw2Fqb7saYxF2shfWfwPw7IO8YXP4atLkdjFvHABIRERERkRK4M9n7HQg1xjTFqbG7DhhRuIAxphZwwFqbDzwIvO/GeMRdslLhx9th42dQ/1Lo/QFUD/V0VCIiIiIiFzS3JXvW2lxjzB3A94A38L61Ns4YMwFYYa39CugOTDLGWGAJ8A93xSNukvwbzB4AR9Og67+h3T3g5e3pqERERERELnjG2qLd6M5t7du3tytWrPB0GAKw6xf4vA9UCoKrv4Ra0Z6OSERERESk3DPGrLTWtj9VOXc245TyLGkRfNEfAhrAkPlQpaGnIxIRERERkUI0eoacuW3znBE3AxvDsMVK9EREREREzkFK9uTMbJnj9NGrHgZDF+neeSIiIiIi5ygle3L6Nn4BX/7N6Zs3ZAH4656HIiIiIiLnKiV7cnrW/w++HgJ12jt99CrV8HREIiIiIiJyEkr25NTip8LcEdCgM1z7PfhV9XREIiIiIiJyCkr25OTWvgvf3gDBPeCauVChiqcjEhERERGR06BkT0q2+nWY93do0guu/hp8K3s6IhEREREROU1K9qR4K1+CBXdAyEAYNBt8K3k6IhEREREROQNK9uREyyfBonsgbAgM+BR8/DwdkYiIiIiInCEle/IHa+GXx+HnhyDieuj3CXj7ejoqEREREREpBR9PByDnCGvhpwfh9+cg6ia46h3w8vZ0VCIiIiIiUkpK9sRJ9BbdA6v+C63HQs/XwajSV0RERETkfKZk70KXnwcL7oSYN+Gif0L3l8AYT0clIiIiIiJ/kZK9C9mxTJgzArZ8DRffB5c9q0RPRERERKSccGtbPWNMb2NMojFmkzHmgWKmNzLGLDTGrDbGrDXG9HVnPFJIxg6Y0QW2zoXLX4OuzynRExEREREpR9xWs2eM8QZeB64EdgK/G2O+stbGFyr2CDDTWvumMSYSmAs0cVdM4pK8HGYPgtxsuGaOc9N0EREREREpV9xZs9cB2GSt3WKtPQbMAAYVKWOBQNfrqsBuN8YjAOv/BzO7g68/jPhViZ6IiIiISDnlzmSvAZBU6P1O12eFPQGMNMbsxKnVu9ON8VzYrIVfJ8Cc66B2OxixHGpGejoqERERERFxE3cO0FJcBzBb5P1w4ANr7QvGmE7AVGNMtLU2/08LMuY24DaA6rXr89K8DW4JuLzyzj/KVTsfokXaN8RXv5ofazxF3i8HgYOeDk1ERERERNzEncneTiC40PuGnNhM8xagN4C19ldjTEWgFrC3cCFr7dvA2wDt27e3/3dlmLtiLn8O74Ev/wZpv0KXZ4js8ACRGohFREREROS8dc9plnNnM87fgVBjTFNjTAXgOuCrImV2AD0BjDERQEUg1Y0xXVhS18HHHSB1DQz4FDo+qBE3RUREREQuEG6r2bPW5hpj7gC+B7yB9621ccaYCcAKa+1XwL3AO8aY/8Np4nmjtbZoU08pjS1z4JvrwC8QrvsJ6rTzdEQiIiIiInIWufWm6tbauTgDrxT+7LFCr+OBzu6M4YJjLax6GRbfC0Ft4OqvoErRcXFERERERKS8c2uyJ2dZXg4suBPWTobmf4O+U8G3sqejEhERERERD1CyV14cOQhfD4Ed86HDA9BlIhh3dskUEREREZFzmZK98uDgJviiH6RvhV5TIPpGT0ckIiIiIiIepmTvfJZzGFa+BL89B95+MORHaNjV01GJiIiIiMg5QMne+Sg/D+I+gKWPQeZuCL0Guv0Hqjb1dGQiIiIiInKOULJ3PrEWtn0HS+6DfbFQ7xLoPxMaaEBTERERERH5MyV754s9q5wkb8d8qBYCA2ZB6GDdJF1ERERERIqlZO9cl7EDfn4YEqZBxZrQ42VoPRa8K3g6MhEREREROYcp2TtXHUmD3yY5N0gHuPh+55YKFat5Ni4RERERETkvKNk71+Qdg5g34den4MgBiBwFnZ+CwEaejkxERERERM4jSvbOFdbChk/h5wchbTM0ugK6/hvqtPV0ZCIiIiIich5SsncuSP4NFt4FycuhVjRc8y006aXBV0REREREpNSU7HnajgXwRT+oWAOueg+ibgAvb09HJSIiIiIi5zkle56UtAi+6A/VmsOQBeAf5OmIRERERESknPDydAAXrJ1L4PN+ULUpDJmvRE9ERERERMqUkj1P2PkzfN7XGWFzyALwr+3piEREREREpJxxa7JnjOltjEk0xmwyxjxQzPSXjDFrXI8Nxpg0d8ZzTti1FD7vAwENnESvch1PRyQiIiIiIuWQ2/rsGWO8gdeBK4GdwO/GmK+stfEFZay1/1eo/J1A+b7PwO5l8HlvCKgHQxc6zyIiIiIiIm7gzpq9DsAma+0Wa+0xYAYw6CTlhwPT3RiPZyX/Bp/1cppsDlkIAfU9HZGIiIiIiJRj7kz2GgBJhd7vdH12AmNMY6ApsMCN8XhOygr47CqoVMtJ9KoUuxtERERERETKjDuTveLuCG5LKHsd8Km1Nq/YBRlzmzFmhTFmRWpqapkFeFbsWQWfXgl+1Z2mm4HBno5IREREROSU0tOP8N13mzhyJNfToUgpufM+ezuBwplNQ2B3CWWvA/5R0oKstW8DbwO0b9++pITx3LN3DXx6BVQIdCV6jTwdkYiIiIhIiXbtyuCrrxKZPTuRhQu3kpOTT//+YXzxxTB8fDSQ//nGncne70CoMaYpsAsnoRtRtJAxJhyoDvzqxljOvtS1MOsK8A2AYYugahNPRyQiIiIi8ifWWuLiUvnyy/V8+WUiv//u1M2Ehtbg7rsvwd/flyefXMzYsd/wzjsDMKa4xntyrnJbsmetzTXG3AF8D3gD71tr44wxE4AV1tqvXEWHAzOstedPjd2ppK6DWT3Bp5JTo1e1qacjKlFi4j4mT17JdddF06GD+hKKiIiIFMjPt/z6axLJyZn07x9GxYrurCc5e/Ly8lm6NInZs50Eb/PmgwB07NiASZN6MmhQOC1a1Dqe2OXnW556agn16gXw1FOXezJ0OUPmfMux2rdvb1esWOHpMEq2Lw5m9gBvXxi6GKo393RExdq4cT8TJizhk0/WkZ9v8fPz5p13BjBqVGtPhyYiIiLiMdZaVq9OYcaMWGbMiCUpKQOAoCB/xo5tz+23t6devSoejvLMZWXlMG/eZr78MpGvv97Avn1ZVKjgTc+eTbn66hYMGBBW4nZZa7nttq95993VvP56X8aNu/gsRy9FGWNWWmvbn6pc+bg8ca7YHw+zLgcvH2fUzVMketZaNm06wKJF2wgIqMDAgeFUrlzBrSFu2nSAp55awrRpa/Hz8+aeey7hllsuYty4OYwePZt16/YyaVJPvL3VJlvOTZmZx9i9+xC7dmUQFFSZ6Ojang5JROSkli/fyb33/kBCwj6efLI7t9/eXv9nz0Hr1+9jxoxYpk+PZcOG/fj4eNGrVwiTJvUkKKgyr732G08/vYRnn/2ZYcOi+ec/O9K+/bl9K62cnDxmzoxj1qx4fvhhM9nZuVSt6kf//mEMGhRO797NqVLF75TLMcbw5pv92bs3izvumEvt2pW59trIs7AF8lepZq+s7F8PM7uDMTB0EdQIL7bYjh3pLFiwlYULt7FgwVZ27sw4Pi0goAJDhkQyenRrunZtjJdX2bWJ3rLlIE89tYSpU2Pw9fVm3Lj23HdfZ+rUCQCcPwb/93/f8/rrv9OnT3OmTx9M1aoVy2z9IqeSl5fPnj2H2bUrw5XMOQmd8/zH64yMo3+ar0OHBowZ045hw6LcfrFERORMbN+exoMPzmf69Fjq1KlMeHgtlizZTocODXj77f60bl3X0yFe8HbsSD+e4K1Zk4Ix0L17E4YPj2bw4Ehq1Kj0p/KbNh3g1VeX8/77a8jMPEbnzsH8858d+dvfIs6pwUuys3N4773VPP/8UnbsSCc4OJBBg8K5+uoWdO3aGF9f71ItNysrhyuvnMqKFbv54YeRdOvWpGwDl9N2ujV7SvbKwoENTqJn850+ejUjjk9KSclk4cI/kruCNtFBQf706NGUyy9vQo8eTUlJyeTDD9cwa1Y8hw4do3Hjqowa1YrRo1sTGlqz1KFt3XqQp59ewocfOkne2LHtuP/+LtStG1Bs+cmTV3DHHd8SElKdr78e/pfWLXIys2evZ+rUtezcmcGuXRmkpGSSl/fnv0fe3oZ69arQoEEVGjQIpH79ABo0CDz+ft26PUyevJKEhH0EBvoxalQrxoxpR8uWdTy0VSLnrvx8y44d6VSo4E39+udfE7TzSUbGUSZN+omXXlqGMYbx4ztx332dCQiowPTpsdx993ccOJDNPfd04vHHu+lC1Vm2Z08ms2bFM316LEuXOreE7tixAcOHRzNkSNRpfT/S048wZcoaXn31N7ZsOUhwcCB33NGBW2+96IQE8WzKyDjKm2/+zosvLmPv3sN07hzMww9fRu/ezctsYJUDB7Lp0uV9du06xE8/3USrVvqf6wlK9s6m2VfD7qUwbBEHTFMWL3YSuwULthEf79wXsGpVP7p3b8Lllzfl8subEhUVVOyXLisrh9mz1/PRRzHMm7eF/HxLp04NueGG1gwdGkX16qf3B2TbtjQmTlzCBx/E4O1tGDOmHQ880OW02pgvXryNwYNnkpdnmTnzWq68MuTM9ofISaSlHeGuu75l6tS1NGpUlfDwmscTuPr1/0jsGjSoQu3alU/Z1Mlay88/72Dy5JV8+mk8R4/m0alTQ8aMacfQoVFUquR7lrZM5NyQk5PH5s0HiY9PJSEhlYSEfSQk7GP9+n1kZeXg7W0YObIVDz10GWFhuqBXlnJz83n33VU89thCUlOzGDWqFRMnXk5wcNU/lTtwIJv77pvHe++tpkmTarz5Zj9693ZvH//Nmw/g6+tNo0ZVT13YDVJTDxMQUMFjf5PT0o7w+ecJTJ8ey4IFW8nPt7RsWZvrrovmuuuiadaseqmWm5eXzzffbODll5ezcOE2/P19GT26FXfd1ZGIiKAy3oqS7duXxSuvLOfVV38jLe0IvXqF8NBDl9G1a2O3rC8pKZ1Ond5zDWBzC40bV3PLevbty+L333fRq1fzMm3xVh4o2TuLFs+L5evZ61jwawZr1qRgLfj7+3LZZY2OJ3dt29Y94/b5u3Zl8Mkn6/jwwxji4lLx8/Nm4MBwRo9uTa9eIcVWwe/Ykc7EiUuYMmUNxhhuu+0iHnigCw0aBJ7RurduPcigQTOIi0vlxRev4q67Omqo3SJWrtzNPff8wOHDxxgwIIxBg1rQunUd7aeTmD9/Czfd9CW7dx/ikUe68vDDl5W6KUlx9u/P4sMPY5g8eSUbNuynWrWKjB7dijFj2hMZefb+6YqUxFpLamoWXl4GPz9v/Px88PX1KtXfjaysHBIT97mSuVTi453njRsPkJubf7xccHAgERFBREbWIiIiiISEVCZPXsnRo3kMHx7NI490pUWLWmW5mRccay3ffruJf/1rHvHxqXTt2pgXXrjqlP25lizZzpgx37B+/T6GDYviv//tXWLLm9LIzDzGrFlxvPvu6uM1WF27NmbUqFYMGRLp9u4aqamHmTkzjmnT1rFs2U6MgeDgqoSG1iAsrCahoTUIDXWemzatToUKf+3/QVZWDlu3HmTLlsKPNLZsOcjGjfvJycmnWbPqDB8ezfDh0URFlW2f77Vr9/Dyy8v4+ON1HD2aR69eIfzznx3dmqjs3n2IF15YyltvrSQrK4drrongoYe60K6d+/sSxsXtpUuXKdSpU5mff76ZWrX8y2zZ+fmWd99dxYMPzufAgWw6dGjAG2/0PSvbdb5QsncW3XLLl0ybto5LLw3m8sud2ruLL27wl/9oFSgYFerDD9fwySex7NuXRe3alRkxIpobbmhD69Z12Lkzg2ee+Yn33luNMYZbb23Lgw9eRsOGZ5bkFZaZeYzRo7/giy/Wc/PNbXjjjX74+WlMn4yMozz66AJee+13ateuTLNm1fn11ySshUaNqjJwoJP4detW+jbx5U12dg4PPjifl19eTlhYTaZO/Ztbb/VhrWXx4u1MnrySzz6LJycnny5dGnHbbRdx7bWRqu2Tsyo7O4eFC7cxd+5G5s7dyNataX+abgz4+fkcT/78/LypWNGnxM+OHs1l/fp9bNuWRsG/cG9vQ0hIDSIiahERUYvIyCAiIoJo0aIWAQEnNhHcsyeT//xnKW+8sYLs7ByGDYvmkUcuK/MfvxeCtWv3MH78D8ybt4XmzWvw/PNXMmhQ+Gkn8EeP5vLcc78wceJP+Pv78txzV3DrrReVOjmw1rJ8+S7ee28VM2bEkZl5jPDwmtx8c1tycvKYOnUtiYn7qVjRx3UBuRVXXVX8BeTSyMrK4csv1/Pxx+v4/vvN5Obm07JlbYYOjSIvL5+NGw+wceMBNmzYT1rakePzeXsbmjSpdjz5K5wMNm5cFW9vL/LzLSkpmWzZcpDNmw/8KZnbsuUgKSmZf4olIKACISHVadasOuHhNbnmmgjat6/v9ouyqamHefvtlbz++u8kJ2cSHl6TkSNb0apVHaKja9OkSbW/nPxt2XKQ5577mQ8+iCEvL5/rr2/F/fd3PusXNn/6aTtXXjmVNm3qMn/+6DJpkrxqVTLjxs1h+fJddO3amGuvjWDixJ/Yu/cwt9/enqefvvy0W7qVZ0r2zqK9ew9TpcrZaZqQk5PHt99u4qOPYvj66w0cO5ZHixa12LLlINZabrmlLQ89dNkJTUZKKz/f8sQTi3jqqSV07hzMZ58NPT6oy4XGWstnnyXwz39+R3LyIW6/vT0TJ/akWrWK7N17mG++2cCXXyYyb94fo1317RvKoEHh9OkTSmDgqUe7Ko9WrNjNqFFfsH79Pu68swPPPnsF/v5nL9lKTT3Mhx/G8PbbK9m48QDVq1fkhhtaM2ZMe9VmXGBycvL48MMYXnllOYGBfnTs2ICOHRtyySUNCQ4OLNMfgNu2pTFnzgbmzt3EggVbOXIkF39/X3r2bEqPHk3w8fHi6NE8jh7N5ejRPI4cyT3+uuBz57O8Qp87z97ehvDwWscTu4iIIEJDa5TqYlxq6mFefPFXXnvtdw4fPsa110by6KNd1e/1NKSkZPLoowt4//01VK3qx+OPd+P22y8u9YXexMR9jB07h0WLttG5czCTJ/c/o+R7374spk6N4b33VhMXl4q/vy9Dh0Zxyy1t6dw5+Pj5ba3l9993M3VqDNOnx7J/fza1a1dm+PBoRo9uTdu2dc/4u5Cbm8+CBVuZNm0tX3yxnszMYzRsGMiIEdFcf32rYvt0WWvZvz+bjRv3H0/+nETQec7MPHa8rK+vF/XrV2HPnsMcOZJ7/POCmsJmzarTrFk1QkJquF47j5o1K3m0tc2xY3l8+mk8L7+8nN9+23X8c39/XyIjg4iKCiI6uvbx54YNT/13KC5uL5Mm/cz06bH4+npx881t+de/LqVp09I1Qy0Ls2evZ/DgmfTu3ZzZs4eV+sJBWtoRHn10AW+8sYKgIH/+85+ruP76lhhjSEs7wmOPLeT113+nZs1KPP/8lYwe3fqCbk2lZO8CcOBANv/7XyyzZsUTFlaTBx/s4rY20zNnxnHjjbOpVcufL7+8jrZt67llPeeqrVsPcscd3zJ37kbatKnL5Mn9S6yZKnwfm2++2UBqaha+vl706NGUgQPDGDgwvMyS8XNZTk4ekyb9zFNPLaFOncpMmTLIo/0/8/MtixZtY/LklXzxRQI5OfkEBwdSr14V6tULoF69AOrWDSj03nmuXbuyamjPcwW1GU8/vYStW9O46KJ6VKzow6pVycd/ONatG+BK/pwE8OKL65/WcOQFjh3L45dfdjBnjlN7l5CwD4CQkOr06xdKv35hdO3a+Jy9IfP+/Vm89NIyXnllOYcOHeOaayJ49NGutGlz7owWaa1lwYKt1KzpT6tWdTzWfycrK4cXXljKc8/9wrFjedxxRwceeaRrmQzKYa3lww9juPfeHzh06Cj33deZhx++rMSLyXl5+fz44xbee281s2evJycnnw4dGnDrrW0ZNiz6lBcZjx3L49tvNzJ16trjF5AjI4MYPboV11/f6qStg6y1rFyZzLRpa5kxI5Y9ew5TtaofQ4ZEcv31rf7SqOLWOjV4hZO/pKQM6tcP+FMy17hxtTJrReVuGRlHiY9PJS5uL7Gxe4mLSyU2di/JyX/URgYG+hEVVTgJdBLBunUDWLFiN8888zOzZ6+ncmVfbr+9Pffc0+mcud/f5MkrGDt2Djfd1Ib33ht4RkmYtZaPP17H+PE/kJqaxbhx7XnqqcupVu3EZsarVyczbtxcli3bSZcujXj99b5uHSBm69aDJCdncumlwW5bR2kp2ZMyt3p1MoMGzWDfviw+/PBqhgyJ8nRIbpeTk8cLL/zKhAmL8fb24qmnenDHHR1Oe3jlvLx8fv11J199lciXXyayYcN+AC66qB6DBoUzaFA4rVqVv35+iYn7GDXqC37/fTcjR7bilVd6n1NNLvbsyWTq1LWsW7eX5ORDJCdnkpx8iP37s08oawzUquV/PPlzEsIA6tevQp8+oTRvXsMDWyCnIycnj2nT1vL00z+xZctB2revz5NPdqdPH2dUupycPNau3cOyZTtZvnwXy5fvOv4dNQYiI4OOJ38dOzYgKqr2n777ycmH+PbbTcyZs5F58zZz6NAxKlTwplu3xvTtG0q/fqHn3YjGBw5k8/LLy3j55eWkpx9l4MBwHnusq8f7ySQnH+KWW77i2283Ac538vLLm3LFFU3p2bNZqQfXOBOZmcf4/PMEHnpoPrt2HWLw4AieffYKt/wNSE09zPjx8/jooxiaN6/BW2/1o2fPZsenb9+expQpa3j//dUkJWVQo0YlRo9uxS23XFTqe48eOJDNzJlxTJ26lqVLkzAGLr+8KaNHt+aaayKONwfevPkAn3yyjmnT1rFhw34qVPCmf/8wrr++JX37hp6zFzTOVQcOZBMX5yR/TiLoJIH79mUdL1O1qh/p6UepXr0id93VkTvv7EDNmmXXP66sPPHEIp58cjEPPtiFZ57peVrzxMXt5R//mMvixc4tSd58sx8XXXTyCoX8fMuUKau5//4fSUs7wp13duDJJ3uUWQuq5ORDzJwZx/TpsSxfvovo6NqsW3d7mSy7LCnZE7fYsyeTa66ZydKlSTz2WFcef7x7uR0d6eefdzB27DfExaVyzTURvPxy77/UBxKcG7Z++eV6vvwykWXLdmIttGxZm7vvvoQRI1qe9/8k8/Mtr7/+G/ff/yOVKvkyeXL/8+qmq8eO5ZGSkklKSuafksDk5ILPnPd79hwmNzcfY+Bvf4tg/PhOdOp0dq76xcXt5bXXfmPOnI00bBhIZGSQq3+W008rOLhquf1Onq7c3HxXkreEzZsP0q5dPZ58sjt9+4ae8sLKwYPZ/PbbruPJ3/LlO49fBKhc2Zd27eoTGVmL5ct3sXp1CgANGwbSt29z+vYNpWfPZsX2kTvfpKUd4dVXl/PSS8s4ePAI/fqF8thj3dza17Ykn30Wz5gx35CVlcOkST2pUaMS8+dv5ccft7Br1yEAmjatRs+eTbniimZcfnlTgoIq/6V1pqRksmZNCqtXJ7NmzR5Wr05m06YDWAsXX1yfF164issuc88oh4XNn7+FsWPnsGnTAUaNakXv3s358MMY5s3bDMCVV4Zwyy1tGTQovEz71G/adIBp09by0UcxbN2ahr+/LwMHhrN9exq//roTgG7dGjNyZCsGD444py7mlRd79x4+XgsYH59K8+Y1uO22dmfU4uBss9Yyduw3vP32Kl55pTd33tmxxLKZmceYMGExL720jMBAP559tie33HJmfVX378/i4YcX8PbbK6lbN4AXXriK666LLtUF9P37s/jsswRmzIhl0aJtWAtt2tTluuuiGDYsmiZN3NNy7q9Qsiduc/RoLuPGzeH999fwt7+14KOP/ubWHzf5+ZbU1MMkJWWwc2cGSUnphV5nkJOTx/+3d+fxUtZl48c/lywq7guaCSYmWOQChii5mymSoj2ZS9mmPj4uqIj2ZJsi5i9zCY0wM7VMHzWXMjIKMksUk0VFBRRERVI6rtcAACAASURBVAFJEBCV/Ry+vz9mwOPxzMw955wBzpzP+/Wa15n7nvu6v99zn+vMzHUv3/uAAzpx0EG7cNBBuzR5JLMFC5by3e8+wm23Pcsuu2zF8OH9OPbYbs3023zgrbfe549/fInhwycwefI8OnbswDnn9OKcc/Zr1tHY1pVZsxZz+ukjeOSRV+nXryu33nrcBnN6SXNbvToxa9Zifv3rZ7jppgksWrScz32uM9/5zuc47rhuZY+8W0pt7Wr+/OfpDBs2nkcffY2NN25Dv35dWbhwGVOnzmf+/A/2AHfo0K7OAB0fDNSx227bbFA3/K2EmprV3H33C1x55RhmzFjIvvvuxODBh3Lssd0affQ8pcSrry5aW/iNGzeHyZPn0bPnTnzxi13p168re+21Q9UdnV/j3XdX8ItfjOf66//NwoXL6Nt3dy6//FAOOKBTxdtevHg5F1zwN373u+fYb7+Pc+edX2KPPT64zjalxLRpC/jHP17lkUde45//fI3Fi1cAsM8+O64t/g4++BMFP6NWr07MmLHwI4XdW28tWbvMbrttQ48eH6NHjx3Zf/9OHHnkbut0h8qyZau46qrHueaasaxatZpddtmKb3+7B9/+do+KXbqxRkqJsWNnceedz3H//VPp1GlLTjttb049dc9WcTmCyldbu5oTT7yfP/3pJe6990ROOunDZ4GllPjDH15k4MBRzJ79Lmec0ZOrrz6ySSN5jh8/h3PP/QtPPz2XI47owi9+cUym2168994K/vSnadxzz2RGj84NJtSt23aceuqenHzyZ9bprTMaw2JPFZVS4uc/H8egQaP51Ke255BDdmHTTdux6aZty/650UbBnDnvNVjIzZq1mDlz3mPlytoPtd++fRs6ddqSzp23JKXcP/qaa292333bfOHXmYMO2oVu3bbL9EUspcSddz7PxRePZtGiZVx8cR8uu6zyN7tdcx3KDTeM4+GHp9Ou3UaceupeDBy4f4u4NjKlxN13v8B5542kpmY1Q4cezZln7lu1X37re//9ldx++7MMHfoUM2e+Q9eu23LxxX34xjf2afKgTQsWLOXWW5/hppsm8sYbi+nceUvOPXc/zjxz3w99ML799tK191PL3Vst93P27HfXLtO+fRu6ddtubRGY+zK8W1UMHFRTs5p77skVeS+/vJCePT/G4MGHcdxxjS/y9GHvvbeCm26awHXX/Zu3317KMcfszhVXHMZ++1XmSN9jj83km998iNmz3818m5ba2tU8/fTctcXf2LFvsGJFLe3abcQBB3Ti85/vQp8+nXnjjcX54u4/PPfcf1iyZBUAbdtuxGc+05GePXeiR48d6dlzJ/bee8cGrxtaH2bMWMicOe9y0EG7NPsOJak5LVu2iqOOuovx4+fwt799jcMP7wLkcnjAgJGMGvUK++yzIzfd9MVmuxautnY1t9zyNN///qMsWbKSQYP68KMfHfKR73DLlq1i5MiXuffeKTz88HSWL6+hc+ctOeWU3O04evQof4Ci9cViT+vE6NGvMHDg33j77aUsW1bDsmWrqK1tWk61a7cRO++cK+Q6d96KTp22yP/8YN7223f40J7VlStreeaZuTzxxBtrH2tOvdp++w4fKv569tzpIxd0v/TS25xzTm4UtD59OvGrXx27Xkajmz59AT//+Th+85tJLF26ikMP/QQDBx5QkaNFzWHBgqWcffZfeOCBqRx4YGfuuOMEPvnJ1nkNW03Nah58cCrXXvskTz89l+2378CAAftx3nm9y95jOWnSfxg2bBx33z2Z5ctrOOywXTn//N70779HWUfn3n13BS+99Pbam2uvuQ9bbvRePjRw0HHH7bHebrbcWLW1q7nnnslceeUYpk9fQI8eH2Pw4EPp3z/7sPcqz5IlKxk+fALXXDOWBQuWceyx3bjiisNKXmOT1YoVNfzoR//kuuueZPfdt+XOO7/E/vs37ijismWrGDt21tri7+mn31x7q4ottmifP1r3MXr2zP3s3r2jtxeSmsmiRcs4+ODf8MYbixk9+uv89a8v89OfjqV9+zb8+MdHcO65+1XkbJN585bw3e8+wm9/O4nOnbfkhhv6ctxx3XjkkVe5557JPPTQS7z33kp22GEzTjqpO6eeuhcHHNCpRV7+YLGn9WbVqtq1hV+Wn7W1q/n4x7fIF3NbscMOmzX5n27N6T11i79XXlkEwKabtmX//TutLf7Gjp3F1Vc/wWabteeaa44s+5zxSli0aBm33fYsw4aN5403FtOly9ZccMH+nH56zw3iSMya0zAGDPgrCxYs5corD+eSSz63QRak61pKiTFjXufaa5/kL395mU03bcu3vtWDQYP6FB3IYdWqWv74x5cYNmw8TzzxBh06tOO00/ZiwIDezb7jYdmyVUyc+ObagYNefnkhkLs+4fjj96B//z0aNfz6ulJbu5rf/34KQ4Y8xrRpC9h77x0ZPPhQjj/+U+v9f7e1eO+9FQwbNp7rrnuSRYuWc8IJn2Lw4EPZZ5/Gj975/PNvcdppf+CFF+Zx9tmf5brrjmrWMysWLlzGs8/OZdddt6ZLl23MFanCZs9+lz59blt7lslXv7oX1133hXVyiccTT7zBeeeN5Pnn32KzzdqxZMkqtt56E7785U9zyil7cthhu7b4Sxss9qR65s59j7FjZ60t/p599j+sXp3L/9NO25vrrz+KHXZo2kX9za2mZjUPPfQSN9zwFGPHzmKLLdpzxhk9Of/8/dfJ6HMNefnlBZx//l/XnoZxxx0nNOkLXjWbOnU+11//JHfd9QKrVtU2OJjLvHm5m+/efPNE5sx5j91224bzztuPb3+7xzob9GDatLcZMWIaI0ZM58knZ7F6dWLnnbegf/9c4Xf44btuMEc8xo2bzZln/pnJk+ex1147MHjwYZxwgkXe+rJ48XJ+/vNxXH/9v1m8eAUnntidyy8/tKwRIWtrV/Ozn/2bH/7wn2yzzSbcfvvx9OvXtYK9lrSuTJ06n8GD/8XZZ/fiiCO6rNO2a2pWc/PNE5k06T8cf/weHHXUJzeYz7LmYLEnlfDeeysYN24OW221ccWuO2lO48fP4cYbx3HffVOorV3N8cd/ioED9+eQQz6xTo7ALFu2ip/85Al++tOxbLJJW6688vCKnYZRbebOfY9hw8bzy19O5J13lnPggZ0588x9efTR1/j976ewcmUtRx31Sc4/vzfHHLP7ej1COn/+EkaOfJkRI6YzatQMlixZxeabt+fooz9J//570K9f1yZdSN9YS5as5Ic/fJQbbxzHzjtvyc9+dhRf/nJ3i7wNxDvvLGfo0H8zdOhTvP/+Sk466TNcfvmhJQc4mDnzHb75zYcYM+Z1/uu/Ps2vfnXseskvSWppNohiLyL6AjcCbYBbU0pXN7DMScBgIAHPpZS+WmydFntq7ebMeZebbprAzTc/zcKFy+jZ82NcdNEBnHzynhW7uezDD0/nggv+ymuvvcPXvrYX1167bk7DqDbvv7+S2257hqFDn+L11xez+ebt+da39mHAgN4fGmVwQ7F8eQ2PPvpa/qjfNObOfZ+NNgoOPLAzJ530GU4/vScdOjRtEJosHnnkVf77v//MzJnvcO65vfjJT47cIE5n1kctXLiM669/khtvHMfSpav46lf34rLLDqVbtw/fb3DNgFgDBowE4Be/6MfXv773BnvqsCRtaNZ7sRcRbYDpwBeA2cAE4NSU0tQ6y3QF7gOOSCktiogdUkrziq3XYk/KWbp0FXfd9Tw33PAUL774NjvttDnnnbcf//M/vZptz/jMme9w4YV/Y8SIaXTv3pHhw/tx2GG7Nsu6W7OamtWMGzebvfbascUULatXJ555Zu7a6/yef/4tdtxxM77znc9x9tm9KjJq7aJFy7jkktHcfvskunXbjltvPW6d3NtMTff220u57ronGTZsPMuX13DaaXvzox8dwu67b8vbby/l7LMf5sEHX+SQQz7BHXecsEHew0qSNmQbQrHXBxicUjo6P/09gJTST+oscw0wPaV0a9b1WuxJH7Z6dWL06FcYOvQpRo9+hU02acs3vrE3Awce0Oh7xKxYUcN11z3JVVc9zkYbBZdffigDBx5QcuhztR6PP/46Q4aM4ZFHXqVjxw5ccsnnOPfc/Zrtnpt/+MOLnHfeSObPX8L//u+BXHbZoWyySfVca9FazJu3hGuuGcvw4RNYtaqWk0/ek0cffY2FC5dx1VVHcNFFBziwkyQ1woZQ7J0I9E0pnZmf/jqwf0ppQJ1lHiJ39O9Acqd6Dk4p/a3Yei32pMKmTJnHDTc8xZ13Ps+KFbX07bs7gwYdwJFH7pb59Ki///0VBgz4K9OnL+DEE7szdOjRdOq0ZYV7rpbqySdnMWTIY4wa9QrbbbcpF1/ch/PO693oI5b/+c/7DBgwkgcffJGePT/Gbbf1bxH3m1Rxc+e+x09/Opabb55It27bcddd/8Xee6/729tIUrVo9mIvIg4CuqaUfhMRHYHNU0qvFVn+K8DR9Yq93iml8+ss8zCwCjgJ6AQ8DuyZUnqn3rrOAs4C2GWXXT77+uuvZ+qz1FrNn7+Em2+eyPDhE3jrrSXsuecODBy4P1/72t4Fj47Mnv0ugwaN4v77p9K167YMG3YMRx+9+zruuVqqceNmM2TIGEaOfJltttmEQYP6cP75vdlqq2w3pE4p8dvfTmLQoNEsW7aKK644jEGD+ng0ucosX15D+/ZtHFhHkpqoWYu9iLgc6AXskVLqFhEfB+5PKR1YJCbLaZw3A0+llH6bn/4HcGlKaUKh9XpkT8puxYoa7r13MkOHPsVzz71Fx44dOOecXpx77n7suOPmQO7+bjfc8BRXXPEYtbWJH/zgYL7znc9V1fDEWncmTnyTIUMe489/ns7WW2/CwIH7c+GFB7D11oWLvtdeW8RZZz3MI4+8ysEH78Ktt/b/yIAekiTpA81d7E0CegLPpJR65uc9n1Lau0hMW3KnaH4emENugJavppSm1FmmL7lBW74ZEdsDzwI9UkoLCq3XYk8qX0qJf/1rJkOHPsXDD0+nXbs2fPWre3H00Z/kxz8ew5Qp8znuuG7ceGNfunRZP/fvU3V59tm5DBkyhoceeoktt9yYCy/cn4EDD2DbbT+4d2Bt7Wp+8YvxfP/7j9KmTXDNNV/grLM+61EfSZJKaO5ib3xKqXdEPJNS2jciNgP+XazYy8f1A24gdz3e7SmlqyJiCDAxpTQichcRXQ/0BWqBq1JK9xZbp8We1DQvv7yAG28cx29+M4mlS1ex665b8/Of9+W44/ZY311TFXruuf/w4x8/zgMPTGWLLdpz/vm9ueiiPrz11vucccYIxo2bwxe/2JVf/vKLdO681fruriRJLUJzF3uXAF3J3UbhJ8DpwN0ppWFN7Wi5LPak5rFo0TKefHIWhx/eZZ3cK02t2+TJ8/jxj8dw331T6NChHStX1rLVVptw4419OfXUPb2/miRJZajEAC1fAI4CAhiVUvp707rYOBZ7ktRyTZ06n2uvfZKNN27DlVceTseOm63vLkmS1OI0W7GXvzn6qJTSkc3Vuaaw2JMkSZLUmmUt9kreyTSlVAssjQgvppAkSZKkFiLr2OrLgRci4u/AkjUzU0oXVKRXkiRJkqQmyVrs/SX/kCRJkiS1AJmKvZTSHRHRHuiWnzUtpbSqct2SJEmSJDVFpmIvIg4D7gBmkhuNs3NEfDOlNKZyXZMkSZIkNVbW0zivB45KKU0DiIhuwD3AZyvVMUmSJElS45UcjTOv3ZpCDyClNB3wLsySJEmStIHKemRvYkTcBtyZn/4a8HRluiRJkiRJaqqsxd45wHnABeSu2RsD3FSpTkmSJEmSmiZrsdcWuDGl9DOAiGgDbFyxXkmSJEmSmiTrNXv/ADatM70p8Ejzd0eSJEmS1ByyFnubpJTeXzORf96hMl2SJEmSJDVV1mJvSUTsu2YiInoByyrTJUmSJElSU2Ut9gYC90fE4xExBrgXGFAqKCL6RsS0iJgREZc28Pq3ImJ+REzKP84sr/uSJEmSpIYULfYiYr+I+FhKaQLwKeD3QA3wN+C1ErFtgOHAMUB34NSI6N7Aor9PKfXIP25tzC8hSZIkSfqwUkf2fgWszD/vA3yfXAG3CLilRGxvYEZK6dWU0kpyRwOPb0JfJUmSJEkZlSr22qSUFuafnwzcklJ6MKX0I2D3ErE7A7PqTM/Oz6vvyxHxfEQ8EBGdM/VakiRJklRUyWIvItbci+/zwKN1Xit1j75oYF6qN/1nYNeU0t7kbuVwR4MrijgrIiZGxMT58+eXaFaSJEmSVKrYuwd4LCL+RG70zccBImJ3YHGJ2NlA3SN1nYA36y6QUlqQUlqRn/w18NmGVpRSuiWl1Cul1Ktjx44lmpUkSZIkFT06l1K6KiL+AewEjE4prTkytxFwfol1TwC6RkQXYA5wCvDVugtExE4ppbn5yf7Ai2X2X5IkSZLUgFKnYpJSeqqBedMzxNVExABgFNAGuD2lNCUihgATU0ojgAsioj+5ET4XAt8qs/+SJEmSpAbEBwfrWoZevXqliRMnru9uSJIkSdJ6ERFPp5R6lVou603VJUmSJEktiMWeJEmSJFUhiz1JkiRJqkIWe5IkSZJUhSz2JEmSJKkKWexJkiRJUhWy2JMkSZKkKmSxJ0mSJElVyGJPkiRJkqqQxZ4kSZIkVSGLPUmSJEmqQhZ7kiRJklSFLPYkSZIkqQpZ7EmSJElSFbLYkyRJkqQqZLEnSZIkSVWoosVeRPSNiGkRMSMiLi2y3IkRkSKiVyX7I0mSJEmtRcWKvYhoAwwHjgG6A6dGRPcGltsCuAAYV6m+SJIkSVJrU8kje72BGSmlV1NKK4F7geMbWO5K4BpgeQX7IkmSJEmtSiWLvZ2BWXWmZ+fnrRURPYHOKaWHK9gPSZIkSWp1KlnsRQPz0toXIzYChgIXl1xRxFkRMTEiJs6fP78ZuyhJkiRJ1amSxd5soHOd6U7Am3WmtwD2BP4VETOBA4ARDQ3SklK6JaXUK6XUq2PHjhXssiRJkiRVh0oWexOArhHRJSLaA6cAI9a8mFJanFLaPqW0a0ppV+ApoH9KaWIF+yRJkiRJrULFir2UUg0wABgFvAjcl1KaEhFDIqJ/pdqVJEmSJEHbSq48pTQSGFlv3mUFlj2skn2RJEmSpNakojdVlyRJkiStHxZ7kiRJklSFLPYkSZIkqQpZ7EmSJElSFbLYkyRJkqQqZLEnSZIkSVXIYk+SJEmSqpDFniRJkiRVIYs9SZIkSapCFnuSJEmSVIUs9iRJkiSpClnsSZIkSVIVstiTJEmSpCpksSdJkiRJVchiT5IkSZKqkMWeJEmSJFWhihZ7EdE3IqZFxIyIuLSB18+OiBciYlJEPBER3SvZH0mSJElqLSpW7EVEG2A4cAzQHTi1gWLu7pTSXimlHsA1wM8q1R9JkiRJak0qeWSvNzAjpfRqSmklcC9wfN0FUkrv1pncDEgV7I8kSZIktRptK7junYFZdaZnA/vXXygizgMGAe2BIyrYH0mSJElqNSp5ZC8amPeRI3cppeEppU8C3wV+2OCKIs6KiIkRMXH+/PnN3E1JkiRJqj6VLPZmA53rTHcC3iyy/L3ACQ29kFK6JaXUK6XUq2PHjs3YRUmSJEmqTpUs9iYAXSOiS0S0B04BRtRdICK61pn8IvByBfsjSZIkSa1Gxa7ZSynVRMQAYBTQBrg9pTQlIoYAE1NKI4ABEXEksApYBHyzUv2RJEmSpNakkgO0kFIaCYysN++yOs8vrGT7kiRJktRaVfSm6pIkSZKk9cNiT5IkSZKqkMWeJEmSJFUhiz1JkiRJqkIWe5IkSZJUhSz2JEmSJKkKWexJkiRJUhWy2JMkSZKkKmSxJ0mSJElVyGJPkiRJkqqQxZ4kSZIkVSGLPUmSJEmqQhZ7kiRJklSFLPYkSZIkqQpZ7EmSJElSFbLYkyRJkqQqVNFiLyL6RsS0iJgREZc28PqgiJgaEc9HxD8i4hOV7I8kSZIktRYVK/Yiog0wHDgG6A6cGhHd6y32LNArpbQ38ABwTaX6I0mSJEmtSSWP7PUGZqSUXk0prQTuBY6vu0BK6Z8ppaX5yaeAThXsjyRJkiS1GpUs9nYGZtWZnp2fV8gZwF8beiEizoqIiRExcf78+c3YRUmSJEmqTpUs9qKBeanBBSNOA3oB1zb0ekrplpRSr5RSr44dOzZjFyVJkiSpOrWt4LpnA53rTHcC3qy/UEQcCfwAODSltKKC/ZEkSZKkVqOSR/YmAF0joktEtAdOAUbUXSAiegK/AvqnlOZVsC+SJEmS1KpUrNhLKdUAA4BRwIvAfSmlKRExJCL65xe7FtgcuD8iJkXEiAKrkyRJkiSVoZKncZJSGgmMrDfvsjrPj6xk+5IkSZLUWlX0puqSJEmSpPXDYk+SJEmSqpDFniRJkiRVIYs9SZIkSapCFnuSJEmSVIUs9iRJkiSpClnsSZIkSVIVstiTJEmSpCpksSdJkiRJVchiT5IkSZKqkMWeJEmSJFUhiz1JkiRJqkIWe5IkSZJUhSz2JEmSJKkKWexJkiRJUhWqaLEXEX0jYlpEzIiISxt4/ZCIeCYiaiLixEr2RZIkSZJak4oVexHRBhgOHAN0B06NiO71FnsD+BZwd6X6IUmSJEmtUdsKrrs3MCOl9CpARNwLHA9MXbNASmlm/rXVFeyHJEmSJLU6lTyNc2dgVp3p2fl5kiRJkqQKq2SxFw3MS41aUcRZETExIibOnz+/id2SJEmSpOpXyWJvNtC5znQn4M3GrCildEtKqVdKqVfHjh2bpXOSJEmSVM0qWexNALpGRJeIaA+cAoyoYHuSJEmSpLyKFXsppRpgADAKeBG4L6U0JSKGRER/gIjYLyJmA18BfhURUyrVH0mSJElqTSo5GicppZHAyHrzLqvzfAK50zslSZIkSc2oojdVlyRJkiStHxZ7kiRJklSFLPYkSZIkqQpZ7EmSJElSFbLYkyRJkqQqZLEnSZIkSVXIYk+SJEmSqpDFniRJkiRVIYs9SZIkSapCFnuSJEmSVIUs9iRJkiSpClnsSZIkSVIVstiTJEmSpCpksSdJkiRJVchiT5IkSZKqkMWeJEmSJFWhihZ7EdE3IqZFxIyIuLSB1zeOiN/nXx8XEbtWsj+SJEmS1FpUrNiLiDbAcOAYoDtwakR0r7fYGcCilNLuwFDgp5XqjyRJkiS1JpU8stcbmJFSejWltBK4Fzi+3jLHA3fknz8AfD4iooJ9kiRJkqRWoZLF3s7ArDrTs/PzGlwmpVQDLAa2q2CfJEmSJKlVaFvBdTd0hC41Yhki4izgrPzk+xExrYl9q4TtgbeNb3Ftt/b4ltz31h7fkvve2uNbct9be3xL7ntrj2/JfW/p8S25780RXymfyLRUSqkiD6APMKrO9PeA79VbZhTQJ/+8LbkNGZXqUyUfwETjW17brT2+Jfe9tce35L639viW3PfWHt+S+97a41ty31t6fEvue3PEr+9HJU/jnAB0jYguEdEeOAUYUW+ZEcA3889PBB5N+a0qSZIkSWq8ip3GmVKqiYgB5I7etQFuTylNiYgh5CrkEcBtwJ0RMQNYSK4glCRJkiQ1USWv2SOlNBIYWW/eZXWeLwe+Usk+rEO3GN8i227t8S257609viX3vbXHt+S+t/b4ltz31h7fkvve0uNbct+bI369Cs+alCRJkqTqU8lr9iRJkiRJ64nFXhNFxO0RMS8iJjcyvnNE/DMiXoyIKRFxYRmxm0TE+Ih4Lh97RSP70CYino2IhxsROzMiXoiISRExsRHxW0fEAxHxUn4b9Ckjdo98u2se70bEwDLbvyi/7SZHxD0RsUkZsRfm46ZkbbehfImIbSPi7xHxcv7nNmXEfiXf/uqI6NWItq/Nb/vnI+KPEbF1mfFX5mMnRcToiPh4OfF1XrskIlJEbF9m+4MjYk6dHOhXbvsRcX5ETMtvx2vKbP/3ddqeGRGTyojtERFPrfnfiYjeZba9T0T8O///9+eI2LJIfIPvM2XkXqH4kvlXJDZT7hWJz5R7heLrvF4094q0nyn3irWfJfeKtJ819wrFl8y/IrGZci8KfEZFbuC2cfm8+33kBnErJ35ARMwo9ncrEf9/+e0+OXL/W+3KjL8tP+/5yH1+bV5OfJ3Xh0XE+43o/28j4rU6f/8eZcRGRFwVEdPzf9cLymz78TrtvhkRD5UZ//mIeCYf/0RE7F5m/BH5+MkRcUdEFL0cKep9v8maewViM+VdkfhMeVckPlPeFYqvM79o3hVpv2TelYjPlHsFYjPlXZH4THlXJL6svNvgrO/hQFv6AzgE2BeY3Mj4nYB988+3AKYD3TPGBrB5/nk7YBxwQCP6MAi4G3i4EbEzge2bsP3uAM7MP28PbN3I9bQB/gN8ooyYnYHXgE3z0/cB38oYuycwGehA7trXR4CujckX4Brg0vzzS4GflhH7aWAP4F9Ar0a0fRTQNv/8p4XaLhK/ZZ3nFwA3lxOfn9+Z3EBOrxfLpQLtDwYuyfg3ayj+8PzfbuP89A7l9r/O69cDl5XR9mjgmPzzfsC/yuz7BODQ/PPTgSuLxDf4PlNG7hWKL5l/RWIz5V6R+Ey5Vyg+a+4VaT9T7hWJz5R7xfqfMfcKtV8y/4rEZso9CnxGkXuvPSU//2bgnDLjewK7UuLzp0h8v/xrAdzTiPbr5t7PyP8PZY3PT/cC7gTeb0T/fwucWCLvCsV+G/gdsFGJvCv5/QJ4EPhGme1PBz6dn38u8Nsy4j8HzAK65ecPAc4osR0+9P0ma+4ViM2Ud0XiM+VdkfhMeVcoPmveFWm/ZN6ViM+Ue4X6niXvirSdKe8aiid3YKysvNvQHh7Za6KU0hhyI4k2Nn5uSumZ/PP3gBfJFSFZYlNKac3emXb5R1kXYUZEJ+CLMLKOLgAAC5dJREFUwK3lxDWHyO0NPoTcqKyklFamlN5p5Oo+D7ySUnq9zLi2wKb5vTQdgDczxn0aeCqltDSlVAM8BnypVFCBfDmeXNFL/ucJWWNTSi+mlKZl6XCB+NH5/gM8BXQqM/7dOpObUST/ivyvDAX+t1hsifhMCsSfA1ydUlqRX2ZeY9qPiABOIvcBnjU2AWuOiGxFkdwrEL8HMCb//O/Al4vEF3qfyZp7DcZnyb8isZlyr0h8ptwr8R5bMvea8h5dIj5T7pVqP0PuFYovmX9FYjPlXpHPqCOAB/Lzi+Vdg/EppWdTSjMbiskYPzL/WgLGUzj3CsW/C2u3/aYUzr0G4yOiDXAtudwru/+lfu8SsecAQ1JKq/PLFcq7om1HxBbk/o4NHmEpEp/pfa9AfC2wIqU0PT+/6Pte/e83+b9Xptxr6LtR1rwrEp8p74rEZ8q7QvFZ865QfDkKxGfKvWJtl8q7IvGZP28biN+OMvJuQ2SxtwGJiF3J7TkaV0ZMm8idvjMP+HtKKXNs3g3k/vFXlxm3RgJGR8TTEXFWmbG7AfOB3+QPl98aEZs1sh+nUODLTiEppTnAdcAbwFxgcUppdMbwycAhEbFdRHQgt8eucznt17FjSmluvk9zgR0auZ6mOh34a7lB+dMyZgFfAy4rtXy92P7AnJTSc+W2W8eA/Gktt0eB0xCL6AYcnD+t57GI2K+RfTgYeCul9HIZMQOBa/Pb7jrge2W2ORnon3/+FTLmX733mbJzrzHvUxliM+Ve/fhyc69ufGNyr4H+l5V79eLLzr0C2y9z7tWLLyv/6sVmzr36n1HAK8A7dQr92RQpnpv6GVcsPnKn0X0d+Fu58RHxG3Jnk3wKGFZm/ABgxJr/vUb2/6p87g2NiI3LiP0kcHLkTt39a0R0bUTbkNu5+Y96O12yxJ8JjIyI2eS2/dVZ48kVSO3ig1PGT6T4+1797zfbkT33mvrdqGB8lrwrFJ817wrEZ867Iv0vmXdF4rPmXrFtXzLvCsRnzrsG4t+mvLzb4FjsbSAid+71g8DAEkn8ISml2pRSD3J7iHpHxJ5ltHksMC+l9HTZHf7AgSmlfYFjgPMi4pAyYtuSOzXtlymlnsAScqeSlSVy59z3B+4vM24bckc2ugAfBzaLiNOyxKaUXiR36tnfyb1hPwfUFA3agEXED8j1///KjU0p/SCl1DkfO6CMNjsAP6DMArGeX5L7AOlBrmC/vsz4tsA25E4v+g5wX36vablOpcydDeT2cl6U33YXkT/CXYbTyf3PPU3uFLuVpQIa+z7THPGFYrPmXkPx5eRe3fh8e2XlXgPtl5V7DcSXlXtFtn2m3GsgPnP+NRCbOffqf0aROyviI4tljS/nMy5D/E3AmJTS4+XGp5S+Te5z40Xg5DLiDyFXIBf7ol6q/e+R+7K/H7At8N0yYjcGlqeUegG/Bm4v93fPK5l3BeIvAvqllDoBvyF3OmKmeOAz5HbsDo2I8cB7FPjcLfD9pqH/r4/kXlO/G2WIL5p3xeKz5F1D8ZG7pjlT3hVpP1PeFYkvmXsZtl3RvCsSnynvGorPH4nNlHcbrLQBnEva0h/kzuFu1DV7+fh25K4bGdTEflxOxuuX8sv/hNyerZnk9hQtBe5qQvuDy2z/Y8DMOtMHA39pRLvHA6MbEfcV4LY6098Abmrk7/7/gHMbky/ANGCn/POdgGnl5hoZrtkrFA98E/g30KEx8XVe+0Sp/4O68cBe5PbYzsw/asgdZf1YI9sv+X/YwLb/G3BYnelXgI5lbr+2wFtApzLbXgxrb38TwLtN2PbdgPEl4j/yPlNm7hV8nyqVf4Vis+Zesbaz5F79+HJzL0P7RXOvwLbPnHtFtl/W3Guo/Uz5l+F3L5l7dZa9nFxh+zYfXK/ZBxhVRvwldaZnUsY143Xj888fIn/9UGPaz887lIzXu+fjLyf3ebsm91YDM5rQ/mFZ2l8TC7wE7Frn7764EdtuO2ABsEmZ2+475C63WDNvF2BqE373o4D7Cizf0Peb/8uSewVi76rzetG8KxafJe9KtV8q7wrEL8qadxnbL5h3heKz5F6JbVcy7wrE/yVr3mX83Qvm3Yb6WO8dqIYHTSj28gn/O+CGRsR2JD+gCbnztx8Hjm1kPwr+4xaJ2QzYos7zJ4G+Za7jcWCP/PPBwLWN6Pu9wLcbEbc/MIXctXpB7vz988uI3yH/c5f8m9g2jckXcufQ1x0k45pyc41GFntAX2AqRQqcEvFd6zw/H3ignPh6r82kxBe3Btrfqc7zi4B7y4w/m9w1BJD70jqL/BfgrP3Pb8PHGrHtXiT/ZZ/cNadPlxm/Jv82IvcecnqR2AbfZ7LmXqH4LPlXpO1MuVckPlPulep7qdwr0n6m3CsSnyn3ivU/S+4Vab9k/hWJzZR7FPiMIncWRt1BMhrcUVYoPsvfrUT7Z5L7vNq0xLZrKP44YPc62+c64LrG9D8/v9gALYX6v1Od9m8gd+1n1tir1/y9yH3uTyi37/ncvaMR2+5YcsXWmoEuzgAeLDN+Te5tDPwDOKJYP+r8nmsG6siUew3FZs27Im1nyruG4vN/60x5V6r/pfKuSP9L5l2J+Ey5V6jvWfKuwLZrmzXvivS97LzbkB7rvQMt/UHucPJcYBW5vQFljdADHETuNILngUn5R7+MsXsDz+ZjJ1NgNLaM62rwDaFEzG7kTl98jlzR9INGtNsDmJj/HR4iY8FUJ74DuT09WzXy976CXKE2mdwIVRuXEfs4uS+rzwGfb2y+kNtb9Q/g5fzPbcuI/VL++Qpye/gL7iEvED+D3JfMNblXbDTNhuIfzG+754E/kxs4o1H/K5T+4tZQ+3cCL+TbH0GdL+AZ49uT2+M4GXim2Bt4of6TG6Hs7Eb83Q8Cns7nzzjgs2XGX0huhLHp5D5EixWpDb7PlJF7heJL5l+R2Ey5VyQ+U+4Vis+ae0Xaz5R7ReIz5V6x/mfMvULtl8y/IrGZco8Cn1HkPjvG53Pgfgq87xaJvyCfdzXkBlq4tcz4GnJHUtf8ToVGMv1IPLkCd2z+bz+Z3NGiLctpv94yxYq9Qv1/tE77d5EftTJj7NbkjnS8QO6o+j7l9p3czp2iO3aLtP+lfNvP5dezW5nx15LbUTGN3GnFBftQZ12H8cGX9ky5VyA2U94Vic+Udw3Fl5N3hdrPmndF+l8y70rEZ8q9Qn3PkndF2s6Ud0Xiy867Demx5hQOSZIkSVIVcYAWSZIkSapCFnuSJEmSVIUs9iRJkiSpClnsSZIkSVIVstiTJEmSpCpksSdJapUiojYiJkXElIh4LiIGRUSjPxcj4vt1nu8aEZObp6eSJDWOxZ4kqbVallLqkVL6DPAFcveQu7wJ6/t+6UUkSVp3LPYkSa1eSmkecBYwIHLaRMS1ETEhIp6PiP8BiIjDImJMRPwxIqZGxM0RsVFEXA1smj9S+H/51baJiF/njxyOjohN19fvJ0lqnSz2JEkCUkqvkvtc3AE4A1icUtoP2A/474jokl+0N3AxsBfwSeC/UkqX8sGRwq/ll+sKDM8fOXwH+PK6+20kSbLYkySprsj/PAr4RkRMAsYB25Er3gDGp5ReTSnVAvcABxVY12sppUn5508Du1amy5IkNazt+u6AJEkbgojYDagF5pEr+s5PKY2qt8xhQKoXWn96jRV1ntcCnsYpSVqnPLInSWr1IqIjcDPwi5RSAkYB50REu/zr3SJis/zivSOiS37kzpOBJ/LzV61ZXpKkDYFH9iRJrdWm+dM02wE1wJ3Az/Kv3UrutMtnIiKA+cAJ+df+DVxN7pq9McAf8/NvAZ6PiGeAH6yLX0CSpGIitwNTkiSVkj+N85KU0rHruy+SJJXiaZySJEmSVIU8sidJkiRJVcgje5IkSZJUhSz2JEmSJKkKWexJkiRJUhWy2JMkSZKkKmSxJ0mSJElVyGJPkiRJkqrQ/wdUavcpieFCbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_validation_curve(train_scores, validation_scores, param_range, xlabel=\"X\", title=\"Curva de complejidad\"):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.ylim(0.0,1.1)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(param_range)\n",
    "    plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
    "    \n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\")\n",
    "    \n",
    "    plt.plot(param_range, validation_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "    \n",
    "    marker_line_width = 0.005\n",
    "    plt.axhspan(0.8 - marker_line_width/2, 0.8 + marker_line_width/2, alpha=0.5)\n",
    "    \n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(1.0, 1.0))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#    None\tgini\t2\tauto\t0.6746\t0.6997\n",
    "# \"Seleccionamos el que consideramos uno de los mejores arboles obtenidos en GridSearch del ej 3\"\n",
    "depths_to_try = np.arange(1, 50, 1)\n",
    "decision_tree_train_scores, decision_tree_validation_scores = \\\n",
    "    validation_curve( \\\n",
    "        DecisionTreeClassifier(max_features=\"auto\", criterion=\"gini\"), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        \"max_depth\", \\\n",
    "        depths_to_try, \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score) \\\n",
    "    )\n",
    "\n",
    "# {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':sp.stats.expon(scale=.1),'C': sp.stats.expon(scale=10)}\n",
    "# 0.0001\trbf\t0.7679\t0.8707\n",
    "cs_to_try = np.arange(1,100,2)\n",
    "svm_train_scores, svm_validation_scores = \\\n",
    "    validation_curve( \\\n",
    "        SVC(gamma=0.0001, kernel='rbf'), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        \"C\", \\\n",
    "        cs_to_try, \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score), \\\n",
    "        n_jobs = 1 \\\n",
    "    )\n",
    "\n",
    "plot_validation_curve(decision_tree_train_scores, decision_tree_validation_scores, depths_to_try, xlabel=\"Depth\", title=\"Curva de Complejidad con Arboles de Aprendizaje\")\n",
    "plot_validation_curve(svm_train_scores, svm_validation_scores, cs_to_try, xlabel=\"C\", title=\"Curva de Complejidad con SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Aprendizaje\n",
    "El Depth claramente aumenta la complejidad de los árboles de manera muy rápida, lo cual lleva a modelos con un sesgo cada vez menor pero en general pareciera tener una varianza bastante alta a partir de ciertas alturas (alrededor de 5), algo que parece correlacionado con el grado de overfitting que presenta el árbol.\n",
    "\n",
    "No parece haber una curva tan definida en la que se pueda conseguir un tradeoff útil entre sesgo y varianza basados en el Depth, savlo quizás en las alturas más pequeñas.\n",
    "\n",
    "### SVM\n",
    "\n",
    "El C parece tener una influencia que escala de manera menos brusca en el overfitting y en la varianza presentada por los modelos.\n",
    "\n",
    "Sin embargo, está claro que el sesgo va disminuyendo a medida que se aumenta el C y la varianza va aumentando, debido a que estamos condiciando al algoritmo a darle una mayor importancia a tener en cuenta a minions que con menor C se pueden considerar ignorables.\n",
    "\n",
    "Pareciera que la zona de los mejores Cs antes de comenzar a caer en la varianza aumentada sería la zona de los Cs entre 9 y 15. En particular C = 11 se ve como la mejor opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(train_scores, validation_scores, param_range, title=\"Curva de aprendizaje\"):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.ylim(0.0,1.1)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"n\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    \n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\")\n",
    "    plt.plot(param_range, validation_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "    \n",
    "    marker_line_width = 0.005\n",
    "    plt.axhspan(0.8 - marker_line_width/2, 0.8 + marker_line_width/2, alpha=0.5)\n",
    "    \n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(1.0, 1.0))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#    None\tgini\t2\tauto\t0.6746\t0.6997\n",
    "# \"Seleccionamos el que consideramos uno de los mejores arboles obtenidos en GridSearch del ej 3\"\n",
    "dtree_train_sizes_abs, decision_tree_train_scores, decision_tree_validation_scores = \\\n",
    "    learning_curve( \\\n",
    "        DecisionTreeClassifier(max_features=\"auto\", criterion=\"gini\", max_depth=3), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        train_sizes = np.arange(0.1, 1., 0.02), \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score) \\\n",
    "    )\n",
    "\n",
    "# {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':sp.stats.expon(scale=.1),'C': sp.stats.expon(scale=10)}\n",
    "# 0.0001\trbf\t0.7679\t0.8707\n",
    "svm_train_sizes_abs, svm_train_scores, svm_validation_scores = \\\n",
    "    learning_curve( \\\n",
    "        SVC(gamma=0.0001, kernel='rbf', C=3), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        train_sizes = np.arange(0.1, 1., 0.02), \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score), \\\n",
    "    )\n",
    "\n",
    "plot_learning_curve(decision_tree_train_scores, decision_tree_validation_scores, dtree_train_sizes_abs, title=\"Curva de Aprendizaje con Arboles de Decisión\")\n",
    "plot_learning_curve(svm_train_scores, svm_validation_scores, svm_train_sizes_abs, title=\"Curva de Aprendizaje con SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Decisión\n",
    "\n",
    "En los árboles de decisión parece que hay una tendencia pronunciada a reducir la varianza, pero el sesgo se mantiene bastante malo a lo largo de todos los n's analizados y no parece tener una tendencia a mejorar con mayores cantidades de datos de entrenamiento, por lo que no consideramos que más datos ayudarían a algo que no sea reducir la varianza (cosa que no ayuda cuando no hay esperanza de mejorar el sesgo).\n",
    "\n",
    "### SVM\n",
    "\n",
    "Inicialmente el sesgo de svm es bastante grande y con cantidades menores a 130 aproximadamente es muy poco confiable.\n",
    "\n",
    "En base al análisis de las curvas de aprendizaje pareciera que SVM probablemente se beneficiaría de tener más datos debido a que los datos de validación presentan una tendencia a crecer en su scoring.\n",
    "\n",
    "Presenta una varianza bastante pequeña inicialmente pero la introducción de más datos parece afectar negativamente este valor, por lo que habría que considerar la posibilidad de limitar en un cierto punto la cantidad de datos de entrenamiento para evitar ganar demasiada varianza (si es que esta tendencia se mantiene)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para Random Forest\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>0.8749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7328</td>\n",
       "      <td>0.8725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>entropy</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.7518</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entropy</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7411</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>entropy</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.7208</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gini</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.7208</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.7163</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  mean_score_validation  mean_score_training\n",
       "7    entropy        3.0                 0.7404               0.8749\n",
       "1       gini        3.0                 0.7328               0.8725\n",
       "10   entropy       30.0                 0.7518               1.0000\n",
       "6    entropy        NaN                 0.7514               1.0000\n",
       "9    entropy       15.0                 0.7483               1.0000\n",
       "0       gini        NaN                 0.7469               1.0000\n",
       "2       gini        8.0                 0.7411               0.9994\n",
       "11   entropy       50.0                 0.7366               1.0000\n",
       "8    entropy        8.0                 0.7345               1.0000\n",
       "4       gini       30.0                 0.7208               1.0000\n",
       "5       gini       50.0                 0.7208               1.0000\n",
       "3       gini       15.0                 0.7163               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_parameters = [{'max_depth': [None, 3, 8, 15, 30, 50] , 'criterion': ['gini', 'entropy']}]\n",
    "grid_forest_result = doSearch('grid', RandomForestClassifier(n_estimators=200), forest_parameters)\n",
    "top_resultados(grid_forest_result, \"Random Forest\")\n",
    "\n",
    "# Seleccionamos max_depth = 3\n",
    "# porque una depth mayor parecía invariablemente llevar a overfitting en todos los casos\n",
    "\n",
    "max_features_to_try = np.arange(1, 200, 4)\n",
    "random_forest_train_scores, random_forest_validation_scores = \\\n",
    "    validation_curve( \\\n",
    "        RandomForestClassifier(n_estimators=200, criterion=\"gini\", max_depth=3), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        \"max_features\", \\\n",
    "        max_features_to_try, \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score) \\\n",
    "    )\n",
    "\n",
    "plot_validation_curve(random_forest_train_scores, random_forest_validation_scores, max_features_to_try, xlabel=\"Max Features\", title=\"Curva de Complejidad con Random Forest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max features\n",
    "\n",
    "#### Explicación \n",
    "\n",
    "Max features determina la cantidad de atributos que deben observar los árboles cuando se intenta determinar cuál es la mejor manera de separar los valores en cada nodo según los valores de sus atributos.\n",
    "\n",
    "Esto podría resultar beneficioso en el uso de muchos árboles al mismo tiempo para poder analizar los objetos desde diferentes \"perspectivas\" y luego proceder a votar. De otra manera podríamos terminar con muchos árboles parecidos sin que ninguno de estos pueda contribuir nada muy distinto a la hora de clasificar un minion.\n",
    "\n",
    "#### Análisis\n",
    "\n",
    "La curva de complejidad de Random Forest no parece presentar muy buenos valores para límites muy grandes, pareciera que mantener muchos árboles de tamaño pequeño que miran pocas features es la mejor estrategia a juzgar por los datos que se tienen.\n",
    "\n",
    "En particular alrededor de las 15 max_features por árbol se presenta la mejor opción.\n",
    "\n",
    "Estos resultados parecen validar la opinión antes dada de que tener muchos árboles con distintas perspectivas provee una mejor votación a la hora de clasificar cada minion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_train_sizes_abs, random_forest_train_scores, random_forest_validation_scores = \\\n",
    "    learning_curve( \\\n",
    "        RandomForestClassifier(n_estimators=200, criterion=\"gini\", max_depth=3, max_features=15), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        train_sizes = np.arange(0.1, 1., 0.02), \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score), \\\n",
    "    )\n",
    "\n",
    "plot_learning_curve(random_forest_train_scores, random_forest_validation_scores, random_forest_train_sizes_abs, title=\"Curva de Aprendizaje con Random Forest con Depth bajo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados parecen bastante prometedores, en particular, pareciera que se consiguió un sesgo relativamente bueno desde el principio.\n",
    "\n",
    "Sin embargo, la varianza parece reducirse bastante lentamente, aunque se podría probar con más datos para ver si la tendencia a reducir la varianza se dibuja más pronunciadamente con otro entrenamiento con mayor experiencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  n_neighbors p weights mean_score_validation mean_score_training\n",
    "#  71 2 uniform 0.7674 0.7627\n",
    "kneighbors = KNeighborsClassifier(n_neighbors=71, p=2, weights=\"uniform\")\n",
    "\n",
    "X_eval_np = np.array(X_eval)\n",
    "y_eval_np = np.array(y_eval).ravel()\n",
    "\n",
    "kneighbors.fit(X_dev_np, y_dev_np)\n",
    "# kneighbors.fit(X_eval_np, y_eval_np)\n",
    "# lda.fit(X_eval_np, y_eval_np)\n",
    "\n",
    "y_prediction_knn = kneighbors.predict(X_eval_np)\n",
    "print(\"Scoring esperado para la competencia: \", roc_auc_score(y_eval_np, y_prediction_knn))\n",
    "\n",
    "kneighbors_competition = KNeighborsClassifier(n_neighbors=71, p=2, weights=\"uniform\")\n",
    "kneighbors_competition.fit(np.array(X), np.array(y).ravel())\n",
    "\n",
    "prediction = pd.DataFrame(kneighbors_competition.predict(X_competencia))\n",
    "prediction.columns = ['output']\n",
    "prediction.to_csv('y_competencia.csv', encoding='utf-8', index_label=\"index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
