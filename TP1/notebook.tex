
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{TP1}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Trabajo Práctico 1}\label{trabajo-pruxe1ctico-1}

\subsubsection{Clasificación sobre datos
simulados.}\label{clasificaciuxf3n-sobre-datos-simulados.}

\subsection{Introducción}\label{introducciuxf3n}

Para este trabajo, hemos creado una función generadora de minions. Sobre
cada minion, hemos medido 200 características que representan
habilidades que poseen en distintas tareas (relacionadas al Mal).

El doctor Nefario ha ideado una fórmula para determinar si un minion es
o no apto para concretar su plan para conquistar el mundo. De esta
manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido
dicha fórmula y necesita seguir decidiendo si nuevos minions son o no
aptos para su macabro plan.

Es por esto que nuestro objetivo será construir clasificadores que
estimen lo mejor posible la probabilidad de que nuevos minions sean o no
aptos para concretar el plan de conquista y así facilitarle las cosas al
doctor Nefario.

Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que
sobreestiman sus resultados, decidió guardarse varias etiquetas extra
que no compartirá con nadie, y que luego utilizará para elegir al mejor
equipo, al cual contratará para (de una vez por todas) conquistar el
mundo.

En concreto:

Tendrán disponible una matriz de datos \(X\) de \(500\) filas en donde
cada fila \(x^{(i)}\) representa un vector de \(200\) características de
cada instancia. Es decir,
\(\textbf{x}^{(i)} = x_1^{(i)}, \dots, x_{200}^{(i)}\) con \(i\) entre
\(1\) y \(500\). Además, tendrán y, un vector de \(500\) posiciones con
dos posibles valores: \(True\) y \(False\).

Por otra parte, tendrán disponibles más instancias de evaluación
\(X_{competencia}\) sin las respectivas etiquetas que utilizaremos para
evaluar sus resultados.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{} PREAMBULOS}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{o}{\PYZpc{}}\PY{k}{reload\PYZus{}ext} autoreload
        \PY{o}{\PYZpc{}}\PY{k}{autoreload}
        
        
        \PY{n}{SEED} \PY{o}{=} \PY{l+m+mi}{1234}
        
        \PY{k+kn}{import} \PY{n+nn}{warnings}
        \PY{n}{warnings}\PY{o}{.}\PY{n}{simplefilter}\PY{p}{(}\PY{n}{action}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ignore}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{category}\PY{o}{=}\PY{n+ne}{FutureWarning}\PY{p}{)}
        \PY{k+kn}{from} \PY{n+nn}{IPython}\PY{n+nn}{.}\PY{n+nn}{display} \PY{k}{import} \PY{n}{display}\PY{p}{,} \PY{n}{HTML}
        \PY{k+kn}{from} \PY{n+nn}{time} \PY{k}{import} \PY{n}{time}
        
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{numpy}\PY{n+nn}{.}\PY{n+nn}{ma} \PY{k}{as} \PY{n+nn}{ma}
        \PY{n}{np}\PY{o}{.}\PY{n}{set\PYZus{}printoptions}\PY{p}{(}\PY{n}{precision}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{n}{SEED}\PY{p}{)}
        
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as}  \PY{n+nn}{pd}
        \PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{display.max\PYZus{}rows}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
        \PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{display.max\PYZus{}columns}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{15}\PY{p}{)}
        
        \PY{n}{pd}\PY{o}{.}\PY{n}{set\PYZus{}option}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{precision}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
        
        \PY{k+kn}{import} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble}
        \PY{k+kn}{import} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes}
        \PY{k+kn}{import} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm}
        
        \PY{k+kn}{import} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection}
        \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{randint} \PY{k}{as} \PY{n}{sp\PYZus{}randint}
        
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{tree}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{cross\PYZus{}val\PYZus{}score} 
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{KFold}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{validation\PYZus{}curve}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{learning\PYZus{}curve}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{accuracy\PYZus{}score}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{roc\PYZus{}auc\PYZus{}score}
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{svm}
        
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{neighbors} \PY{k}{import} \PY{n}{KNeighborsClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{discriminant\PYZus{}analysis} \PY{k}{import} \PY{n}{LinearDiscriminantAnalysis}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k}{import} \PY{n}{DecisionTreeClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes} \PY{k}{import} \PY{n}{GaussianNB}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{svm} \PY{k}{import} \PY{n}{LinearSVC}\PY{p}{,} \PY{n}{SVC}
        
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{GridSearchCV}\PY{p}{,} \PY{n}{RandomizedSearchCV}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes} \PY{k}{import} \PY{n}{GaussianNB}\PY{p}{,} \PY{n}{MultinomialNB}
        \PY{k+kn}{import} \PY{n+nn}{scipy} \PY{k}{as} \PY{n+nn}{sp}
        \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{expon}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{pipeline} \PY{k}{import} \PY{n}{Pipeline}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
        
        \PY{k+kn}{from} \PY{n+nn}{math} \PY{k}{import} \PY{n}{log}
        
        \PY{k+kn}{from} \PY{n+nn}{collections} \PY{k}{import} \PY{n}{Counter}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{c+c1}{\PYZsh{} Carga de datos}
        \PY{n}{X} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{X.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{index\PYZus{}col}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{index}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{y} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{index\PYZus{}col}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{index}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{dtype}\PY{o}{=}\PY{n+nb}{int}\PY{p}{)}  \PY{c+c1}{\PYZsh{} Cargamos los valores booleanos (True y False)}
                                                                \PY{c+c1}{\PYZsh{} como números (1 y 0) para facilitar el manejo luego. }
        
        \PY{n}{X\PYZus{}competencia} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{X\PYZus{}competencia1.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{index\PYZus{}col}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{index}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{y\PYZus{}competencia\PYZus{}ejemplo} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{y\PYZus{}competencia\PYZus{}ejemplo.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{index\PYZus{}col}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{index}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{display}\PY{p}{(}\PY{n}{X}\PY{p}{)}
        \PY{n}{display}\PY{p}{(}\PY{n}{y}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Descomentar si quieren ver los datos para la competencia:}
        \PY{c+c1}{\PYZsh{} display(X\PYZus{}competencia) }
        \PY{c+c1}{\PYZsh{} display(y\PYZus{}competencia\PYZus{}ejemplo)}
\end{Verbatim}


    
    \begin{verbatim}
            0       1       2       3       4       5       6   ...       193  \
index                                                           ...             
0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   
1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   
2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   
3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   
4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   
...       ...     ...     ...     ...     ...     ...     ...   ...       ...   
495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   
496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   
497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   
498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   
499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   

          194     195     196     197     198     199  
index                                                  
0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  
1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  
2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  
3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  
4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  
...       ...     ...     ...     ...     ...     ...  
495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  
496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  
497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  
498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  
499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  

[500 rows x 200 columns]
    \end{verbatim}

    
    
    \begin{verbatim}
       output
index        
0           0
1           0
2           0
3           0
4           1
...       ...
495         1
496         0
497         1
498         0
499         0

[500 rows x 1 columns]
    \end{verbatim}

    
    \subsection{Ejercicio 1}\label{ejercicio-1}

\subsubsection{Separación de datos}\label{separaciuxf3n-de-datos}

Contarán con una cantidad limitada de datos, por lo cual es importante
tomar una buena decisión en el momento de empezar a utilizarlos. En este
punto pedimos que evalúen cómo separar sus datos para desarrollo y para
evaluación tomando en cuenta la competencia.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{c+c1}{\PYZsh{} EJERCICIO 1. }
        
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{1234}\PY{p}{)}
        
        
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        \PY{c+c1}{\PYZsh{}\PYZsh{} AQUI VA SU CODIGO}
        
        \PY{n}{X\PYZus{}dev}\PY{p}{,} \PY{n}{X\PYZus{}eval}\PY{p}{,} \PY{n}{y\PYZus{}dev}\PY{p}{,} \PY{n}{y\PYZus{}eval} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size} \PY{o}{=} \PY{l+m+mf}{0.1}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Objetivo: variables X\PYZus{}dev, X\PYZus{}eval, y\PYZus{}dev e y\PYZus{}eval asignadas}
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        
        \PY{c+c1}{\PYZsh{} print(\PYZdq{}X\PYZus{}dev: \PYZob{}\PYZcb{}, y\PYZus{}dev: \PYZob{}\PYZcb{} para desarrollo\PYZdq{}.format(X\PYZus{}dev.shape, y\PYZus{}dev.shape))}
        \PY{c+c1}{\PYZsh{} print(\PYZdq{}X\PYZus{}eval: \PYZob{}\PYZcb{}, y\PYZus{}eval: \PYZob{}\PYZcb{} para evaluación\PYZdq{}.format(X\PYZus{}eval.shape, y\PYZus{}eval.shape))}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{y\PYZus{}dev}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} muestra un histograma para la distribución de y.}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_4_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{Ejercicio 2}\label{ejercicio-2}

\subsubsection{Construcción de
modelos}\label{construcciuxf3n-de-modelos}

Para este punto, la tarea consiste en construir y evaluar modelos de
tipo árbol de decisión, de manera de obtener una estimación realista de
la performance de los mismos.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Entrenar un árbol de decisión con altura máxima 3 y el resto de los
  hiperparámetros en default.
\item
  Estimar la performance del modelo utilizando K-fold cross validation
  con K = 5, con las métricas ``Accuracy'' y ``ROC AUC''. Para ello, se
  pide medir la performance en cada partición tanto sobre el fold de
  validación como sobre los folds de entrenamiento. Luego, completar la
  primera tabla.
\item
  Entrenar árboles de decisión para cada una de las siguientes
  combinaciones y completar la segunda tabla.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\textbf{EJERCICIO EXTRA: Usar la implementación de árboles de decisión
que realizaron para la guía de ejercicios de la materia. Adaptarla para
que cumpla con la interfaz requerida por sklearn, asegurarse de que
funcione con variables continuas y reproducir las tablas anteriores. }

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{accuracies\PYZus{}training} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{n}{accuracies\PYZus{}validation} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{n}{aucs\PYZus{}training} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{n}{aucs\PYZus{}validation} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{} Puede serles de utilidad tener a X\PYZus{}dev e y\PYZus{}dev como matrices de numpy directamente:}
        \PY{n}{X\PYZus{}dev\PYZus{}np} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{X\PYZus{}dev}\PY{p}{)}
        \PY{n}{y\PYZus{}dev\PYZus{}np} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{y\PYZus{}dev}\PY{p}{)}\PY{o}{.}\PY{n}{ravel}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        \PY{k}{def} \PY{n+nf}{get\PYZus{}scores}\PY{p}{(}\PY{n}{train\PYZus{}indexes}\PY{p}{,} \PY{n}{test\PYZus{}indexes}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}criterion}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{n}{accuracy\PYZus{}score}\PY{p}{,} \PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{]}\PY{p}{)}\PY{p}{:}
            \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{[}\PY{n}{train\PYZus{}indexes}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{[}\PY{n}{test\PYZus{}indexes}\PY{p}{]}
            \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{[}\PY{n}{train\PYZus{}indexes}\PY{p}{]}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{[}\PY{n}{test\PYZus{}indexes}\PY{p}{]}
        
            \PY{n}{iteration\PYZus{}classifier} \PY{o}{=} \PY{n}{tree}\PY{o}{.}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{n}{max\PYZus{}depth}\PY{p}{,} \PY{n}{criterion}\PY{o}{=}\PY{n}{decision\PYZus{}tree\PYZus{}criterion}\PY{p}{)}
            \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
            
            \PY{n}{metrics\PYZus{}scores} \PY{o}{=} \PY{p}{[}\PY{p}{]}
            
            \PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
                \PY{k}{if} \PY{n}{metric} \PY{o}{==} \PY{n}{accuracy\PYZus{}score}\PY{p}{:}
                    \PY{n}{y\PYZus{}test\PYZus{}prediction} \PY{o}{=} \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
                    \PY{n}{metrics\PYZus{}scores}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}prediction}\PY{p}{)}\PY{p}{)}
        
                    \PY{n}{y\PYZus{}train\PYZus{}prediction} \PY{o}{=} \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
                    \PY{n}{metrics\PYZus{}scores}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}prediction}\PY{p}{)}\PY{p}{)}
                \PY{k}{elif} \PY{n}{metric} \PY{o}{==} \PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{:}
                    \PY{c+c1}{\PYZsh{}Devuelve un array con la probabilidad de la clase 0 y la clase 1.}
                    \PY{c+c1}{\PYZsh{}roc\PYZus{}auc\PYZus{}score pide solo la probobabilidad de la clase \PYZdq{}positiva\PYZdq{}, asi que le paso el indice 1}
                    \PY{n}{y\PYZus{}test\PYZus{}proba\PYZus{}prediction} \PY{o}{=} \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
                    \PY{n}{metrics\PYZus{}scores}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}proba\PYZus{}prediction}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        
                    \PY{n}{y\PYZus{}train\PYZus{}proba\PYZus{}prediction} \PY{o}{=} \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
                    \PY{n}{metrics\PYZus{}scores}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}proba\PYZus{}prediction}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
            
            \PY{k}{return} \PY{n}{metrics\PYZus{}scores}
        
        \PY{c+c1}{\PYZsh{}\PYZsh{} AQUI VA SU CODIGO }
        \PY{c+c1}{\PYZsh{}\PYZsh{} Objetivo: accuracies\PYZus{}training, accuracies\PYZus{}validation, aucs\PYZus{}training y aucs\PYZus{}validation asignados}
        \PY{c+c1}{\PYZsh{} Ejercicio 2.1}
        \PY{n}{classifier} \PY{o}{=} \PY{n}{tree}\PY{o}{.}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
        \PY{n}{classifier} \PY{o}{=} \PY{n}{classifier}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Ejercicio 2.2}
        
        
        \PY{n}{kf} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
        \PY{k}{for} \PY{n}{train\PYZus{}index}\PY{p}{,} \PY{n}{test\PYZus{}index} \PY{o+ow}{in} \PY{n}{kf}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{)}\PY{p}{:}
            \PY{p}{[}\PY{n}{accuracy\PYZus{}test}\PY{p}{,} \PY{n}{accuracy\PYZus{}train}\PY{p}{,} \PY{n}{auc\PYZus{}roc\PYZus{}test}\PY{p}{,} \PY{n}{auc\PYZus{}roc\PYZus{}train}\PY{p}{]} \PY{o}{=} \PY{n}{get\PYZus{}scores}\PY{p}{(}\PY{n}{train\PYZus{}index}\PY{p}{,} \PY{n}{test\PYZus{}index}\PY{p}{)}
            
            \PY{n}{accuracies\PYZus{}validation}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{accuracy\PYZus{}test}\PY{p}{)}
            \PY{n}{aucs\PYZus{}validation}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}test}\PY{p}{)}
            \PY{n}{accuracies\PYZus{}training}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{accuracy\PYZus{}train}\PY{p}{)}
            \PY{n}{aucs\PYZus{}training}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}train}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        
        \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{index}\PY{o}{=}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
        \PY{n}{df}\PY{o}{.}\PY{n}{index}\PY{o}{.}\PY{n}{name} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Permutación}\PY{l+s+s2}{\PYZdq{}}
                          
        \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy (training)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{accuracies\PYZus{}training}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy (validación)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{accuracies\PYZus{}validation}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AUC ROC (training)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{aucs\PYZus{}training}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AUC ROC (validación)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{aucs\PYZus{}validation}
        
        \PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZlt{}h3\PYZgt{} TABLA 1 \PYZlt{}/h3\PYZgt{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
        \PY{n}{display}\PY{p}{(}\PY{n}{df}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Descomentar las siguientes líneas para graficar el resultado}
        \PY{n}{df}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{bar}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bbox\PYZus{}to\PYZus{}anchor}\PY{o}{=}\PY{p}{(}\PY{l+m+mf}{1.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{)}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    
    \begin{verbatim}
             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \
Permutación                                                                   
1                         0.8167                 0.6556              0.8737   
2                         0.8278                 0.6111              0.8878   
3                         0.8222                 0.7111              0.8739   
4                         0.8361                 0.7111              0.8543   
5                         0.8056                 0.7444              0.8822   

             AUC ROC (validación)  
Permutación                        
1                          0.6892  
2                          0.6410  
3                          0.7523  
4                          0.7456  
5                          0.7566  
    \end{verbatim}

    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_6_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{resultados\PYZus{}training} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{n}{resultados\PYZus{}validation} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        \PY{c+c1}{\PYZsh{}\PYZsh{} AQUI VA SU CODIGO }
        \PY{c+c1}{\PYZsh{}\PYZsh{} Objetivo: resultados\PYZus{}training y resultados\PYZus{}validation asignadas}
        \PY{c+c1}{\PYZsh{}}
        \PY{c+c1}{\PYZsh{}\PYZsh{} Recomendamos seguir el siguiente esquema:}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{n}{SEED}\PY{p}{)}
        
        \PY{k}{for} \PY{n}{criterio} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{:}
            \PY{k}{for} \PY{n}{altura} \PY{o+ow}{in} \PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{k+kc}{None}\PY{p}{]}\PY{p}{:}
                \PY{n}{kf} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
                \PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}list}\PY{p}{,} \PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}
                
                \PY{k}{for} \PY{n}{train\PYZus{}index}\PY{p}{,} \PY{n}{test\PYZus{}index} \PY{o+ow}{in} \PY{n}{kf}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{)}\PY{p}{:}
                    \PY{p}{[}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}fold}\PY{p}{,} \PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}fold}\PY{p}{]} \PY{o}{=} \PY{n}{get\PYZus{}scores}\PY{p}{(}\PY{n}{train\PYZus{}index}\PY{p}{,} \PY{n}{test\PYZus{}index}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}criterion}\PY{o}{=}\PY{n}{criterio}\PY{p}{,} \PY{n}{max\PYZus{}depth} \PY{o}{=} \PY{n}{altura}\PY{p}{,} \PY{n}{metrics} \PY{o}{=} \PY{p}{[}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{]}\PY{p}{)}
                    
                    \PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}fold}\PY{p}{)}
                    \PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}fold}\PY{p}{)}
                \PY{n}{resultados\PYZus{}training}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}list}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}list}\PY{p}{)} \PY{p}{)}
                \PY{n}{resultados\PYZus{}validation}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}list}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}list}\PY{p}{)} \PY{p}{)}
        \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
        
        \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{index}\PY{o}{=}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Altura máxima}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Inifinito}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{2}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Criterio de evaluación de corte}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{3} \PY{o}{+} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ganancia de Información}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{3}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AUC ROC promedio (training)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{resultados\PYZus{}training} \PY{c+c1}{\PYZsh{} reemplazar por resultados\PYZus{}training}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AUC ROC promedio (validación)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{resultados\PYZus{}validation} \PY{c+c1}{\PYZsh{} reemplazar por resultados\PYZus{}validation}
           
        \PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZlt{}h3\PYZgt{} TABLA 2 \PYZlt{}/h3\PYZgt{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
        \PY{n}{display}\PY{p}{(}\PY{n}{df}\PY{p}{)}
\end{Verbatim}


    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    
    \begin{verbatim}
  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \
0             3                            Gini                       0.8744   
1             5                            Gini                       0.9754   
2     Inifinito                            Gini                       1.0000   
3             3         Ganancia de Información                       0.8772   
4             5         Ganancia de Información                       0.9825   
5     Inifinito         Ganancia de Información                       1.0000   

   AUC ROC promedio (validación)  
0                         0.7133  
1                         0.6521  
2                         0.6382  
3                         0.7153  
4                         0.6967  
5                         0.6873  
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{c+c1}{\PYZsh{}Ejercicio extra}
         
         \PY{c+c1}{\PYZsh{} Definición de la clase \PYZdq{}Pregunta\PYZdq{}}
         \PY{k}{class} \PY{n+nc}{Pregunta}\PY{p}{:}
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{atributo}\PY{p}{,} \PY{n}{valor}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{atributo} \PY{o}{=} \PY{n}{atributo}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{valor} \PY{o}{=} \PY{n}{valor}
             
             \PY{k}{def} \PY{n+nf}{cumple}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{instancia}\PY{p}{)}\PY{p}{:}
                 \PY{k}{return} \PY{n}{instancia}\PY{p}{[}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{atributo}\PY{p}{]} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{valor}
             
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}repr\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{)}\PY{p}{:}
                 \PY{k}{return} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{¿Es el valor para }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ menor o igual a }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{?}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{atributo}\PY{p}{,} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{valor}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{c+c1}{\PYZsh{} Definición de la estructura del árbol. }
         \PY{k}{class} \PY{n+nc}{Hoja}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}  Contiene las cuentas para cada clase (en forma de diccionario)}
             \PY{c+c1}{\PYZsh{}  Por ejemplo, \PYZob{}\PYZsq{}Si\PYZsq{}: 2, \PYZsq{}No\PYZsq{}: 2\PYZcb{}}
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{cuentas} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{Counter}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}\PY{p}{)}
         
         \PY{k}{class} \PY{n+nc}{Nodo\PYZus{}De\PYZus{}Decision}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Un Nodo de Decisión contiene preguntas y una referencia al sub\PYZhy{}árbol izquierdo y al sub\PYZhy{}árbol derecho}
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{pregunta}\PY{p}{,} \PY{n}{sub\PYZus{}arbol\PYZus{}izquierdo}\PY{p}{,} \PY{n}{sub\PYZus{}arbol\PYZus{}derecho}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{pregunta} \PY{o}{=} \PY{n}{pregunta}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sub\PYZus{}arbol\PYZus{}izquierdo} \PY{o}{=} \PY{n}{sub\PYZus{}arbol\PYZus{}izquierdo}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{sub\PYZus{}arbol\PYZus{}derecho} \PY{o}{=} \PY{n}{sub\PYZus{}arbol\PYZus{}derecho}    
         
             
         \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{k}{def} \PY{n+nf}{construir\PYZus{}arbol}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{altura}\PY{p}{,} \PY{n}{criterio}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} ALGORITMO RECURSIVO para construcción de un árbol de decisión binario. }
             \PY{c+c1}{\PYZsh{} Suponemos que estamos parados en la raiz del árbol y tenemos que decidir cómo construirlo. }
             
             \PY{n}{ganancia}\PY{p}{,} \PY{n}{pregunta} \PY{o}{=} \PY{n}{encontrar\PYZus{}mejor\PYZus{}atributo\PYZus{}y\PYZus{}corte}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{criterio}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Criterio de corte: ¿Hay ganancia?}
             \PY{k}{if} \PY{n}{ganancia} \PY{o}{==} \PY{l+m+mi}{0} \PY{o+ow}{or} \PY{p}{(}\PY{n}{altura} \PY{o}{!=} \PY{k+kc}{None} \PY{o+ow}{and} \PY{n}{altura} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}  Si no hay ganancia en separar, o llegue a la altura requerida, corto la recursion. }
                 \PY{k}{return} \PY{n}{Hoja}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} Si hay ganancia en partir el conjunto en 2}
             \PY{n}{instancias\PYZus{}cumplen}\PY{p}{,} \PY{n}{etiquetas\PYZus{}cumplen}\PY{p}{,} \PY{n}{instancias\PYZus{}no\PYZus{}cumplen}\PY{p}{,} \PY{n}{etiquetas\PYZus{}no\PYZus{}cumplen} \PY{o}{=} \PY{n}{partir\PYZus{}segun}\PY{p}{(}\PY{n}{pregunta}\PY{p}{,} \PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} partir devuelve instancias y etiquetas que caen en cada rama (izquierda y derecha)}
         
             \PY{n}{altura\PYZus{}rec} \PY{o}{=} \PY{k+kc}{None} \PY{k}{if}\PY{p}{(}\PY{n}{altura} \PY{o}{==} \PY{k+kc}{None}\PY{p}{)} \PY{k}{else} \PY{n}{altura} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}
             \PY{c+c1}{\PYZsh{} Paso recursivo (consultar con el computador más cercano)}
             \PY{n}{sub\PYZus{}arbol\PYZus{}izquierdo} \PY{o}{=} \PY{n}{construir\PYZus{}arbol}\PY{p}{(}\PY{n}{instancias\PYZus{}cumplen}\PY{p}{,} \PY{n}{etiquetas\PYZus{}cumplen}\PY{p}{,} \PY{n}{altura\PYZus{}rec}\PY{p}{,} \PY{n}{criterio}\PY{p}{)}
             \PY{n}{sub\PYZus{}arbol\PYZus{}derecho}   \PY{o}{=} \PY{n}{construir\PYZus{}arbol}\PY{p}{(}\PY{n}{instancias\PYZus{}no\PYZus{}cumplen}\PY{p}{,} \PY{n}{etiquetas\PYZus{}no\PYZus{}cumplen}\PY{p}{,} \PY{n}{altura\PYZus{}rec}\PY{p}{,} \PY{n}{criterio}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} los pasos anteriores crean todo lo que necesitemos de sub\PYZhy{}árbol izquierdo y sub\PYZhy{}árbol derecho}
         
             \PY{c+c1}{\PYZsh{} sólo falta conectarlos con un nodo de decisión:}
             \PY{k}{return} \PY{n}{Nodo\PYZus{}De\PYZus{}Decision}\PY{p}{(}\PY{n}{pregunta}\PY{p}{,} \PY{n}{sub\PYZus{}arbol\PYZus{}izquierdo}\PY{p}{,} \PY{n}{sub\PYZus{}arbol\PYZus{}derecho}\PY{p}{)}
         
         
         \PY{k}{def} \PY{n+nf}{encontrar\PYZus{}mejor\PYZus{}atributo\PYZus{}y\PYZus{}corte}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{criterio}\PY{p}{)}\PY{p}{:}
             \PY{n}{max\PYZus{}ganancia} \PY{o}{=} \PY{l+m+mi}{0}
             \PY{n}{mejor\PYZus{}pregunta} \PY{o}{=} \PY{k+kc}{None}
             \PY{k}{for} \PY{n}{columna} \PY{o+ow}{in} \PY{n}{instancias}\PY{o}{.}\PY{n}{columns}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}if columna \PYZpc{} 50 == 0:}
                 \PY{c+c1}{\PYZsh{}    print(\PYZdq{}Atributo: \PYZob{}\PYZcb{}\PYZdq{}.format(columna))}
                 \PY{n}{bordes} \PY{o}{=} \PY{n}{generar\PYZus{}valores\PYZus{}borde}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{columna}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}rint(\PYZdq{}Bordes \PYZob{}\PYZcb{}\PYZdq{}.format(bordes))}
                 \PY{k}{for} \PY{n}{valor} \PY{o+ow}{in} \PY{n}{bordes}\PY{p}{:}
                     \PY{c+c1}{\PYZsh{} Probando corte para atributo y valor}
                     \PY{n}{pregunta} \PY{o}{=} \PY{n}{Pregunta}\PY{p}{(}\PY{n}{columna}\PY{p}{,} \PY{n}{valor}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}print(\PYZsq{}Pregunta: \PYZob{}\PYZcb{}\PYZsq{}.format(pregunta))}
                     \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{,} \PY{n}{\PYZus{}}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha} \PY{o}{=} \PY{n}{partir\PYZus{}segun}\PY{p}{(}\PY{n}{pregunta}\PY{p}{,} \PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{)}
                     \PY{k}{if}\PY{p}{(}\PY{n}{criterio} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                         \PY{n}{ganancia} \PY{o}{=} \PY{n}{ganancia\PYZus{}gini}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha}\PY{p}{)}
                     \PY{k}{else}\PY{p}{:}
                         \PY{n}{ganancia} \PY{o}{=} \PY{n}{ganancia\PYZus{}entropia}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{}print(\PYZdq{}La ganancia para la pregunta \PYZob{}\PYZcb{}, es \PYZob{}\PYZcb{}\PYZdq{}.format(pregunta, ganancia))}
                     \PY{k}{if} \PY{n}{ganancia} \PY{o}{\PYZgt{}} \PY{n}{max\PYZus{}ganancia}\PY{p}{:}
                         \PY{n}{max\PYZus{}ganancia} \PY{o}{=} \PY{n}{ganancia}
                         \PY{n}{mejor\PYZus{}pregunta} \PY{o}{=} \PY{n}{pregunta}
             \PY{c+c1}{\PYZsh{}print(\PYZdq{}La mejor pregunta es \PYZob{}\PYZcb{}, con una ganancia de \PYZob{}\PYZcb{}\PYZdq{}.format(mejor\PYZus{}pregunta, max\PYZus{}ganancia))        }
             \PY{k}{return} \PY{n}{max\PYZus{}ganancia}\PY{p}{,} \PY{n}{mejor\PYZus{}pregunta}
             
         
         \PY{k}{def} \PY{n+nf}{generar\PYZus{}valores\PYZus{}borde}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{columna}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}El metodo argsort de numpy returns the indices that would sort an array.}
             \PY{n}{bordes} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{if} \PY{n}{instancias}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{1}\PY{p}{:}
                 \PY{k}{return} \PY{n}{bordes}
             \PY{n}{valores} \PY{o}{=} \PY{n}{instancias}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{n}{columna}\PY{p}{]}
             \PY{n}{valores}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{drop}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
             \PY{n}{indices\PYZus{}valores\PYZus{}ordenados} \PY{o}{=} \PY{n}{valores}\PY{o}{.}\PY{n}{argsort}\PY{p}{(}\PY{p}{)}
             
             \PY{n}{anterior\PYZus{}indice} \PY{o}{=} \PY{n}{indices\PYZus{}valores\PYZus{}ordenados}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
             \PY{n}{anterior\PYZus{}valor} \PY{o}{=} \PY{n}{valores}\PY{p}{[}\PY{n}{anterior\PYZus{}indice}\PY{p}{]}
             \PY{n}{anterior\PYZus{}etiqueta} \PY{o}{=} \PY{n}{etiquetas}\PY{p}{[}\PY{n}{anterior\PYZus{}indice}\PY{p}{]}
         
             \PY{k}{for} \PY{n}{actual\PYZus{}indice} \PY{o+ow}{in} \PY{n}{indices\PYZus{}valores\PYZus{}ordenados}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}Indice representa el numero de la instancia que estoy mirando}
                 \PY{n}{actual\PYZus{}valor} \PY{o}{=} \PY{n}{valores}\PY{p}{[}\PY{n}{actual\PYZus{}indice}\PY{p}{]}
                 \PY{n}{actual\PYZus{}etiqueta} \PY{o}{=} \PY{n}{etiquetas}\PY{p}{[}\PY{n}{actual\PYZus{}indice}\PY{p}{]}
                 \PY{k}{if} \PY{n}{actual\PYZus{}etiqueta} \PY{o}{!=} \PY{n}{anterior\PYZus{}etiqueta}\PY{p}{:}
                     \PY{n}{bordes}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{(}\PY{n}{anterior\PYZus{}valor} \PY{o}{+} \PY{n}{actual\PYZus{}valor}\PY{p}{)}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{)}
                 \PY{n}{anterior\PYZus{}indice} \PY{o}{=} \PY{n}{actual\PYZus{}indice}
                 \PY{n}{anterior\PYZus{}valor} \PY{o}{=} \PY{n}{actual\PYZus{}valor}
                 \PY{n}{anterior\PYZus{}etiqueta} \PY{o}{=} \PY{n}{actual\PYZus{}etiqueta}
             \PY{k}{return} \PY{n}{bordes}
         
         
         \PY{k}{def} \PY{n+nf}{generar\PYZus{}valores\PYZus{}borde\PYZus{}random}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{columna}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{}Divide en subarreglos de tamaño 10 y elige un candidato de manera aleatoria de cada uno de ellos}
             \PY{n}{valores} \PY{o}{=} \PY{n}{instancias}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{n}{columna}\PY{p}{]}
             \PY{k}{if} \PY{n}{valores}\PY{o}{.}\PY{n}{size} \PY{o}{\PYZlt{}}\PY{o}{=}\PY{l+m+mi}{10}\PY{p}{:}
                 \PY{k}{return} \PY{n}{valores}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}
             \PY{n}{subarreglos} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array\PYZus{}split}\PY{p}{(}\PY{n}{valores}\PY{p}{,} \PY{n}{valores}\PY{o}{.}\PY{n}{size}\PY{o}{/}\PY{l+m+mi}{10}\PY{p}{)} 
             \PY{n}{bordes} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{subarreglo} \PY{o+ow}{in} \PY{n}{subarreglos}\PY{p}{:}
                 \PY{n}{bordes}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{subarreglo}\PY{p}{)}\PY{p}{)}
             \PY{k}{return} \PY{n}{bordes}
         
         \PY{k}{def} \PY{n+nf}{partir\PYZus{}segun}\PY{p}{(}\PY{n}{pregunta}\PY{p}{,} \PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{)}\PY{p}{:}
             \PY{c+c1}{\PYZsh{} Esta función debe separar instancias y etiquetas según si cada instancia cumple o no con la pregunta (ver método \PYZsq{}cumple\PYZsq{})}
             \PY{c+c1}{\PYZsh{} COMPLETAR (recomendamos utilizar máscaras para este punto)}
             \PY{n}{mascara} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{apply\PYZus{}along\PYZus{}axis}\PY{p}{(}\PY{n}{pregunta}\PY{o}{.}\PY{n}{cumple}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{instancias}\PY{p}{)}
             
             \PY{n}{instancias\PYZus{}cumplen} \PY{o}{=} \PY{n}{instancias}\PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{mascara}\PY{p}{)}\PY{p}{]}
             \PY{n}{instancias\PYZus{}no\PYZus{}cumplen} \PY{o}{=} \PY{n}{instancias}\PY{p}{[}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{o}{\PYZti{}}\PY{n}{mascara}\PY{p}{)}\PY{p}{]}
             
             \PY{n}{etiquetas\PYZus{}cumplen} \PY{o}{=} \PY{n}{ma}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{,} \PY{n}{mask} \PY{o}{=} \PY{o}{\PYZti{}}\PY{n}{mascara}\PY{p}{)}\PY{o}{.}\PY{n}{compressed}\PY{p}{(}\PY{p}{)}\PY{p}{;}
             \PY{n}{etiquetas\PYZus{}no\PYZus{}cumplen} \PY{o}{=} \PY{n}{ma}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{,} \PY{n}{mask} \PY{o}{=} \PY{n}{mascara}\PY{p}{)}\PY{o}{.}\PY{n}{compressed}\PY{p}{(}\PY{p}{)}\PY{p}{;}
             
             \PY{k}{return} \PY{n}{instancias\PYZus{}cumplen}\PY{p}{,} \PY{n}{etiquetas\PYZus{}cumplen}\PY{p}{,} \PY{n}{instancias\PYZus{}no\PYZus{}cumplen}\PY{p}{,} \PY{n}{etiquetas\PYZus{}no\PYZus{}cumplen}
         
         \PY{n}{diccionario\PYZus{}gini} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{n}{diccionario\PYZus{}entropia} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         
         \PY{k}{def} \PY{n+nf}{gini}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}\PY{p}{:}
             \PY{n}{diccionario} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{Counter}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}\PY{p}{)}
             \PY{n}{totalEtiquetas} \PY{o}{=} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{diccionario}\PY{o}{.}\PY{n}{values}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{impureza} \PY{o}{=} \PY{l+m+mi}{1}
             \PY{k}{for} \PY{n}{etiqueta} \PY{o+ow}{in} \PY{n}{diccionario}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                 \PY{n}{impureza} \PY{o}{=} \PY{n}{impureza} \PY{o}{\PYZhy{}} \PY{p}{(}\PY{n}{diccionario}\PY{p}{[}\PY{n}{etiqueta}\PY{p}{]}\PY{o}{/}\PY{n}{totalEtiquetas}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}
             \PY{k}{return} \PY{n}{impureza}
         
         \PY{k}{def} \PY{n+nf}{ganancia\PYZus{}gini}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha}\PY{p}{)}\PY{p}{:}
             \PY{n}{n\PYZus{}izq} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{)}
             \PY{n}{n\PYZus{}der} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha}\PY{p}{)}
             \PY{n}{n} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}
             
             \PY{n}{gini\PYZus{}total} \PY{o}{=} \PY{n}{gini}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}
             \PY{n}{gini\PYZus{}izq} \PY{o}{=} \PY{n}{gini}\PY{p}{(}\PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{)}
             \PY{n}{gini\PYZus{}der} \PY{o}{=} \PY{n}{gini}\PY{p}{(}\PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha}\PY{p}{)}
             
             \PY{n}{ganancia\PYZus{}gini} \PY{o}{=} \PY{n}{gini\PYZus{}total} \PY{o}{\PYZhy{}} \PY{p}{(}\PY{p}{(}\PY{n}{n\PYZus{}izq}\PY{o}{/}\PY{n}{n}\PY{p}{)}\PY{o}{*}\PY{n}{gini\PYZus{}izq} \PY{o}{+} \PY{p}{(}\PY{n}{n\PYZus{}der}\PY{o}{/}\PY{n}{n}\PY{p}{)}\PY{o}{*}\PY{n}{gini\PYZus{}der}\PY{p}{)}
             
             \PY{k}{return} \PY{n}{ganancia\PYZus{}gini}
         
         \PY{k}{def} \PY{n+nf}{entropia}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}\PY{p}{:}
             \PY{n}{diccionario} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{Counter}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}\PY{p}{)}
             \PY{n}{tupla} \PY{o}{=} \PY{p}{(}\PY{n}{diccionario}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{,} \PY{n}{diccionario}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
             \PY{k}{if} \PY{n}{tupla} \PY{o+ow}{in} \PY{n}{diccionario\PYZus{}entropia}\PY{p}{:}
                 \PY{k}{return} \PY{n}{diccionario\PYZus{}entropia}\PY{p}{[}\PY{n}{tupla}\PY{p}{]}
             \PY{n}{entropia} \PY{o}{=} \PY{l+m+mi}{0}
             \PY{k}{for} \PY{n}{etiqueta} \PY{o+ow}{in} \PY{n}{diccionario}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{:}
                 \PY{n}{proporcion} \PY{o}{=} \PY{n}{diccionario}\PY{p}{[}\PY{n}{etiqueta}\PY{p}{]}\PY{o}{/}\PY{n+nb}{len}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}
                 \PY{n}{entropia} \PY{o}{+}\PY{o}{=} \PY{o}{\PYZhy{}}\PY{n}{proporcion}\PY{o}{*}\PY{n}{log}\PY{p}{(}\PY{n}{proporcion}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}
             \PY{n}{diccionario\PYZus{}entropia}\PY{p}{[}\PY{n}{tupla}\PY{p}{]} \PY{o}{=} \PY{n}{entropia}
             \PY{k}{return} \PY{n}{entropia}
         
         \PY{k}{def} \PY{n+nf}{ganancia\PYZus{}entropia}\PY{p}{(}\PY{n}{instancias}\PY{p}{,} \PY{n}{etiquetas}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{,} \PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha}\PY{p}{)}\PY{p}{:}
             \PY{n}{n\PYZus{}izq} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{)}
             \PY{n}{n\PYZus{}der} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha}\PY{p}{)}
             \PY{n}{n} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}
             
             \PY{n}{entropia\PYZus{}total} \PY{o}{=} \PY{n}{entropia}\PY{p}{(}\PY{n}{etiquetas}\PY{p}{)}
             \PY{n}{entropia\PYZus{}izq} \PY{o}{=} \PY{n}{entropia}\PY{p}{(}\PY{n}{etiquetas\PYZus{}rama\PYZus{}izquierda}\PY{p}{)}
             \PY{n}{entropia\PYZus{}der} \PY{o}{=} \PY{n}{entropia}\PY{p}{(}\PY{n}{etiquetas\PYZus{}rama\PYZus{}derecha}\PY{p}{)}
             
             \PY{n}{ganancia\PYZus{}entropia} \PY{o}{=} \PY{n}{entropia\PYZus{}total} \PY{o}{\PYZhy{}} \PY{p}{(}\PY{p}{(}\PY{n}{n\PYZus{}izq}\PY{o}{/}\PY{n}{n}\PY{p}{)}\PY{o}{*}\PY{n}{entropia\PYZus{}izq} \PY{o}{+} \PY{p}{(}\PY{n}{n\PYZus{}der}\PY{o}{/}\PY{n}{n}\PY{p}{)}\PY{o}{*}\PY{n}{entropia\PYZus{}der}\PY{p}{)}
             
             \PY{k}{return} \PY{n}{ganancia\PYZus{}entropia}
         
         \PY{k}{def} \PY{n+nf}{imprimir\PYZus{}arbol}\PY{p}{(}\PY{n}{arbol}\PY{p}{,} \PY{n}{spacing}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
             \PY{k}{if} \PY{n+nb}{isinstance}\PY{p}{(}\PY{n}{arbol}\PY{p}{,} \PY{n}{Hoja}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb}{print} \PY{p}{(}\PY{n}{spacing} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Hoja:}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{arbol}\PY{o}{.}\PY{n}{cuentas}\PY{p}{)}
                 \PY{k}{return}
         
             \PY{n+nb}{print} \PY{p}{(}\PY{n}{spacing} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{pregunta}\PY{p}{)}\PY{p}{)}
         
             \PY{n+nb}{print} \PY{p}{(}\PY{n}{spacing} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZgt{} True:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{imprimir\PYZus{}arbol}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{sub\PYZus{}arbol\PYZus{}izquierdo}\PY{p}{,} \PY{n}{spacing} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
             \PY{n+nb}{print} \PY{p}{(}\PY{n}{spacing} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}\PYZhy{}\PYZgt{} False:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{imprimir\PYZus{}arbol}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{sub\PYZus{}arbol\PYZus{}derecho}\PY{p}{,} \PY{n}{spacing} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{  }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         
         \PY{k}{def} \PY{n+nf}{predecir}\PY{p}{(}\PY{n}{arbol}\PY{p}{,} \PY{n}{x\PYZus{}t}\PY{p}{)}\PY{p}{:}
             \PY{k}{if} \PY{n+nb}{isinstance}\PY{p}{(}\PY{n}{arbol}\PY{p}{,} \PY{n}{Hoja}\PY{p}{)}\PY{p}{:}
                 \PY{k}{return} \PY{n+nb}{max}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{cuentas}\PY{p}{,} \PY{n}{key}\PY{o}{=}\PY{n}{arbol}\PY{o}{.}\PY{n}{cuentas}\PY{o}{.}\PY{n}{get}\PY{p}{)}
             
             \PY{k}{if}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{pregunta}\PY{o}{.}\PY{n}{cumple}\PY{p}{(}\PY{n}{x\PYZus{}t}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                 \PY{k}{return} \PY{n}{predecir}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{sub\PYZus{}arbol\PYZus{}izquierdo}\PY{p}{,} \PY{n}{x\PYZus{}t}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{k}{return} \PY{n}{predecir}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{sub\PYZus{}arbol\PYZus{}derecho}\PY{p}{,} \PY{n}{x\PYZus{}t}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{predecir\PYZus{}proba}\PY{p}{(}\PY{n}{arbol}\PY{p}{,} \PY{n}{x\PYZus{}t}\PY{p}{)}\PY{p}{:}
             \PY{k}{if} \PY{n+nb}{isinstance}\PY{p}{(}\PY{n}{arbol}\PY{p}{,} \PY{n}{Hoja}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{}Retorno la probabilidad de que la clase sea \PYZsq{}Si\PYZsq{}}
                 \PY{k}{return} \PY{n}{arbol}\PY{o}{.}\PY{n}{cuentas}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{o}{/}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{cuentas}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)} \PY{o}{+} \PY{n}{arbol}\PY{o}{.}\PY{n}{cuentas}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{)}
             
             \PY{k}{if}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{pregunta}\PY{o}{.}\PY{n}{cumple}\PY{p}{(}\PY{n}{x\PYZus{}t}\PY{p}{)}\PY{p}{)}\PY{p}{:}
                 \PY{k}{return} \PY{n}{predecir}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{sub\PYZus{}arbol\PYZus{}izquierdo}\PY{p}{,} \PY{n}{x\PYZus{}t}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{k}{return} \PY{n}{predecir}\PY{p}{(}\PY{n}{arbol}\PY{o}{.}\PY{n}{sub\PYZus{}arbol\PYZus{}derecho}\PY{p}{,} \PY{n}{x\PYZus{}t}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{k}{class} \PY{n+nc}{MiClasificadorArbol}\PY{p}{(}\PY{p}{)}\PY{p}{:} 
             \PY{k}{def} \PY{n+nf}{\PYZus{}\PYZus{}init\PYZus{}\PYZus{}}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{columnas}\PY{o}{=}\PY{k+kc}{None}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{arbol} \PY{o}{=} \PY{k+kc}{None}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{columnas} \PY{o}{=} \PY{n}{columnas}
             
             \PY{k}{def} \PY{n+nf}{fit}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{k+kc}{None}\PY{p}{,} \PY{n}{criterion}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
                 \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{arbol} \PY{o}{=} \PY{n}{construir\PYZus{}arbol}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{columnas}\PY{p}{)}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{p}{,} \PY{n}{criterion}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{}imprimir\PYZus{}arbol(self.arbol)}
                 \PY{k}{return} \PY{n+nb+bp}{self}
             
             \PY{k}{def} \PY{n+nf}{predict}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{)}\PY{p}{:}
                 \PY{n}{predictions} \PY{o}{=} \PY{p}{[}\PY{p}{]}
                 \PY{k}{for} \PY{n}{x\PYZus{}t} \PY{o+ow}{in} \PY{n}{X\PYZus{}test}\PY{p}{:}
                     \PY{n}{x\PYZus{}t\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{[}\PY{n}{x\PYZus{}t}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{columnas}\PY{p}{)}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                     \PY{n}{prediction} \PY{o}{=} \PY{n}{predecir}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{arbol}\PY{p}{,} \PY{n}{x\PYZus{}t\PYZus{}df}\PY{p}{)} 
                     \PY{c+c1}{\PYZsh{}print(x\PYZus{}t, \PYZdq{}predicción \PYZhy{}\PYZgt{}\PYZdq{}, prediction)}
                     \PY{n}{predictions}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{prediction}\PY{p}{)}
                 \PY{k}{return} \PY{n}{predictions}
             
             \PY{k}{def} \PY{n+nf}{predict\PYZus{}proba}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{)}\PY{p}{:}
                 \PY{n}{predictions} \PY{o}{=} \PY{p}{[}\PY{p}{]}
                 \PY{k}{for} \PY{n}{x\PYZus{}t} \PY{o+ow}{in} \PY{n}{X\PYZus{}test}\PY{p}{:}
                     \PY{n}{x\PYZus{}t\PYZus{}df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{[}\PY{n}{x\PYZus{}t}\PY{p}{]}\PY{p}{,} \PY{n}{columns}\PY{o}{=}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{columnas}\PY{p}{)}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}
                     \PY{n}{prediction} \PY{o}{=} \PY{n}{predecir\PYZus{}proba}\PY{p}{(}\PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{arbol}\PY{p}{,} \PY{n}{x\PYZus{}t\PYZus{}df}\PY{p}{)} 
                     \PY{c+c1}{\PYZsh{}print(x\PYZus{}t, \PYZdq{}predicción \PYZhy{}\PYZgt{}\PYZdq{}, prediction)}
                     \PY{n}{predictions}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{prediction}\PY{p}{)}
                 \PY{k}{return} \PY{n}{predictions}
             
             \PY{k}{def} \PY{n+nf}{score}\PY{p}{(}\PY{n+nb+bp}{self}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{:}
                 \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n+nb+bp}{self}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
                 
                 \PY{n}{accuracy} \PY{o}{=} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{y\PYZus{}i} \PY{o}{==} \PY{n}{y\PYZus{}j} \PY{k}{for} \PY{p}{(}\PY{n}{y\PYZus{}i}\PY{p}{,} \PY{n}{y\PYZus{}j}\PY{p}{)} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{)}
                 \PY{k}{return} \PY{n}{accuracy}
         
         
         \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{k}{def} \PY{n+nf}{get\PYZus{}dt\PYZus{}scores}\PY{p}{(}\PY{n}{train\PYZus{}indexes}\PY{p}{,} \PY{n}{test\PYZus{}indexes}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}criterion}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test} \PY{o}{=} \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{[}\PY{n}{train\PYZus{}indexes}\PY{p}{]}\PY{p}{,} \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{[}\PY{n}{test\PYZus{}indexes}\PY{p}{]}
             \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{[}\PY{n}{train\PYZus{}indexes}\PY{p}{]}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{[}\PY{n}{test\PYZus{}indexes}\PY{p}{]}
             
             \PY{n}{iteration\PYZus{}classifier} \PY{o}{=} \PY{n}{MiClasificadorArbol}\PY{p}{(}\PY{p}{)}
             \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}criterion}\PY{p}{)}
             
             \PY{n}{metrics\PYZus{}scores} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             
             \PY{k}{for} \PY{n}{metric} \PY{o+ow}{in} \PY{n}{metrics}\PY{p}{:}
                 \PY{k}{if} \PY{n}{metric} \PY{o}{==} \PY{n}{accuracy\PYZus{}score}\PY{p}{:}
                     \PY{n}{y\PYZus{}test\PYZus{}prediction} \PY{o}{=} \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
                     \PY{n}{metrics\PYZus{}scores}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}prediction}\PY{p}{)}\PY{p}{)}
         
                     \PY{n}{y\PYZus{}train\PYZus{}prediction} \PY{o}{=} \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
                     \PY{n}{metrics\PYZus{}scores}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}prediction}\PY{p}{)}\PY{p}{)}
                 \PY{k}{elif} \PY{n}{metric} \PY{o}{==} \PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{:}
                     \PY{c+c1}{\PYZsh{}Nuestro predictor solamente devuelve la probabilidad de la clase positiva}
                     \PY{n}{y\PYZus{}test\PYZus{}proba\PYZus{}prediction} \PY{o}{=} \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
                     \PY{n}{metrics\PYZus{}scores}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test\PYZus{}proba\PYZus{}prediction}\PY{p}{)}\PY{p}{)}
         
                     \PY{n}{y\PYZus{}train\PYZus{}proba\PYZus{}prediction} \PY{o}{=} \PY{n}{iteration\PYZus{}classifier}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}
                     \PY{n}{metrics\PYZus{}scores}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train\PYZus{}proba\PYZus{}prediction}\PY{p}{)}\PY{p}{)}
             
             \PY{k}{return} \PY{n}{metrics\PYZus{}scores}
         
         
         
         \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         \PY{n}{resultados\PYZus{}training} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{n}{resultados\PYZus{}validation} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         
         \PY{k}{for} \PY{n}{criterio} \PY{o+ow}{in} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{:}
             \PY{k}{for} \PY{n}{altura} \PY{o+ow}{in} \PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{k+kc}{None}\PY{p}{]}\PY{p}{:}
                 \PY{n}{kf} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}
                 \PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}list}\PY{p}{,} \PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Criterio: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{, Altura: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{criterio}\PY{p}{,} \PY{n}{altura}\PY{p}{)}\PY{p}{)}
                 \PY{n}{contador\PYZus{}fold} \PY{o}{=} \PY{l+m+mi}{1}
                 \PY{k}{for} \PY{n}{train\PYZus{}index}\PY{p}{,} \PY{n}{test\PYZus{}index} \PY{o+ow}{in} \PY{n}{kf}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{)}\PY{p}{:}
                     \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Probando fold: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{contador\PYZus{}fold}\PY{p}{)}\PY{p}{)}
                     \PY{n}{contador\PYZus{}fold}\PY{o}{+}\PY{o}{=}\PY{l+m+mi}{1}
                     \PY{p}{[}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}fold}\PY{p}{,} \PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}fold}\PY{p}{]} \PY{o}{=} \PY{n}{get\PYZus{}dt\PYZus{}scores}\PY{p}{(}\PY{n}{train\PYZus{}index}\PY{p}{,} \PY{n}{test\PYZus{}index}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}criterion}\PY{o}{=}\PY{n}{criterio}\PY{p}{,} \PY{n}{max\PYZus{}depth} \PY{o}{=} \PY{n}{altura}\PY{p}{,} \PY{n}{metrics} \PY{o}{=} \PY{p}{[}\PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{]}\PY{p}{)}
                     
                     \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Resultado test: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{, resultado train: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}fold}\PY{p}{,} \PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}fold}\PY{p}{)}\PY{p}{)}
                     \PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}fold}\PY{p}{)}
                     \PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}fold}\PY{p}{)}
                 \PY{n}{resultados\PYZus{}training}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}list}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}train\PYZus{}list}\PY{p}{)} \PY{p}{)}
                 \PY{n}{resultados\PYZus{}validation}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}list}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{auc\PYZus{}roc\PYZus{}test\PYZus{}list}\PY{p}{)} \PY{p}{)}
         \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}}
         
         \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{index}\PY{o}{=}\PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Altura máxima}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Inifinito}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{2}
         \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Criterio de evaluación de corte}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{3} \PY{o}{+} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Ganancia de Información}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{*} \PY{l+m+mi}{3}
         \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AUC ROC promedio (training)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{resultados\PYZus{}training} \PY{c+c1}{\PYZsh{} reemplazar por resultados\PYZus{}training}
         \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AUC ROC promedio (validación)}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{resultados\PYZus{}validation} \PY{c+c1}{\PYZsh{} reemplazar por resultados\PYZus{}validation}
            
         \PY{n}{display}\PY{p}{(}\PY{n}{HTML}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZlt{}h3\PYZgt{} TABLA EJERCICIO EXTRA \PYZlt{}/h3\PYZgt{}}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
         \PY{n}{display}\PY{p}{(}\PY{n}{df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Criterio: gini, Altura: 3
Probando fold: 1
Resultado test: 0.6536561264822135, resultado train: 0.8176953708312593
Probando fold: 2
Resultado test: 0.61, resultado train: 0.8277529761904762
Probando fold: 3
Resultado test: 0.708502024291498, resultado train: 0.8164086687306501
Probando fold: 4
Resultado test: 0.6998491704374057, resultado train: 0.8298739118312215
Probando fold: 5
Resultado test: 0.7444334487877289, resultado train: 0.8075158400699148
Criterio: gini, Altura: 5
Probando fold: 1
Resultado test: 0.6408102766798419, resultado train: 0.9486062717770035
Probando fold: 2
Resultado test: 0.6225, resultado train: 0.9501488095238095
Probando fold: 3
Resultado test: 0.6761133603238867, resultado train: 0.9404024767801856
Probando fold: 4
Resultado test: 0.6440422322775263, resultado train: 0.9336565568945755
Probando fold: 5
Resultado test: 0.6989114299851559, resultado train: 0.9617185305409033
Criterio: gini, Altura: None
Probando fold: 1
Resultado test: 0.6625494071146245, resultado train: 1.0
Probando fold: 2
Resultado test: 0.61, resultado train: 1.0
Probando fold: 3
Resultado test: 0.6568825910931173, resultado train: 1.0
Probando fold: 4
Resultado test: 0.669683257918552, resultado train: 1.0
Probando fold: 5
Resultado test: 0.6786244433448788, resultado train: 1.0
Criterio: entropy, Altura: 3
Probando fold: 1
Resultado test: 0.641304347826087, resultado train: 0.8091712294673967
Probando fold: 2
Resultado test: 0.5675, resultado train: 0.8158482142857143
Probando fold: 3
Resultado test: 0.6968623481781376, resultado train: 0.7718266253869969
Probando fold: 4
Resultado test: 0.6417797888386123, resultado train: 0.8011865299420675
Probando fold: 5
Resultado test: 0.7444334487877289, resultado train: 0.8075158400699148
Criterio: entropy, Altura: 5
Probando fold: 1
Resultado test: 0.5889328063241106, resultado train: 0.9250248880039821
Probando fold: 2
Resultado test: 0.6725, resultado train: 0.9475446428571429
Probando fold: 3
Resultado test: 0.6715587044534413, resultado train: 0.8743034055727554
Probando fold: 4
Resultado test: 0.6613876319758673, resultado train: 0.9419591684996437
Probando fold: 5
Resultado test: 0.7115289460663038, resultado train: 0.9350947282998845
Criterio: entropy, Altura: None
Probando fold: 1
Resultado test: 0.5978260869565217, resultado train: 1.0
Probando fold: 2
Resultado test: 0.6849999999999999, resultado train: 1.0
Probando fold: 3
Resultado test: 0.6629554655870445, resultado train: 1.0
Probando fold: 4
Resultado test: 0.6840120663650076, resultado train: 1.0
Probando fold: 5
Resultado test: 0.7337951509153884, resultado train: 1.0

    \end{Verbatim}

    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
    
    \begin{verbatim}
  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \
0             3                            Gini                       0.8198   
1             5                            Gini                       0.9469   
2     Inifinito                            Gini                       1.0000   
3             3         Ganancia de Información                       0.8011   
4             5         Ganancia de Información                       0.9248   
5     Inifinito         Ganancia de Información                       1.0000   

   AUC ROC promedio (validación)  
0                         0.6833  
1                         0.6565  
2                         0.6555  
3                         0.6584  
4                         0.6612  
5                         0.6727  
    \end{verbatim}

    
    \subsection{Ejercicio 3: Comparación de
algoritmos}\label{ejercicio-3-comparaciuxf3n-de-algoritmos}

Se pide explorar distintas combinaciones de algoritmos de aprendizaje e
hiperparámetros, de manera de buscar una performance óptima. Para este
ejercicio es necesario que evalúen posibilidades utilizando la técnica
de Grid Search. Como métrica de performance, usar siempre el área bajo
la curva (AUC ROC) resultante de 5-fold cross-validation.

Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM.
Hiperparámetros: Revisar la documentación de cada uno para la búsqueda
de combinaciones prometedoras.

Se pide generar un reporte que contenga:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Una descripción de las distintas combinaciones consideradas y su
  performance asociada (las que consideren relevantes, con al menos la
  mejor combinación para cada algoritmo).
\item
  Una breve explicación de los factores que creen que produjeron dicho
  resultado.
\end{enumerate}

En este punto evaluaremos tanto los hiperparámetros elegidos como las
conclusiones relacionadas a por qué piensan que ciertos algoritmos
funcionan mejor que otros para estos datos.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

\textbf{EJERCICIO EXTRA}: Utilizar RandomizedSearchCV con rangos de
parámetros que contengan a los utilizados en el GridSearch. Analizar si
se encontraron mejores combinaciones de parámetros que no hayan sido
tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo
de ejecución.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{k+kn}{import} \PY{n+nn}{collections}
         
         \PY{n}{pd}\PY{o}{.}\PY{n}{options}\PY{o}{.}\PY{n}{display}\PY{o}{.}\PY{n}{max\PYZus{}rows} \PY{o}{=} \PY{l+m+mi}{50}
         
         \PY{k}{def} \PY{n+nf}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{grid}\PY{p}{,} \PY{n}{method}\PY{p}{,} \PY{n}{top}\PY{o}{=}\PY{l+m+mi}{25}\PY{p}{)}\PY{p}{:}
             \PY{n+nb}{print}\PY{p}{(} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}\PYZsh{} Si quieren, pueden utilizar esta función para imprimir las mejores combinaciones de su grid}
             \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Top }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s2}{ combinaciones}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{top}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n}{method}\PY{p}{)}
             \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{grid}\PY{o}{.}\PY{n}{cv\PYZus{}results\PYZus{}}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{params}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
             \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}score\PYZus{}validation}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{grid}\PY{o}{.}\PY{n}{cv\PYZus{}results\PYZus{}}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}test\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
             \PY{n}{df}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}score\PYZus{}training}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{=} \PY{n}{grid}\PY{o}{.}\PY{n}{cv\PYZus{}results\PYZus{}}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}train\PYZus{}score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}
             \PY{n}{display}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{mean\PYZus{}score\PYZus{}validation}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{top}\PY{p}{)}\PY{p}{)}
             \PY{n+nb}{print}\PY{p}{(} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n}{iteraciones} \PY{o}{=} \PY{l+m+mi}{70}
         
         \PY{k}{def} \PY{n+nf}{doSearch}\PY{p}{(}\PY{n}{searchType}\PY{p}{,} \PY{n}{clasiffier}\PY{p}{,} \PY{n}{parameters}\PY{p}{)}\PY{p}{:}
             \PY{k}{if} \PY{n}{searchType} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{n}{gridSearch} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{clasiffier}\PY{p}{,} \PY{n}{parameters}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{return\PYZus{}train\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n}{gridSearch}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{)}
                 \PY{k}{return} \PY{n}{gridSearch}
         
             \PY{k}{if} \PY{n}{searchType} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{n}{randomSearch} \PY{o}{=} \PY{n}{RandomizedSearchCV}\PY{p}{(}\PY{n}{clasiffier}\PY{p}{,} \PY{n}{param\PYZus{}distributions}\PY{o}{=}\PY{n}{parameters}\PY{p}{,} \PY{n}{n\PYZus{}iter}\PY{o}{=}\PY{n}{iteraciones}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{refit}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
                 \PY{n}{randomSearch}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{)}
                 \PY{k}{return} \PY{n}{randomSearch}
\end{Verbatim}


    Elección de Parametros para KNN:

GridSearch: - n: Cantidad de vecinos: elegimos un rango entre 3 y 150
vecinos. Decidimos un valor impar como inicial para evitar problemas de
empate en la frontera. Elegir un rango tan amplio nos permite ver en más
detalle la interacción de los distintos parámetros. - weights: para
predecir los valores utilizaremos uniform y distance para asignarle
pesos a los vecinos. - p: forma de calcular la distancia, utilizaremos
la distancia euclidiana y la manhattan

RandomSearch: La diferencia es que utilizaremos un rango de vecindad
entre 3 y 200 de forma aleatoria

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{n}{knn\PYZus{}parameters\PYZus{}grid} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}neighbors}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{10}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{,}\PY{l+m+mi}{30}\PY{p}{,}\PY{l+m+mi}{40}\PY{p}{,}\PY{l+m+mi}{100}\PY{p}{,}\PY{l+m+mi}{110}\PY{p}{,}\PY{l+m+mi}{120}\PY{p}{,}\PY{l+m+mi}{150}\PY{p}{]}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weights}\PY{l+s+s2}{\PYZdq{}} \PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{distance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
         \PY{n}{knn\PYZus{}parameters\PYZus{}random} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}neighbors}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{201}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{p}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{weights}\PY{l+s+s2}{\PYZdq{}} \PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{uniform}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{distance}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}
         
         
         \PY{n}{grid\PYZus{}KNN\PYZus{}result} \PY{o}{=} \PY{n}{doSearch}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{knn\PYZus{}parameters\PYZus{}grid}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{grid\PYZus{}KNN\PYZus{}result}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{KNN GridSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n}{random\PYZus{}KNN\PYZus{}result} \PY{o}{=}  \PY{n}{doSearch}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{KNeighborsClassifier}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{knn\PYZus{}parameters\PYZus{}random}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{random\PYZus{}KNN\PYZus{}result}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{KNN RandomSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
 
 
Top 25 combinaciones KNN GridSearch

    \end{Verbatim}

    
    \begin{verbatim}
    n_neighbors  p   weights  mean_score_validation  mean_score_training
33          120  1  distance                 0.8519               1.0000
29          110  1  distance                 0.8515               1.0000
32          120  1   uniform                 0.8515               0.8502
28          110  1   uniform                 0.8505               0.8514
25          100  1  distance                 0.8496               1.0000
31          110  2  distance                 0.8489               1.0000
24          100  1   uniform                 0.8489               0.8513
27          100  2  distance                 0.8485               1.0000
30          110  2   uniform                 0.8480               0.8479
37          150  1  distance                 0.8473               1.0000
23           40  2  distance                 0.8464               1.0000
26          100  2   uniform                 0.8462               0.8488
22           40  2   uniform                 0.8459               0.8669
36          150  1   uniform                 0.8458               0.8432
19           30  2  distance                 0.8449               1.0000
18           30  2   uniform                 0.8439               0.8662
35          120  2  distance                 0.8438               1.0000
34          120  2   uniform                 0.8433               0.8452
39          150  2  distance                 0.8407               1.0000
38          150  2   uniform                 0.8402               0.8408
15           20  2  distance                 0.8394               1.0000
14           20  2   uniform                 0.8371               0.8724
17           30  1  distance                 0.8367               1.0000
16           30  1   uniform                 0.8363               0.8592
21           40  1  distance                 0.8347               1.0000
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 
 
 
Top 25 combinaciones KNN RandomSearch

    \end{Verbatim}

    
    \begin{verbatim}
    n_neighbors  p   weights  mean_score_validation  mean_score_training
39          125  1   uniform                 0.8530               0.8492
68           64  2  distance                 0.8529               1.0000
56          115  1  distance                 0.8518               1.0000
30          110  1  distance                 0.8515               1.0000
55          131  1  distance                 0.8512               1.0000
21          113  1   uniform                 0.8511               0.8514
60          119  1  distance                 0.8510               1.0000
6            45  2  distance                 0.8509               1.0000
31          117  1   uniform                 0.8507               0.8508
42           75  2   uniform                 0.8506               0.8568
32          110  1   uniform                 0.8505               0.8514
41          105  1  distance                 0.8504               1.0000
9           118  1  distance                 0.8503               1.0000
10           84  2  distance                 0.8499               1.0000
20           60  2  distance                 0.8492               1.0000
66           98  2  distance                 0.8491               1.0000
61          107  2   uniform                 0.8488               0.8481
48           53  2   uniform                 0.8486               0.8608
40           90  2   uniform                 0.8483               0.8502
16           48  2   uniform                 0.8483               0.8641
29          147  1  distance                 0.8482               1.0000
12          102  2  distance                 0.8482               1.0000
33           86  2   uniform                 0.8481               0.8524
24           42  2   uniform                 0.8478               0.8681
50          139  1  distance                 0.8478               1.0000
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 

    \end{Verbatim}

    \subsubsection{Conclusiones de KNN}\label{conclusiones-de-knn}

Los resultados obtenidos muestran que los modelos usando knn tiende a
sobreajustarse a los datos de entrenamiento cuando se toma distance como
parámeto de weights, sin importar la forma de calcular la distancia o la
vecindad tomada. La performance obtenida para los datos de test se
estanca en un valor cercano al a 0.85.

La exploración random confirmó que a partir de cierta valor de vecindad
los resultados no mejoran, sin importar qué otra combinación de
parametros se use.

Por otro lado, medir la distancia con p=1 o 2 no influye en los
resultados, ambos parecen funcionar bien con diversos valores de
vecinos.

De la misma manera, usar pesos uniformes y con distancia tampoco parece
influir.

\paragraph{Justificación de selección de
parámetros}\label{justificaciuxf3n-de-selecciuxf3n-de-paruxe1metros}

Seleccionamos un rango relativamente grande de vecinos, tratando de ser
exhaustivos pero, como dijimos antes, a partir de cierto valor de
vecinos los resultados no varían demasiado, por lo que decidimos
limitarlo en 150 (con RandomSearch le dimos un rango un poco más grande
simplemente porque RandomSearch nos permite explorar muchos más
valores).

Weights y uniform son dos de los valores más comunes para tomar en knn,
y queríamos ver si influían de alguna manera decisiva en los resultados.

De la misma manera, tanto la distancia Euclideana como la Manhattan son
medidas normalmente usadas, y también nos pareció interesante ver si
influían en la performance de los modelos.

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

    \subsubsection{Elección de Parametros para Decision
Tree:}\label{elecciuxf3n-de-parametros-para-decision-tree}

GridSearch: - criterion: utilizaremos gini y entropy para decidir los
splits - splitter: evaularemos con los criterios de best y random -
max\_depth: la altura del arbol la iniciaremos en 3, aumentandolo hasta
50. No consideramos arboles de altura mayor ya que se corre el riesgo de
caer en overfitting. El objetivo seria buscar uno no tan alto pero que
generalice bien. - max\_features: la cantidad de instancias que se
consideraran en un split inicial en 10 se ira aumentando hasta 100 y en
auto

RandomSearch: La diferencia es que utilizaremos valores random en la
altura de 5 hasta 50 y para el split se consideraran valores random
entre 1 y 200

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{tree\PYZus{}parameters\PYZus{}grid} \PY{o}{=} \PY{p}{[}\PY{p}{\PYZob{}} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{class\PYZus{}weight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{balanced}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{k+kc}{None}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{splitter}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{,} \PY{l+m+mi}{40}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auto}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{]}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{p}{\PYZcb{}}\PY{p}{]}
         \PY{n}{tree\PYZus{}parameters\PYZus{}random} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{class\PYZus{}weight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{balanced}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{k+kc}{None}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{splitter}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}features}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{p}{\PYZcb{}}
         
         \PY{n}{gridSearch} \PY{o}{=} \PY{n}{GridSearchCV}\PY{p}{(}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{tree\PYZus{}parameters\PYZus{}grid}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{return\PYZus{}train\PYZus{}score}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         \PY{n}{gridSearch}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{gridSearch}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision Tree GridSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         
         \PY{n}{randomSearch} \PY{o}{=} \PY{n}{RandomizedSearchCV}\PY{p}{(}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{param\PYZus{}distributions}\PY{o}{=}\PY{n}{tree\PYZus{}parameters\PYZus{}random}\PY{p}{,} \PY{n}{n\PYZus{}iter}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{refit}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
         \PY{n}{randomSearch}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{randomSearch}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Decision Tree RandomSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
 
 
Top 25 combinaciones Decision Tree GridSearch

    \end{Verbatim}

    
    \begin{verbatim}
    class_weight criterion  max_depth max_features splitter  \
305         None   entropy          5         None   random   
317         None   entropy          5          100   random   
1       balanced      gini          3         None   random   
106     balanced   entropy          3           50     best   
203         None      gini          3           50   random   
102     balanced   entropy          3           30     best   
14      balanced      gini          3         auto     best   
298         None   entropy          3           50     best   
193         None      gini          3         None   random   
196         None      gini          3           20     best   
295         None   entropy          3           30   random   
6       balanced      gini          3           30     best   
296         None   entropy          3           40     best   
9       balanced      gini          3           40   random   
127     balanced   entropy          5         auto   random   
309         None   entropy          5           20   random   
104     balanced   entropy          3           40     best   
109     balanced   entropy          3          100   random   
315         None   entropy          5           50   random   
13      balanced      gini          3          100   random   
8       balanced      gini          3           40     best   
217         None      gini          5           40   random   
200         None      gini          3           40     best   
12      balanced      gini          3          100     best   
113     balanced   entropy          5         None   random   

     mean_score_validation  mean_score_training  
305                 0.7726               0.9166  
317                 0.7644               0.9078  
1                   0.7568               0.8162  
106                 0.7478               0.8612  
203                 0.7473               0.7994  
102                 0.7465               0.8491  
14                  0.7450               0.8312  
298                 0.7445               0.8586  
193                 0.7436               0.8201  
196                 0.7404               0.8454  
295                 0.7389               0.7747  
6                   0.7376               0.8473  
296                 0.7351               0.8574  
9                   0.7335               0.7711  
127                 0.7325               0.8214  
309                 0.7315               0.8384  
104                 0.7289               0.8624  
109                 0.7280               0.8027  
315                 0.7276               0.8799  
13                  0.7274               0.8160  
8                   0.7268               0.8590  
217                 0.7265               0.8664  
200                 0.7261               0.8557  
12                  0.7257               0.8704  
113                 0.7254               0.9286  
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 
 
 
Top 25 combinaciones Decision Tree RandomSearch

    \end{Verbatim}

    
    \begin{verbatim}
   class_weight criterion  max_depth  max_features splitter  \
19         None   entropy          3            55     best   
51         None      gini          5           113   random   
35     balanced      gini         19            40     best   
87         None      gini         45            94     best   
70         None   entropy         45           157   random   
18         None      gini          5            39   random   
54     balanced   entropy         41            75   random   
85         None   entropy          5           145     best   
20     balanced      gini         21            91     best   
52         None      gini          7            24   random   
4          None      gini          5           147     best   
43         None   entropy         41           131     best   
26     balanced      gini         47            93   random   
72     balanced   entropy         41            34   random   
55     balanced   entropy         31           121   random   
88     balanced   entropy         13            65     best   
53         None      gini         11           100     best   
65         None   entropy         23           107     best   
74     balanced      gini         11            30     best   
69         None   entropy         39           151     best   
90         None   entropy         37           139     best   
37         None   entropy         29           191     best   
28         None      gini         15            67     best   
15     balanced      gini         27            15     best   
59         None   entropy         17           164     best   

    mean_score_validation  mean_score_training  
19                 0.7217               0.8565  
51                 0.7161               0.9184  
35                 0.7057               1.0000  
87                 0.6962               1.0000  
70                 0.6896               1.0000  
18                 0.6861               0.8748  
54                 0.6856               1.0000  
85                 0.6853               0.9686  
20                 0.6824               1.0000  
52                 0.6799               0.9565  
4                  0.6780               0.9694  
43                 0.6746               1.0000  
26                 0.6744               1.0000  
72                 0.6743               1.0000  
55                 0.6732               1.0000  
88                 0.6726               1.0000  
53                 0.6722               1.0000  
65                 0.6713               1.0000  
74                 0.6699               1.0000  
69                 0.6657               1.0000  
90                 0.6623               1.0000  
37                 0.6618               1.0000  
28                 0.6617               1.0000  
15                 0.6616               1.0000  
59                 0.6612               1.0000  
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 

    \end{Verbatim}

    \subsubsection{Conclusiones de Decision
Tree:}\label{conclusiones-de-decision-tree}

Los resultados obtenidos muestran que la mejor performance la tienen los
árboles de altura baja, especialmente entre 3 y 5. Con la variación de
los parametros de criterios y spliter no logramos gran diferencia en la
etapa de validación, pero si notamos que en entrenamiento overfittean
ligeramente más a los datos.

Como era de esperar, la altura es el factor que mas influye en la
clasificación, mientras que los splitters y criterios no parecen influir
mucho en los resultados.

Para max\_features mirar menos de 20 o 30 no da buenos resultados, sin
embargo, no mirar todos los features no influye tanto en la performance
del modelo como uno supondría.

\paragraph{Justificación de selección de
parámetros}\label{justificaciuxf3n-de-selecciuxf3n-de-paruxe1metros}

Los criterios más comunes en árboles son gini y entropy, por eso
seleccionamos estos.

Es interesante ver si se gana algo en validación cuando seleccionamos un
splitter random en vez de ir siempre con best, por eso nos pareció bueno
compararlos.

Para max\_depth no nos pareció necesario ir más allá de 50 porque con
valores más altos se vuevle muy difícil evitar el overfitting.

Teniendo en cuenta que tenemos muy pocas instancias en comparación con
la cantidad de atributos, nos pareció interesante comprobar si mirar
menos de estos atributos podría contribuir a una mejor generalización
(para evitar que los árboles encuentren relaciones falsas entre
atributos).

    \subsubsection{Elección de Parametros para
LDA:}\label{elecciuxf3n-de-parametros-para-lda}

GridSearch: - solver: utilizaremos los criterios de descomposición en
valores singulares'svd', cuadrados minimos 'lsqr' y autovectores 'eigen'
- shrinkage: se combinará con lsqr y eigen con valores de 0.1, 0.5, 1 y
none - n\_components: es la cantidad de classes sobre las que se hará
reducción de la dimensionalidad

RandomSearch: Se usarán valores para shrinkage y n\_components dentro de
los mismos rangos que con GridSearch, pero seleccionando más valores
dentro de éstos.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{n}{lda\PYZus{}parameters\PYZus{}grid} \PY{o}{=} \PY{p}{[}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{solver}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lsqr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eigen}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{shrinkage}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.5}\PY{p}{,} \PY{l+m+mf}{0.7}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auto}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{150}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{]}
         \PY{n}{lda\PYZus{}parameters\PYZus{}random} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{solver}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lsqr}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{eigen}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{shrinkage}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mf}{0.000001}\PY{p}{)}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)} \PY{o}{+} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auto}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{n\PYZus{}components}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{\PYZcb{}}
         
         \PY{n}{grid\PYZus{}LDA\PYZus{}result} \PY{o}{=} \PY{n}{doSearch}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{LinearDiscriminantAnalysis}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lda\PYZus{}parameters\PYZus{}grid}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{grid\PYZus{}LDA\PYZus{}result}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LDA GridSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n}{random\PYZus{}LDA\PYZus{}result} \PY{o}{=} \PY{n}{doSearch}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{LinearDiscriminantAnalysis}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{lda\PYZus{}parameters\PYZus{}random}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{random\PYZus{}LDA\PYZus{}result}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{LDA RandomSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
 
 
Top 25 combinaciones LDA GridSearch

    \end{Verbatim}

    
    \begin{verbatim}
    n_components shrinkage solver  mean_score_validation  mean_score_training
44            20       0.7   lsqr                 0.8627               0.9502
64           100       0.7   lsqr                 0.8627               0.9502
24             5       0.7   lsqr                 0.8627               0.9502
4              0       0.7   lsqr                 0.8627               0.9502
74           150       0.7   lsqr                 0.8627               0.9502
54            50       0.7   lsqr                 0.8627               0.9502
14             1       0.7   lsqr                 0.8627               0.9502
34            10       0.7   lsqr                 0.8627               0.9502
35            10       0.7  eigen                 0.8624               0.9503
25             5       0.7  eigen                 0.8624               0.9503
15             1       0.7  eigen                 0.8624               0.9503
65           100       0.7  eigen                 0.8624               0.9503
75           150       0.7  eigen                 0.8624               0.9503
45            20       0.7  eigen                 0.8624               0.9503
55            50       0.7  eigen                 0.8624               0.9503
5              0       0.7  eigen                 0.8624               0.9503
43            20       0.5  eigen                 0.8594               0.9735
53            50       0.5  eigen                 0.8594               0.9735
73           150       0.5  eigen                 0.8594               0.9735
63           100       0.5  eigen                 0.8594               0.9735
23             5       0.5  eigen                 0.8594               0.9735
33            10       0.5  eigen                 0.8594               0.9735
3              0       0.5  eigen                 0.8594               0.9735
13             1       0.5  eigen                 0.8594               0.9735
22             5       0.5   lsqr                 0.8591               0.9737
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 
 
 
Top 25 combinaciones LDA RandomSearch

    \end{Verbatim}

    
    \begin{verbatim}
    n_components  shrinkage solver  mean_score_validation  mean_score_training
28            49     0.6470   lsqr                 0.8641               0.9578
3             27     0.6573   lsqr                 0.8641               0.9565
41            48     0.6547   lsqr                 0.8639               0.9569
46            18     0.6337  eigen                 0.8635               0.9594
39            32     0.6050   lsqr                 0.8633               0.9629
4             40     0.5859  eigen                 0.8627               0.9651
55            34     0.6986  eigen                 0.8627               0.9504
58            16     0.5856   lsqr                 0.8626               0.9651
66            17     0.6991   lsqr                 0.8626               0.9503
17             4     0.5736   lsqr                 0.8625               0.9665
45            12     0.5496  eigen                 0.8623               0.9689
59            13     0.7774   lsqr                 0.8622               0.9364
15            19     0.5640  eigen                 0.8620               0.9674
25            16     0.7806   lsqr                 0.8620               0.9356
14            11     0.7821   lsqr                 0.8619               0.9352
48             6     0.7862   lsqr                 0.8619               0.9342
29            46     0.7156   lsqr                 0.8619               0.9478
54            36     0.7926  eigen                 0.8618               0.9331
23            10     0.7191   lsqr                 0.8616               0.9473
27            34     0.7996   lsqr                 0.8614               0.9309
34            35     0.8052  eigen                 0.8610               0.9299
47            37     0.8458   lsqr                 0.8589               0.9192
61            18     0.8621   lsqr                 0.8579               0.9143
64            39     0.8652  eigen                 0.8577               0.9139
20            40     0.8696   lsqr                 0.8575               0.9119
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 

    \end{Verbatim}

    \subsubsection{Conclusiones de LDA:}\label{conclusiones-de-lda}

En los casos de GridSearch, los modelos con shrinkage 1.0 parecen tener
mucho menos overfitting que aquellos con shrinkage 0.5, mientras que
variar otros paramétros aparentemente no afecta los resultados de manera
significativa.

Utilizando RandomSearch pudimos profundizar sobre estas variaciones de
shrinkage para intentar mejorar los resultados. Sin embargo no parecen
haber contribuido nada nuevo, simplemente cuánto más cerca de 0.5
estamos tenemos mayor overfitting, mientras que a medida que nos
acercamos a 1.0 se reduce éste, manteniendo un score de validation
razonable.

El uso de shrinkage "auto" no parece aportar nada nuevo a los
resultados.

\paragraph{Justificación de selección de
parámetros}\label{justificaciuxf3n-de-selecciuxf3n-de-paruxe1metros}

Los 3 solvers seleccionados son los más comúnmente usados, por eso nos
pareció útil comparar su performance.

La cantidad de componentes en que se comprimen los datos es importante
en este caso porque contamos con una cantidad relativamente baja de
datos de entrenamiento, es interesante ver la relación de este
hiperparámetro con shrinkage y la influencia conjunta de éstos en los
resultados.

    Naive Bayes

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n}{grid\PYZus{}gauss\PYZus{}result} \PY{o}{=} \PY{n}{doSearch}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{GaussianNB}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{grid\PYZus{}gauss\PYZus{}result}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Naive Gauss GridSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
 
 
Top 25 combinaciones Naive Gauss GridSearch

    \end{Verbatim}

    
    \begin{verbatim}
   mean_score_validation  mean_score_training
0                 0.8337               0.8696
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 

    \end{Verbatim}

    Conclusiones de Naive Bayes: Los resultados obtenidos para Naive Bayes
son relativamente buenos, esto podríamos darnos una intuición de cuánta
dependencia existe entre los atributos (dado que naive bayes asume una
independencia total entre los atributos).

    \subsubsection{Elección de Parametros para
SVM:}\label{elecciuxf3n-de-parametros-para-svm}

GridSearch: - C: es el parametro de penalización a los errores se
probaremos con 0.1 daremos poca tolerancia al error a fin de que
encuentre un mejor hiperplano, 1.0 es el valor por deafult y 1000 para
dejar poca tolerancia a los errores. - kernel : probaremos con `linear',
`poly', `rbf' y `sigmoid'. - gamma: se probarán distintos valores en
escalas normalmente consideradas útiles.

RandomSearch: Se generan modelos con una cobertura más alta y más
detallada de gammas y C, pero se mantiene el resto de los
hiperparámetros parecidos a los originales de grid search.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{n}{svm\PYZus{}parameters\PYZus{}grid} \PY{o}{=} \PY{p}{[}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{poly}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gamma}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mf}{1e\PYZhy{}1}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}2}\PY{p}{,}\PY{l+m+mf}{1e\PYZhy{}3}\PY{p}{,} \PY{l+m+mf}{1e\PYZhy{}4}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{linear}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{]}
         \PY{n}{svm\PYZus{}parameters\PYZus{}random} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{kernel}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{poly}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{sigmoid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gamma}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}\PY{n}{sp}\PY{o}{.}\PY{n}{stats}\PY{o}{.}\PY{n}{expon}\PY{p}{(}\PY{n}{scale}\PY{o}{=}\PY{o}{.}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{C}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{,} \PY{l+m+mf}{0.0001}\PY{p}{)}\PY{p}{\PYZcb{}}
         
         
         \PY{n}{grid\PYZus{}SVM\PYZus{}result} \PY{o}{=} \PY{n}{doSearch}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{SVC}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{svm\PYZus{}parameters\PYZus{}grid}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{grid\PYZus{}SVM\PYZus{}result}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SVM GridSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         
         \PY{n}{random\PYZus{}SVM\PYZus{}result} \PY{o}{=} \PY{n}{doSearch}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{random}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{SVC}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{svm\PYZus{}parameters\PYZus{}random}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{random\PYZus{}SVM\PYZus{}result}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{SVM RandomSearch}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
 
 
Top 25 combinaciones SVM GridSearch

    \end{Verbatim}

    
    \begin{verbatim}
         C   gamma   kernel  mean_score_validation  mean_score_training
18     1.0  0.0010      rbf                 0.8603               0.9459
20     1.0  0.0010  sigmoid                 0.8602               0.9164
5      0.1  0.0100  sigmoid                 0.8592               0.8785
27   100.0  0.0100      rbf                 0.8583               1.0000
39  1000.0  0.0100      rbf                 0.8583               1.0000
15     1.0  0.0100      rbf                 0.8549               1.0000
17     1.0  0.0100  sigmoid                 0.8479               0.8415
3      0.1  0.0100      rbf                 0.8464               0.9976
21     1.0  0.0001      rbf                 0.8418               0.8676
6      0.1  0.0010      rbf                 0.8408               0.8723
11     0.1  0.0001  sigmoid                 0.8404               0.8649
23     1.0  0.0001  sigmoid                 0.8404               0.8649
9      0.1  0.0001      rbf                 0.8404               0.8657
8      0.1  0.0010  sigmoid                 0.8404               0.8645
35   100.0  0.0001  sigmoid                 0.8404               0.9757
43  1000.0  0.0010     poly                 0.8366               1.0000
13     1.0  0.1000     poly                 0.8366               1.0000
40  1000.0  0.0100     poly                 0.8366               1.0000
16     1.0  0.0100     poly                 0.8366               1.0000
37  1000.0  0.1000     poly                 0.8366               1.0000
28   100.0  0.0100     poly                 0.8366               1.0000
1      0.1  0.1000     poly                 0.8366               1.0000
25   100.0  0.1000     poly                 0.8366               1.0000
31   100.0  0.0010     poly                 0.8330               1.0000
4      0.1  0.0100     poly                 0.8330               1.0000
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 
 
 
Top 25 combinaciones SVM RandomSearch

    \end{Verbatim}

    
    \begin{verbatim}
           C   gamma kernel  mean_score_validation  mean_score_training
53  988.7063  0.0039    rbf                 0.8561                  1.0
62  988.1081  0.0163    rbf                 0.8432                  1.0
64  748.5610  0.0185    rbf                 0.8403                  1.0
69   49.7005  0.0418   poly                 0.8366                  1.0
32  266.6386  0.0045   poly                 0.8366                  1.0
24  969.8684  0.0802   poly                 0.8366                  1.0
51  803.8989  0.0494   poly                 0.8366                  1.0
27  169.6537  0.0675   poly                 0.8366                  1.0
29  194.2318  0.1306   poly                 0.8366                  1.0
30  473.5725  0.0183   poly                 0.8366                  1.0
34  278.2392  0.0860   poly                 0.8366                  1.0
1   412.6012  0.0654   poly                 0.8366                  1.0
36  622.0649  0.0026   poly                 0.8366                  1.0
38  330.3536  0.0051   poly                 0.8366                  1.0
46  325.6052  0.5765   poly                 0.8366                  1.0
41  906.3403  0.0039   poly                 0.8366                  1.0
45   16.4455  0.1130   poly                 0.8366                  1.0
43  248.7860  0.0561   poly                 0.8366                  1.0
56  597.3770  0.1151   poly                 0.8366                  1.0
2   983.9096  0.0757   poly                 0.8366                  1.0
15  530.9955  0.2469   poly                 0.8366                  1.0
3   600.7153  0.0889   poly                 0.8366                  1.0
11  215.4129  0.3359   poly                 0.8366                  1.0
59  200.4161  0.2027   poly                 0.8366                  1.0
66  428.8816  0.0234    rbf                 0.8344                  1.0
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 

    \end{Verbatim}

    \subsubsection{Conclusiones de SVM:}\label{conclusiones-de-svm}

Los resultados para GridSearch en general favorecen el uso de Cs más
bien pequeños, como se puede notar claramente en los mejores resultados.
Tanto en RandomSearch como en GridSearch se nota que el kernel rbf tiene
mejores resultados.

También es interesante (y esperable) observar que, en los casos en que
se usó Cs de 100 y 1000, los resultados de training tienen un score
perfecto a diferencia de Cs 1.0 y 0.1.

Sabemos que Cs más altos suelen tener menos chances de proveer una
visión más general de los datos, esto explicaría por qué hay una
presencia menor de Cs altos.

Por otro lado, en RandomSearch encontramos que, salvo excepciones, los
Cs altos dominan los mejores resultados. En particular, también parece
que el kernel polinomial se lleva mejor con éstos. Al tener más
versatilidad en elecciones de valores para RandomSearch, parece que es
más fácil encontrar un compromiso entre tolerancia a error y
abstracción.

\paragraph{Justificación de selección de
parámetros}\label{justificaciuxf3n-de-selecciuxf3n-de-paruxe1metros}

Seleccionamos estos 3 kernels porque suelen ser los más tradicionalmente
usados y, al no tener un mejor conocimiento de la naturaleza de los
datos, no conviene seleccionar otros más complicados.

Por otro lado, seguimos este mismo criterio para seleccionar Cs y
gammas. Con RandomSearch, para demostrar su capacidad contra GridSearch,
le proveimos la posibilidad de explorar más en detalle éstos
hiperparámetros, pero dentro del rango que le proveímos a GridSearch.

    \subsection{Ejercicio 4:}\label{ejercicio-4}

\subsubsection{Diagnóstico
Sesgo-Varianza.}\label{diagnuxf3stico-sesgo-varianza.}

En este punto, se pide inspeccionar dos de sus mejores modelos
encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el
mejor de tipo SVM. Para ello:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Graficar curvas de complejidad para cada modelo, variando la
  profundidad en el caso de árboles, y el hiperparámetro C en el caso de
  SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos
  hiperparámetros.
\item
  Graficar curvas de aprendizaje para cada modelo. En base a estas
  curvas, sacar conclusiones sobre si los algoritmos parecen haber
  alcanzado su límite, o bien si aumentar la cantidad de datos debería
  ayudar.
\item
  Construir un modelo RandomForest con 200 árboles. Explorar para qué
  sirve el hiperparámetro max\_features y cómo afecta a la performance
  del algoritmo mediante una curva de complejidad. Explicar por qué
  creen que se dieron los resultados obtenidos. Por último, graficar una
  curva de aprendizaje sobre los parámetros elegidos para determinar si
  sería útil o no conseguir más datos (usar grid search para encontrar
  una buena combinación de parámetros).
\end{enumerate}

\textbf{Atención}: Tener en cuenta que debemos seguir utilizando ROC AUC
como métrica para estas curvas.

\textbf{ver}:
http://scikit-learn.org/stable/modules/learning\_curve.html\#learning-curve

\begin{longtable}[]{@{}l@{}}
\toprule
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\textbf{EJERCICIO EXTRA:} Utilizar RandomizedSearchCV para explorar la
performance del algoritmo de Gradient Boosting y comparar con los
resultados obtenidos en el punto (c).\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

    Como hiperparámetros para SVM seleccionamos kernel rbf y gama 0.01, que
son hiperparámetros que observamos que aparecen con bastante frecuencia
en las tablas del ejercicio 3.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}validation\PYZus{}curve}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{validation\PYZus{}scores}\PY{p}{,} \PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{xlabel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{X}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Curva de complejidad}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
             \PY{n}{train\PYZus{}scores\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{train\PYZus{}scores\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{validation\PYZus{}scores\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{validation\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{validation\PYZus{}scores\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{validation\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
             \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mf}{0.0}\PY{p}{,}\PY{l+m+mf}{1.1}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{title}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}plt.xlabel(xlabel)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{c+c1}{\PYZsh{}plt.xticks(param\PYZus{}range)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{yticks}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{1.1}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{)}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{semilogx}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{train\PYZus{}scores\PYZus{}mean}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{darkorange}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{semilogx}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{validation\PYZus{}scores\PYZus{}mean}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Validation score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{navy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{lw}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
             
             \PY{n}{marker\PYZus{}line\PYZus{}width} \PY{o}{=} \PY{l+m+mf}{0.005}
             \PY{n}{plt}\PY{o}{.}\PY{n}{axhspan}\PY{p}{(}\PY{l+m+mf}{0.8} \PY{o}{\PYZhy{}} \PY{n}{marker\PYZus{}line\PYZus{}width}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mf}{0.8} \PY{o}{+} \PY{n}{marker\PYZus{}line\PYZus{}width}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lower right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bbox\PYZus{}to\PYZus{}anchor}\PY{o}{=}\PY{p}{(}\PY{l+m+mf}{1.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{)}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{}    None	gini	2	auto	0.6746	0.6997}
         \PY{c+c1}{\PYZsh{} \PYZdq{}Seleccionamos el que consideramos uno de los mejores arboles obtenidos en GridSearch del ej 3\PYZdq{}}
         \PY{n}{depths\PYZus{}to\PYZus{}try} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
         \PY{n}{decision\PYZus{}tree\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}validation\PYZus{}scores} \PY{o}{=} \PYZbs{}
             \PY{n}{validation\PYZus{}curve}\PY{p}{(} \PYZbs{}
                 \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{40}\PY{p}{,} \PY{n}{criterion}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{class\PYZus{}weight}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{balanced}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{,} \PYZbs{}
                 \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PYZbs{}
                 \PY{n}{depths\PYZus{}to\PYZus{}try}\PY{p}{,} \PYZbs{}
                 \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PYZbs{}
                 \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}} \PYZbs{}
             \PY{p}{)}
         
         \PY{n}{cs\PYZus{}to\PYZus{}try} \PY{o}{=} \PY{p}{[}\PY{n+nb}{pow}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{n}{x}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{]}
         \PY{n}{svm\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{svm\PYZus{}validation\PYZus{}scores} \PY{o}{=} \PYZbs{}
             \PY{n}{validation\PYZus{}curve}\PY{p}{(} \PYZbs{}
                 \PY{n}{SVC}\PY{p}{(}\PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.001}\PY{p}{,} \PY{n}{kernel}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{,} \PYZbs{}
                 \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{C}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PYZbs{}
                 \PY{n}{cs\PYZus{}to\PYZus{}try}\PY{p}{,} \PYZbs{}
                 \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PYZbs{}
                 \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PYZbs{}
                 \PY{n}{n\PYZus{}jobs} \PY{o}{=} \PY{l+m+mi}{1} \PYZbs{}
             \PY{p}{)}
         
         \PY{n}{plot\PYZus{}validation\PYZus{}curve}\PY{p}{(}\PY{n}{decision\PYZus{}tree\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}validation\PYZus{}scores}\PY{p}{,} \PY{n}{depths\PYZus{}to\PYZus{}try}\PY{p}{,} \PY{n}{xlabel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Depth}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Curva de Complejidad con Arboles de Aprendizaje}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{plot\PYZus{}validation\PYZus{}curve}\PY{p}{(}\PY{n}{svm\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{svm\PYZus{}validation\PYZus{}scores}\PY{p}{,} \PY{n}{cs\PYZus{}to\PYZus{}try}\PY{p}{,} \PY{n}{xlabel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{C}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Curva de Complejidad con SVM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_28_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_28_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Árboles de Aprendizaje}\label{uxe1rboles-de-aprendizaje}

El Depth claramente aumenta la complejidad de los árboles de manera muy
rápida, lo cual lleva a modelos con un sesgo cada vez menor pero en
general pareciera tener una varianza bastante alta a partir de ciertas
alturas (alrededor de 9), algo que parece correlacionado con el grado de
overfitting que presenta el árbol.

Se ve de manera bastante bien definida que en los valores cercanos al 10
ya se llega a un nivel de varianza demasiado alto, esto se profundiza a
medida que se acerca a depth = 1000.

Basados en estos resultados, podemos decir que un valor razonable para
tomar como max\_depth sería 5.

\subsubsection{SVM}\label{svm}

El C parece tener una influencia que escala de manera menos brusca en el
overfitting y en la varianza presentada por los modelos.

Sin embargo, está claro que el sesgo va disminuyendo a medida que se
aumenta el C y la varianza va aumentando, debido a que estamos
condiciando al algoritmo a darle una mayor importancia a tener en cuenta
a minions que con menor C se pueden considerar ignorables.

Pareciera que la zona de los mejores Cs antes de comenzar a caer en
calidad sería la zona con los Cs entre 1 y 10. En particular C = 4 se ve
como una buena opción.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}learning\PYZus{}curve}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{validation\PYZus{}scores}\PY{p}{,} \PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Curva de aprendizaje}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{:}
             \PY{n}{train\PYZus{}scores\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{train\PYZus{}scores\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{train\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{validation\PYZus{}scores\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{validation\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
             \PY{n}{validation\PYZus{}scores\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{validation\PYZus{}scores}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
         
             \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{ylim}\PY{p}{(}\PY{l+m+mf}{0.0}\PY{p}{,}\PY{l+m+mf}{1.1}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{title}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{train\PYZus{}scores\PYZus{}mean}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Training score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                          \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{darkorange}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{param\PYZus{}range}\PY{p}{,} \PY{n}{validation\PYZus{}scores\PYZus{}mean}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Cross\PYZhy{}validation score}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}
                      \PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{navy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
             
             \PY{n}{marker\PYZus{}line\PYZus{}width} \PY{o}{=} \PY{l+m+mf}{0.005}
             \PY{n}{plt}\PY{o}{.}\PY{n}{axhspan}\PY{p}{(}\PY{l+m+mf}{0.8} \PY{o}{\PYZhy{}} \PY{n}{marker\PYZus{}line\PYZus{}width}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mf}{0.8} \PY{o}{+} \PY{n}{marker\PYZus{}line\PYZus{}width}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lower right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bbox\PYZus{}to\PYZus{}anchor}\PY{o}{=}\PY{p}{(}\PY{l+m+mf}{1.0}\PY{p}{,} \PY{l+m+mf}{1.0}\PY{p}{)}\PY{p}{)}
             
             \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
             
         \PY{c+c1}{\PYZsh{}    None	gini	2	auto	0.6746	0.6997}
         \PY{c+c1}{\PYZsh{} \PYZdq{}Seleccionamos el que consideramos uno de los mejores arboles obtenidos en GridSearch del ej 3\PYZdq{}}
         \PY{n}{dtree\PYZus{}train\PYZus{}sizes\PYZus{}abs}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}validation\PYZus{}scores} \PY{o}{=} \PYZbs{}
             \PY{n}{learning\PYZus{}curve}\PY{p}{(} \PYZbs{}
                 \PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{auto}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{criterion}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{,} \PYZbs{}
                 \PY{n}{train\PYZus{}sizes} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.}\PY{p}{,} \PY{l+m+mf}{0.02}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PYZbs{}
                 \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}} \PYZbs{}
             \PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} \PYZob{}\PYZsq{}kernel\PYZsq{}: [\PYZsq{}rbf\PYZsq{}, \PYZsq{}poly\PYZsq{}, \PYZsq{}sigmoid\PYZsq{}], \PYZsq{}gamma\PYZsq{}:sp.stats.expon(scale=.1),\PYZsq{}C\PYZsq{}: sp.stats.expon(scale=10)\PYZcb{}}
         \PY{c+c1}{\PYZsh{} 0.0001	rbf	0.7679	0.8707}
         \PY{n}{svm\PYZus{}train\PYZus{}sizes\PYZus{}abs}\PY{p}{,} \PY{n}{svm\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{svm\PYZus{}validation\PYZus{}scores} \PY{o}{=} \PYZbs{}
             \PY{n}{learning\PYZus{}curve}\PY{p}{(} \PYZbs{}
                 \PY{n}{SVC}\PY{p}{(}\PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.0001}\PY{p}{,} \PY{n}{kernel}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rbf}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{C}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{,} \PYZbs{}
                 \PY{n}{train\PYZus{}sizes} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.}\PY{p}{,} \PY{l+m+mf}{0.02}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PYZbs{}
                 \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PYZbs{}
             \PY{p}{)}
         
         \PY{n}{plot\PYZus{}learning\PYZus{}curve}\PY{p}{(}\PY{n}{decision\PYZus{}tree\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{decision\PYZus{}tree\PYZus{}validation\PYZus{}scores}\PY{p}{,} \PY{n}{dtree\PYZus{}train\PYZus{}sizes\PYZus{}abs}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Curva de Aprendizaje con Arboles de Decisión}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{plot\PYZus{}learning\PYZus{}curve}\PY{p}{(}\PY{n}{svm\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{svm\PYZus{}validation\PYZus{}scores}\PY{p}{,} \PY{n}{svm\PYZus{}train\PYZus{}sizes\PYZus{}abs}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Curva de Aprendizaje con SVM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_30_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_30_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Árboles de Decisión}\label{uxe1rboles-de-decisiuxf3n}

En los árboles de decisión parece que hay una tendencia pronunciada a
reducir la varianza, pero el sesgo se mantiene bastante malo a lo largo
de todos los n's analizados y no parece que haya una tendencia a mejorar
con mayores cantidades de datos de entrenamiento, por lo que no
consideramos que más datos ayuden a mejorar los resultados.

\subsubsection{SVM}\label{svm}

Inicialmente el sesgo de svm es bastante grande y con cantidades menores
a 130 aproximadamente es muy poco confiable.

En base al análisis de las curvas de aprendizaje pareciera que SVM
probablemente se beneficiaría de tener más datos debido a que los
scorings (tanto de validación como de entrenamiento) presentan una
tendencia a crecer.

La varianza parece haberse estabilizado en un rango de valores
relativamente bajo, aunque crece un poco a partir de aproximadamente n =
200.

Es probable que, en este caso, aumentar la cantidad de datos ayude a
obtener mejores resultados.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{forest\PYZus{}parameters} \PY{o}{=} \PY{p}{[}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{max\PYZus{}depth}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{k+kc}{None}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{15}\PY{p}{,} \PY{l+m+mi}{30}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{]} \PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{criterion}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{gini}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{entropy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{\PYZcb{}}\PY{p}{]}
         \PY{n}{grid\PYZus{}forest\PYZus{}result} \PY{o}{=} \PY{n}{doSearch}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{)}\PY{p}{,} \PY{n}{forest\PYZus{}parameters}\PY{p}{)}
         \PY{n}{top\PYZus{}resultados}\PY{p}{(}\PY{n}{grid\PYZus{}forest\PYZus{}result}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Random Forest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
 
 
Top 10 combinaciones Random Forest

    \end{Verbatim}

    
    \begin{verbatim}
   criterion  max_depth  mean_score_validation  mean_score_training
8    entropy        8.0                 0.8478               1.0000
6    entropy        NaN                 0.8441               1.0000
10   entropy       30.0                 0.8415               1.0000
9    entropy       15.0                 0.8399               1.0000
3       gini       15.0                 0.8395               1.0000
11   entropy       50.0                 0.8383               1.0000
7    entropy        3.0                 0.8342               0.9501
5       gini       50.0                 0.8316               1.0000
4       gini       30.0                 0.8315               1.0000
0       gini        NaN                 0.8302               1.0000
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
 

    \end{Verbatim}

    Seleccionamos Random Forest con max\_depth=8. Pensando en la Navaja de
Occam, es la opción más simple y tiene buenos resultados. Por otrol
lado, criterio=entropy produce scores marginalmente mejores.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{n}{max\PYZus{}features\PYZus{}to\PYZus{}try} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{200}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
         \PY{n}{random\PYZus{}forest\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{random\PYZus{}forest\PYZus{}validation\PYZus{}scores} \PY{o}{=} \PYZbs{}
             \PY{n}{validation\PYZus{}curve}\PY{p}{(} \PYZbs{}
                 \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{criterion}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{entropy}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{,} \PYZbs{}
                 \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{max\PYZus{}features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PYZbs{}
                 \PY{n}{max\PYZus{}features\PYZus{}to\PYZus{}try}\PY{p}{,} \PYZbs{}
                 \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PYZbs{}
                 \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}} \PYZbs{}
             \PY{p}{)}
         
         \PY{n}{plot\PYZus{}validation\PYZus{}curve}\PY{p}{(}\PY{n}{random\PYZus{}forest\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{random\PYZus{}forest\PYZus{}validation\PYZus{}scores}\PY{p}{,} \PY{n}{max\PYZus{}features\PYZus{}to\PYZus{}try}\PY{p}{,} \PY{n}{xlabel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Max Features}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Curva de Complejidad con Random Forest}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_34_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Max features}\label{max-features}

\paragraph{Explicación}\label{explicaciuxf3n}

max\_features determina la cantidad de atributos que deben observar los
árboles cuando se intenta determinar cuál es la mejor manera de separar
los valores en cada nodo según los valores de sus atributos.

Esto podría resultar beneficioso en el uso de muchos árboles al mismo
tiempo para poder analizar los objetos desde diferentes "perspectivas" y
luego proceder a votar. De otra manera podríamos terminar con muchos
árboles parecidos sin que ninguno de estos pueda contribuir nada muy
distinto a la hora de clasificar un minion.

\paragraph{Análisis}\label{anuxe1lisis}

La curva de complejidad de Random Forest no parece variar mucho
aumentando el límite, si bien los scores son mejores a partir de
max\_features=10.

Teniendo en cuenta que estamos usando 200 árboles, cada uno mirando
diferentes subgrupos de los 200 features, es posible que variaciones en
max\_features afecten poco debido a que hay una alta probabilidad de que
todos los features sean mirados por algunos de los 200 árboles, por lo
que la gran mayoría terminarían incidiendo en los resultados.

Basados en la curva dibujada, un valor posible para elegir sería
max\_features=15.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{random\PYZus{}forest\PYZus{}train\PYZus{}sizes\PYZus{}abs}\PY{p}{,} \PY{n}{random\PYZus{}forest\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{random\PYZus{}forest\PYZus{}validation\PYZus{}scores} \PY{o}{=} \PYZbs{}
             \PY{n}{learning\PYZus{}curve}\PY{p}{(} \PYZbs{}
                 \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{criterion}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{gini}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{max\PYZus{}depth}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{,} \PY{n}{max\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{,} \PYZbs{}
                 \PY{n}{train\PYZus{}sizes} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mf}{1.}\PY{p}{,} \PY{l+m+mf}{0.02}\PY{p}{)}\PY{p}{,} \PYZbs{}
                 \PY{n}{cv}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PYZbs{}
                 \PY{n}{scoring}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{roc\PYZus{}auc}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PYZbs{}
             \PY{p}{)}
         
         \PY{n}{plot\PYZus{}learning\PYZus{}curve}\PY{p}{(}\PY{n}{random\PYZus{}forest\PYZus{}train\PYZus{}scores}\PY{p}{,} \PY{n}{random\PYZus{}forest\PYZus{}validation\PYZus{}scores}\PY{p}{,} \PY{n}{random\PYZus{}forest\PYZus{}train\PYZus{}sizes\PYZus{}abs}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Curva de Aprendizaje con Random Forest con Depth bajo}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_36_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Se consiguió un sesgo relativamente bueno desde el principio. Sin
embargo, la varianza parece reducirse bastante lentamente aunque se
podría probar con más datos para ver si la tendencia a reducir la
varianza se dibuja más pronunciadamente con más datos.

    \subsection{Competencias}\label{competencias}

La entrega del trabajo estará acompañada de una competencia en la cual
deberán poner a prueba su mejor modelo y sobre todo, su capacidad para
estimar sus resultados.

Su tarea será estimar la performance (AUC ROC) que tendrá su mejor
modelo en datos de evaluación (X\_competencia).

Para ello, deberán predecir las probabilidades de las distintas
instancias con su modelo, enviarnos dichas probabilidades junto a una
estimación con 4 decimales de cuál será el AUC ROC resultante y
calcularemos el resultado real. El grupo que consiga acercarse más al
valor real, será el grupo ganador.

Recomendamos no perder de vista esta competencia en el momento de
separar los datos en los primeros puntos.

Para esto, junto con la entrega del informe, deberán enviar un archivo
en formato csv con las columnas ``index'' y ``output'' (ver ejemplo de
archivo en:
\href{https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv}{y\_competencia\_ejemplo.csv})
y un valor esperado de AUC ROC.

\subsection{Entrega}\label{entrega}

\begin{itemize}
\tightlist
\item
  Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán
  que completar las celdas faltantes (ya sea con explicaciones y
  gráficos o código).
\item
  El notebook final deberá ser entregado en formatos .html e .ipynb. Es
  necesario que los resultados puedan reproducirse al ejecutar todas las
  celdas en orden (Kernel - Restart and Run All) utilizando las
  bibliotecas requeridas en el archivo: requirements.txt del
  repositorio.
\item
  Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La
  entrega se debe realizar a través del campus virtual y debe contener
  el informe.
\item
  El trabajo deberá elaborarse en grupos de 3 personas.
\item
  Se podrán pedir pruebas de integridad y autoría; es decir, verificar
  que la salida solicitada es fruto del modelo presentado y que el
  modelo fue construido según lo requerido en este enunciado.
\item
  La evaluación será grupal y se basará en la calidad del informe
  (presentación, claridad, prolijidad); la originalidad, practicidad y
  coherencia técnica de la solución; la corrección y solidez de las
  pruebas realizadas.
\item
  En el primer parcial se incluirá una pregunta sobre la solución
  entregada. Esa pregunta no influirá en la nota del parcial, pero sí en
  la nota individual del TP1.
\item
  La participación en la competencia es obligatoria. De todas maneras,
  el resultado no incidirán en la nota de la materia.
\item
  Los ejercicios extra son opcionales para aprobar el TP, pero son
  obligatorios para promocionar la materia.
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{}  n\PYZus{}neighbors p weights mean\PYZus{}score\PYZus{}validation mean\PYZus{}score\PYZus{}training}
        
        \PY{n}{X\PYZus{}eval\PYZus{}np} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{X\PYZus{}eval}\PY{p}{)}
        \PY{n}{y\PYZus{}eval\PYZus{}np} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{y\PYZus{}eval}\PY{p}{)}\PY{o}{.}\PY{n}{ravel}\PY{p}{(}\PY{p}{)}
        
        \PY{n}{svm} \PY{o}{=} \PY{n}{SVC}\PY{p}{(}\PY{n}{C}\PY{o}{=}\PY{l+m+mf}{1.0}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.0010}\PY{p}{,} \PY{n}{kernel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{rbf}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{probability}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{svm}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}dev\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}dev\PYZus{}np}\PY{p}{)}
        
        \PY{n}{y\PYZus{}prediction\PYZus{}svm} \PY{o}{=} \PY{n}{svm}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}eval\PYZus{}np}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Scoring esperado para la competencia SVM: }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{roc\PYZus{}auc\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}eval\PYZus{}np}\PY{p}{,} \PY{n}{y\PYZus{}prediction\PYZus{}svm}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{svm\PYZus{}competition} \PY{o}{=} \PY{n}{SVC}\PY{p}{(}\PY{n}{C}\PY{o}{=}\PY{l+m+mf}{1.0}\PY{p}{,} \PY{n}{gamma}\PY{o}{=}\PY{l+m+mf}{0.0010}\PY{p}{,} \PY{n}{kernel}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{rbf}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
        \PY{n}{svm\PYZus{}competition}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{X}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{o}{.}\PY{n}{ravel}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{prediction} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{svm\PYZus{}competition}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}competencia}\PY{p}{)}\PY{p}{)}
        \PY{n}{prediction}\PY{o}{.}\PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{output}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
        \PY{n}{prediction}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}competencia.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{encoding}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{utf\PYZhy{}8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{index\PYZus{}label}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{index}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Scoring esperado para la competencia SVM:  0.7389162561576355

    \end{Verbatim}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
