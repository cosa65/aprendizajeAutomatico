{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "\n",
    "import sklearn.model_selection\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "import scipy as sp\n",
    "from scipy.stats import expon\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import math\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6   ...       193  \\\n",
       "index                                                           ...             \n",
       "0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "...       ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "          194     195     196     197     198     199  \n",
       "index                                                  \n",
       "0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "...       ...\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego. \n",
    "\n",
    "# X_competencia = pd.read_csv(\"X_competencia.csv\", index_col=\"index\")\n",
    "# y_competencia_ejemplo = pd.read_csv(\"y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "display(X)\n",
    "display(y)\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO 1. \n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO\n",
    "\n",
    "X_dev, X_eval, y_dev, y_eval = train_test_split(X, y, test_size = 0.1)\n",
    "\n",
    "# Objetivo: variables X_dev, X_eval, y_dev e y_eval asignadas\n",
    "#########################################################\n",
    "\n",
    "\n",
    "# print(\"X_dev: {}, y_dev: {} para desarrollo\".format(X_dev.shape, y_dev.shape))\n",
    "# print(\"X_eval: {}, y_eval: {} para evaluación\".format(X_eval.shape, y_eval.shape))\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(y_dev))  # muestra un histograma para la distribución de y.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA: Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.   **\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.6892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>0.6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.7523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>0.8543</td>\n",
       "      <td>0.7456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8056</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.7566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.8167                 0.6556              0.8737   \n",
       "2                         0.8278                 0.6111              0.8878   \n",
       "3                         0.8222                 0.7111              0.8739   \n",
       "4                         0.8361                 0.7111              0.8543   \n",
       "5                         0.8056                 0.7444              0.8822   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.6892  \n",
       "2                          0.6410  \n",
       "3                          0.7523  \n",
       "4                          0.7456  \n",
       "5                          0.7566  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "# Puede serles de utilidad tener a X_dev e y_dev como matrices de numpy directamente:\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "########################################################\n",
    "def get_scores(train_indexes, test_indexes, decision_tree_criterion=\"gini\", max_depth=3, metrics=[accuracy_score, roc_auc_score]):\n",
    "    X_train, X_test = X_dev_np[train_indexes], X_dev_np[test_indexes]\n",
    "    y_train, y_test = y_dev_np[train_indexes], y_dev_np[test_indexes]\n",
    "\n",
    "    iteration_classifier = tree.DecisionTreeClassifier(max_depth=max_depth, criterion=decision_tree_criterion)\n",
    "    iteration_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    metrics_scores = []\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric == accuracy_score:\n",
    "            y_test_prediction = iteration_classifier.predict(X_test)\n",
    "            metrics_scores.append(accuracy_score(y_test, y_test_prediction))\n",
    "\n",
    "            y_train_prediction = iteration_classifier.predict(X_train)\n",
    "            metrics_scores.append(accuracy_score(y_train, y_train_prediction))\n",
    "        elif metric == roc_auc_score:\n",
    "            #Devuelve un array con la probabilidad de la clase 0 y la clase 1.\n",
    "            #roc_auc_score pide solo la probobabilidad de la clase \"positiva\", asi que le paso el indice 1\n",
    "            y_test_proba_prediction = iteration_classifier.predict_proba(X_test)\n",
    "            metrics_scores.append(roc_auc_score(y_test, y_test_proba_prediction[:, 1]))\n",
    "\n",
    "            y_train_proba_prediction = iteration_classifier.predict_proba(X_train)\n",
    "            metrics_scores.append(roc_auc_score(y_train, y_train_proba_prediction[:, 1]))\n",
    "    \n",
    "    return metrics_scores\n",
    "    \n",
    "#    for metric in metrics:\n",
    "#        y_prediction = iteration_classifier.predict(X_test)\n",
    "#        metrics_scores.append(metric(y_test, y_prediction))\n",
    "        \n",
    "#        y_prediction = iteration_classifier.predict(X_train)\n",
    "#        metrics_scores.append(metric(y_train, y_prediction))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     accuracy_test = accuracy_score(y_test, y_prediction)\n",
    "#     auc_roc_test = roc_auc_score(y_test, y_prediction)\n",
    "\n",
    "#     y_prediction = iteration_classifier.predict(X_train)\n",
    "#     accuracy_train = accuracy_score(y_train, y_prediction)\n",
    "#     auc_roc_train = roc_auc_score(y_train, y_prediction)\n",
    "\n",
    "#    return metrics_scores\n",
    "\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: accuracies_training, accuracies_validation, aucs_training y aucs_validation asignados\n",
    "# Ejercicio 2.1\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=3)\n",
    "classifier = classifier.fit(X_dev_np, y_dev_np)\n",
    "\n",
    "#classifier.predict_proba([test])\n",
    "\n",
    "# Ejercicio 2.2\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(X_dev_np):\n",
    "    [accuracy_test, accuracy_train, auc_roc_test, auc_roc_train] = get_scores(train_index, test_index)\n",
    "    \n",
    "    accuracies_validation.append(accuracy_test)\n",
    "    aucs_validation.append(auc_roc_test)\n",
    "    accuracies_training.append(accuracy_train)\n",
    "    aucs_training.append(auc_roc_train)\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"] = accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracies_validation\n",
    "df[\"AUC ROC (training)\"] = aucs_training\n",
    "df[\"AUC ROC (validación)\"] = aucs_validation\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "df.plot(kind=\"bar\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>0.7133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.6521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.8772</td>\n",
       "      <td>0.7153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>0.6967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8744   \n",
       "1             5                            Gini                       0.9754   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.8772   \n",
       "4             5         Ganancia de Información                       0.9825   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.7133  \n",
       "1                         0.6521  \n",
       "2                         0.6382  \n",
       "3                         0.7153  \n",
       "4                         0.6967  \n",
       "5                         0.6873  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: resultados_training y resultados_validation asignadas\n",
    "#\n",
    "## Recomendamos seguir el siguiente esquema:\n",
    "np.random.seed(SEED)\n",
    "\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "    for altura in [3, 5, None]:\n",
    "        kf = KFold(n_splits=5)\n",
    "        auc_roc_test_list, auc_roc_train_list = [], []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X_dev_np):\n",
    "            [auc_roc_test_fold, auc_roc_train_fold] = get_scores(train_index, test_index, decision_tree_criterion=criterio, max_depth = altura, metrics = [roc_auc_score])\n",
    "            \n",
    "            auc_roc_test_list.append(auc_roc_test_fold)\n",
    "            auc_roc_train_list.append(auc_roc_train_fold)\n",
    "        resultados_training.append( sum(auc_roc_train_list) / len(auc_roc_train_list) )\n",
    "        resultados_validation.append( sum(auc_roc_test_list) / len(auc_roc_test_list) )\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterio: gini, Altura: 3\n",
      "Probando fold: 1\n",
      "Atributo: 0\n",
      "Atributo: 1\n",
      "Atributo: 2\n",
      "Atributo: 3\n",
      "Atributo: 4\n",
      "Atributo: 5\n",
      "Atributo: 6\n",
      "Atributo: 7\n",
      "Atributo: 8\n",
      "Atributo: 9\n",
      "Atributo: 10\n",
      "Atributo: 11\n",
      "Atributo: 12\n",
      "Atributo: 13\n",
      "Atributo: 14\n",
      "Atributo: 15\n",
      "Atributo: 16\n",
      "Atributo: 17\n",
      "Atributo: 18\n",
      "Atributo: 19\n",
      "Atributo: 20\n",
      "Atributo: 21\n",
      "Atributo: 22\n",
      "Atributo: 23\n",
      "Atributo: 24\n",
      "Atributo: 25\n",
      "Atributo: 26\n",
      "Atributo: 27\n",
      "Atributo: 28\n",
      "Atributo: 29\n",
      "Atributo: 30\n",
      "Atributo: 31\n",
      "Atributo: 32\n",
      "Atributo: 33\n",
      "Atributo: 34\n",
      "Atributo: 35\n",
      "Atributo: 36\n",
      "Atributo: 37\n",
      "Atributo: 38\n",
      "Atributo: 39\n",
      "Atributo: 40\n",
      "Atributo: 41\n",
      "Atributo: 42\n",
      "Atributo: 43\n",
      "Atributo: 44\n",
      "Atributo: 45\n",
      "Atributo: 46\n",
      "Atributo: 47\n",
      "Atributo: 48\n",
      "Atributo: 49\n",
      "Atributo: 50\n",
      "Atributo: 51\n",
      "Atributo: 52\n",
      "Atributo: 53\n",
      "Atributo: 54\n",
      "Atributo: 55\n",
      "Atributo: 56\n",
      "Atributo: 57\n",
      "Atributo: 58\n",
      "Atributo: 59\n",
      "Atributo: 60\n",
      "Atributo: 61\n",
      "Atributo: 62\n",
      "Atributo: 63\n",
      "Atributo: 64\n",
      "Atributo: 65\n",
      "Atributo: 66\n",
      "Atributo: 67\n",
      "Atributo: 68\n",
      "Atributo: 69\n",
      "Atributo: 70\n",
      "Atributo: 71\n",
      "Atributo: 72\n",
      "Atributo: 73\n",
      "Atributo: 74\n",
      "Atributo: 75\n",
      "Atributo: 76\n",
      "Atributo: 77\n",
      "Atributo: 78\n",
      "Atributo: 79\n",
      "Atributo: 80\n",
      "Atributo: 81\n",
      "Atributo: 82\n",
      "Atributo: 83\n",
      "Atributo: 84\n",
      "Atributo: 85\n",
      "Atributo: 86\n",
      "Atributo: 87\n",
      "Atributo: 88\n",
      "Atributo: 89\n",
      "Atributo: 90\n",
      "Atributo: 91\n",
      "Atributo: 92\n",
      "Atributo: 93\n",
      "Atributo: 94\n",
      "Atributo: 95\n",
      "Atributo: 96\n",
      "Atributo: 97\n",
      "Atributo: 98\n",
      "Atributo: 99\n",
      "Atributo: 100\n",
      "Atributo: 101\n",
      "Atributo: 102\n",
      "Atributo: 103\n",
      "Atributo: 104\n",
      "Atributo: 105\n",
      "Atributo: 106\n",
      "Atributo: 107\n",
      "Atributo: 108\n",
      "Atributo: 109\n",
      "Atributo: 110\n",
      "Atributo: 111\n",
      "Atributo: 112\n",
      "Atributo: 113\n",
      "Atributo: 114\n",
      "Atributo: 115\n",
      "Atributo: 116\n",
      "Atributo: 117\n",
      "Atributo: 118\n",
      "Atributo: 119\n",
      "Atributo: 120\n",
      "Atributo: 121\n",
      "Atributo: 122\n",
      "Atributo: 123\n",
      "Atributo: 124\n",
      "Atributo: 125\n",
      "Atributo: 126\n",
      "Atributo: 127\n",
      "Atributo: 128\n",
      "Atributo: 129\n",
      "Atributo: 130\n",
      "Atributo: 131\n",
      "Atributo: 132\n",
      "Atributo: 133\n",
      "Atributo: 134\n",
      "Atributo: 135\n",
      "Atributo: 136\n",
      "Atributo: 137\n",
      "Atributo: 138\n",
      "Atributo: 139\n",
      "Atributo: 140\n",
      "Atributo: 141\n",
      "Atributo: 142\n",
      "Atributo: 143\n",
      "Atributo: 144\n",
      "Atributo: 145\n",
      "Atributo: 146\n",
      "Atributo: 147\n",
      "Atributo: 148\n",
      "Atributo: 149\n",
      "Atributo: 150\n",
      "Atributo: 151\n",
      "Atributo: 152\n",
      "Atributo: 153\n",
      "Atributo: 154\n",
      "Atributo: 155\n",
      "Atributo: 156\n",
      "Atributo: 157\n",
      "Atributo: 158\n",
      "Atributo: 159\n",
      "Atributo: 160\n",
      "Atributo: 161\n",
      "Atributo: 162\n",
      "Atributo: 163\n",
      "Atributo: 164\n",
      "Atributo: 165\n",
      "Atributo: 166\n",
      "Atributo: 167\n",
      "Atributo: 168\n",
      "Atributo: 169\n",
      "Atributo: 170\n",
      "Atributo: 171\n",
      "Atributo: 172\n",
      "Atributo: 173\n",
      "Atributo: 174\n",
      "Atributo: 175\n",
      "Atributo: 176\n",
      "Atributo: 177\n",
      "Atributo: 178\n",
      "Atributo: 179\n",
      "Atributo: 180\n",
      "Atributo: 181\n",
      "Atributo: 182\n",
      "Atributo: 183\n",
      "Atributo: 184\n",
      "Atributo: 185\n",
      "Atributo: 186\n",
      "Atributo: 187\n",
      "Atributo: 188\n",
      "Atributo: 189\n",
      "Atributo: 190\n",
      "Atributo: 191\n",
      "Atributo: 192\n",
      "Atributo: 193\n",
      "Atributo: 194\n",
      "Atributo: 195\n",
      "Atributo: 196\n",
      "Atributo: 197\n",
      "Atributo: 198\n",
      "Atributo: 199\n",
      "La mejor pregunta es ¿Es el valor para 122 menor o igual a 0.07759906013344077?, con una ganancia de 0.09688185605626276\n",
      "Atributo: 0\n",
      "Atributo: 1\n",
      "Atributo: 2\n",
      "Atributo: 3\n",
      "Atributo: 4\n",
      "Atributo: 5\n",
      "Atributo: 6\n",
      "Atributo: 7\n",
      "Atributo: 8\n",
      "Atributo: 9\n",
      "Atributo: 10\n",
      "Atributo: 11\n",
      "Atributo: 12\n",
      "Atributo: 13\n",
      "Atributo: 14\n",
      "Atributo: 15\n",
      "Atributo: 16\n",
      "Atributo: 17\n",
      "Atributo: 18\n",
      "Atributo: 19\n",
      "Atributo: 20\n",
      "Atributo: 21\n",
      "Atributo: 22\n",
      "Atributo: 23\n",
      "Atributo: 24\n",
      "Atributo: 25\n",
      "Atributo: 26\n",
      "Atributo: 27\n",
      "Atributo: 28\n",
      "Atributo: 29\n",
      "Atributo: 30\n",
      "Atributo: 31\n",
      "Atributo: 32\n",
      "Atributo: 33\n",
      "Atributo: 34\n",
      "Atributo: 35\n",
      "Atributo: 36\n",
      "Atributo: 37\n",
      "Atributo: 38\n",
      "Atributo: 39\n",
      "Atributo: 40\n",
      "Atributo: 41\n",
      "Atributo: 42\n",
      "Atributo: 43\n",
      "Atributo: 44\n",
      "Atributo: 45\n",
      "Atributo: 46\n",
      "Atributo: 47\n",
      "Atributo: 48\n",
      "Atributo: 49\n",
      "Atributo: 50\n",
      "Atributo: 51\n",
      "Atributo: 52\n",
      "Atributo: 53\n",
      "Atributo: 54\n",
      "Atributo: 55\n",
      "Atributo: 56\n",
      "Atributo: 57\n",
      "Atributo: 58\n",
      "Atributo: 59\n",
      "Atributo: 60\n",
      "Atributo: 61\n",
      "Atributo: 62\n",
      "Atributo: 63\n",
      "Atributo: 64\n",
      "Atributo: 65\n",
      "Atributo: 66\n",
      "Atributo: 67\n",
      "Atributo: 68\n",
      "Atributo: 69\n",
      "Atributo: 70\n",
      "Atributo: 71\n",
      "Atributo: 72\n",
      "Atributo: 73\n",
      "Atributo: 74\n",
      "Atributo: 75\n",
      "Atributo: 76\n",
      "Atributo: 77\n",
      "Atributo: 78\n",
      "Atributo: 79\n",
      "Atributo: 80\n",
      "Atributo: 81\n",
      "Atributo: 82\n",
      "Atributo: 83\n",
      "Atributo: 84\n",
      "Atributo: 85\n",
      "Atributo: 86\n",
      "Atributo: 87\n",
      "Atributo: 88\n",
      "Atributo: 89\n",
      "Atributo: 90\n",
      "Atributo: 91\n",
      "Atributo: 92\n",
      "Atributo: 93\n",
      "Atributo: 94\n",
      "Atributo: 95\n",
      "Atributo: 96\n",
      "Atributo: 97\n",
      "Atributo: 98\n",
      "Atributo: 99\n",
      "Atributo: 100\n",
      "Atributo: 101\n",
      "Atributo: 102\n",
      "Atributo: 103\n",
      "Atributo: 104\n",
      "Atributo: 105\n",
      "Atributo: 106\n",
      "Atributo: 107\n",
      "Atributo: 108\n",
      "Atributo: 109\n",
      "Atributo: 110\n",
      "Atributo: 111\n",
      "Atributo: 112\n",
      "Atributo: 113\n",
      "Atributo: 114\n",
      "Atributo: 115\n",
      "Atributo: 116\n",
      "Atributo: 117\n",
      "Atributo: 118\n",
      "Atributo: 119\n",
      "Atributo: 120\n",
      "Atributo: 121\n",
      "Atributo: 122\n",
      "Atributo: 123\n",
      "Atributo: 124\n",
      "Atributo: 125\n",
      "Atributo: 126\n",
      "Atributo: 127\n",
      "Atributo: 128\n",
      "Atributo: 129\n",
      "Atributo: 130\n",
      "Atributo: 131\n",
      "Atributo: 132\n",
      "Atributo: 133\n",
      "Atributo: 134\n",
      "Atributo: 135\n",
      "Atributo: 136\n",
      "Atributo: 137\n",
      "Atributo: 138\n",
      "Atributo: 139\n",
      "Atributo: 140\n",
      "Atributo: 141\n",
      "Atributo: 142\n",
      "Atributo: 143\n",
      "Atributo: 144\n",
      "Atributo: 145\n",
      "Atributo: 146\n",
      "Atributo: 147\n",
      "Atributo: 148\n",
      "Atributo: 149\n",
      "Atributo: 150\n",
      "Atributo: 151\n",
      "Atributo: 152\n",
      "Atributo: 153\n",
      "Atributo: 154\n",
      "Atributo: 155\n",
      "Atributo: 156\n",
      "Atributo: 157\n",
      "Atributo: 158\n",
      "Atributo: 159\n",
      "Atributo: 160\n",
      "Atributo: 161\n",
      "Atributo: 162\n",
      "Atributo: 163\n",
      "Atributo: 164\n",
      "Atributo: 165\n",
      "Atributo: 166\n",
      "Atributo: 167\n",
      "Atributo: 168\n",
      "Atributo: 169\n",
      "Atributo: 170\n",
      "Atributo: 171\n",
      "Atributo: 172\n",
      "Atributo: 173\n",
      "Atributo: 174\n",
      "Atributo: 175\n",
      "Atributo: 176\n",
      "Atributo: 177\n",
      "Atributo: 178\n",
      "Atributo: 179\n",
      "Atributo: 180\n",
      "Atributo: 181\n",
      "Atributo: 182\n",
      "Atributo: 183\n",
      "Atributo: 184\n",
      "Atributo: 185\n",
      "Atributo: 186\n",
      "Atributo: 187\n",
      "Atributo: 188\n",
      "Atributo: 189\n",
      "Atributo: 190\n",
      "Atributo: 191\n",
      "Atributo: 192\n",
      "Atributo: 193\n",
      "Atributo: 194\n",
      "Atributo: 195\n",
      "Atributo: 196\n",
      "Atributo: 197\n",
      "Atributo: 198\n",
      "Atributo: 199\n",
      "La mejor pregunta es ¿Es el valor para 96 menor o igual a 0.1890699747252976?, con una ganancia de 0.05831297486177739\n",
      "Atributo: 0\n",
      "Atributo: 1\n",
      "Atributo: 2\n",
      "Atributo: 3\n",
      "Atributo: 4\n",
      "Atributo: 5\n",
      "Atributo: 6\n",
      "Atributo: 7\n",
      "Atributo: 8\n",
      "Atributo: 9\n",
      "Atributo: 10\n",
      "Atributo: 11\n",
      "Atributo: 12\n",
      "Atributo: 13\n",
      "Atributo: 14\n",
      "Atributo: 15\n",
      "Atributo: 16\n",
      "Atributo: 17\n",
      "Atributo: 18\n",
      "Atributo: 19\n",
      "Atributo: 20\n",
      "Atributo: 21\n",
      "Atributo: 22\n",
      "Atributo: 23\n",
      "Atributo: 24\n",
      "Atributo: 25\n",
      "Atributo: 26\n",
      "Atributo: 27\n",
      "Atributo: 28\n",
      "Atributo: 29\n",
      "Atributo: 30\n",
      "Atributo: 31\n",
      "Atributo: 32\n",
      "Atributo: 33\n",
      "Atributo: 34\n",
      "Atributo: 35\n",
      "Atributo: 36\n",
      "Atributo: 37\n",
      "Atributo: 38\n",
      "Atributo: 39\n",
      "Atributo: 40\n",
      "Atributo: 41\n",
      "Atributo: 42\n",
      "Atributo: 43\n",
      "Atributo: 44\n",
      "Atributo: 45\n",
      "Atributo: 46\n",
      "Atributo: 47\n",
      "Atributo: 48\n",
      "Atributo: 49\n",
      "Atributo: 50\n",
      "Atributo: 51\n",
      "Atributo: 52\n",
      "Atributo: 53\n",
      "Atributo: 54\n",
      "Atributo: 55\n",
      "Atributo: 56\n",
      "Atributo: 57\n",
      "Atributo: 58\n",
      "Atributo: 59\n",
      "Atributo: 60\n",
      "Atributo: 61\n",
      "Atributo: 62\n",
      "Atributo: 63\n",
      "Atributo: 64\n",
      "Atributo: 65\n",
      "Atributo: 66\n",
      "Atributo: 67\n",
      "Atributo: 68\n",
      "Atributo: 69\n",
      "Atributo: 70\n",
      "Atributo: 71\n",
      "Atributo: 72\n",
      "Atributo: 73\n",
      "Atributo: 74\n",
      "Atributo: 75\n",
      "Atributo: 76\n",
      "Atributo: 77\n",
      "Atributo: 78\n",
      "Atributo: 79\n",
      "Atributo: 80\n",
      "Atributo: 81\n",
      "Atributo: 82\n",
      "Atributo: 83\n",
      "Atributo: 84\n",
      "Atributo: 85\n",
      "Atributo: 86\n",
      "Atributo: 87\n",
      "Atributo: 88\n",
      "Atributo: 89\n",
      "Atributo: 90\n",
      "Atributo: 91\n",
      "Atributo: 92\n",
      "Atributo: 93\n",
      "Atributo: 94\n",
      "Atributo: 95\n",
      "Atributo: 96\n",
      "Atributo: 97\n",
      "Atributo: 98\n",
      "Atributo: 99\n",
      "Atributo: 100\n",
      "Atributo: 101\n",
      "Atributo: 102\n",
      "Atributo: 103\n",
      "Atributo: 104\n",
      "Atributo: 105\n",
      "Atributo: 106\n",
      "Atributo: 107\n",
      "Atributo: 108\n",
      "Atributo: 109\n",
      "Atributo: 110\n",
      "Atributo: 111\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################################\n",
    "#Ejercicio extra\n",
    "\n",
    "# Definición de la clase \"Pregunta\"\n",
    "class Pregunta:\n",
    "    def __init__(self, atributo, valor):\n",
    "        self.atributo = atributo\n",
    "        self.valor = valor\n",
    "    \n",
    "    def cumple(self, instancia):\n",
    "        return instancia[self.atributo] <= self.valor\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"¿Es el valor para {} menor o igual a {}?\".format(self.atributo, self.valor)\n",
    "\n",
    "##################################################################################################################\n",
    "# Definición de la estructura del árbol. \n",
    "class Hoja:\n",
    "    #  Contiene las cuentas para cada clase (en forma de diccionario)\n",
    "    #  Por ejemplo, {'Si': 2, 'No': 2}\n",
    "    def __init__(self, etiquetas):\n",
    "        self.cuentas = dict(Counter(etiquetas))\n",
    "\n",
    "class Nodo_De_Decision:\n",
    "    # Un Nodo de Decisión contiene preguntas y una referencia al sub-árbol izquierdo y al sub-árbol derecho\n",
    "    def __init__(self, pregunta, sub_arbol_izquierdo, sub_arbol_derecho):\n",
    "        self.pregunta = pregunta\n",
    "        self.sub_arbol_izquierdo = sub_arbol_izquierdo\n",
    "        self.sub_arbol_derecho = sub_arbol_derecho    \n",
    "\n",
    "        \n",
    "# creo que no anda\n",
    "#Este metodo se llama al principio, cuando estan todas las instancias y etiquetas\n",
    "#def construir_cache_bordes(instancias, etiquetas):\n",
    "#    if len(instancias) <= 1:\n",
    "#        return\n",
    "#    cache_bordes = {}\n",
    "#    for atributo in instancias.columns:\n",
    "#        cache_bordes[atributo] = {}\n",
    "#        \n",
    "#        valores = instancias.loc[:, atributo]\n",
    "#        indices_valores_ordenados = valores.argsort()\n",
    "#        \n",
    "#        anterior_indice = indices_valores_ordenados.iloc[0]\n",
    "#        anterior_valor = valores[anterior_indice]\n",
    "#        anterior_etiqueta = etiquetas[anterior_indice]\n",
    "#\n",
    "#        for actual_indice, in indices_valores_ordenados:\n",
    "#            #Indice representa el numero de la instancia que estoy mirando\n",
    "#            actual_valor = valores[actual_indice]\n",
    "#            actual_etiqueta = etiquetas[actual_indice]\n",
    "#            if actual_etiqueta != anterior_etiqueta:\n",
    "#                par = [anterior_indice, indice] if anterior_indice < indice else [indice, anterior_indice]\n",
    "#                cache_bordes[atributo][par] = ((anterior_valor + actual_valor)/2)\n",
    "#            anterior_indice = actual_indice\n",
    "#            anterior_valor = actual_valor\n",
    "#            anterior_etiqueta = actual_etiqueta\n",
    "#        return bordes\n",
    "    \n",
    "##################################################################################################################\n",
    "def construir_arbol(instancias, etiquetas, altura, criterio):\n",
    "    # ALGORITMO RECURSIVO para construcción de un árbol de decisión binario. \n",
    "    # Suponemos que estamos parados en la raiz del árbol y tenemos que decidir cómo construirlo. \n",
    "    if rama_terminada(etiquetas):\n",
    "        return Hoja(etiquetas)\n",
    "    \n",
    "    ganancia, pregunta = encontrar_mejor_atributo_y_corte(instancias, etiquetas, criterio)\n",
    "    # Criterio de corte: ¿Hay ganancia?\n",
    "    if ganancia == 0 or (altura != None and altura == 0):\n",
    "        #  Si no hay ganancia en separar, o llegue a la altura requerida, corto la recursion. \n",
    "        return Hoja(etiquetas)\n",
    "    # Si hay ganancia en partir el conjunto en 2\n",
    "    instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen = partir_segun(pregunta, instancias, etiquetas)\n",
    "    # partir devuelve instancias y etiquetas que caen en cada rama (izquierda y derecha)\n",
    "\n",
    "    altura_rec = None if(altura == None) else altura - 1\n",
    "    # Paso recursivo (consultar con el computador más cercano)\n",
    "    sub_arbol_izquierdo = construir_arbol(instancias_cumplen, etiquetas_cumplen, altura_rec, criterio)\n",
    "    sub_arbol_derecho   = construir_arbol(instancias_no_cumplen, etiquetas_no_cumplen, altura_rec, criterio)\n",
    "    # los pasos anteriores crean todo lo que necesitemos de sub-árbol izquierdo y sub-árbol derecho\n",
    "\n",
    "    # sólo falta conectarlos con un nodo de decisión:\n",
    "    return Nodo_De_Decision(pregunta, sub_arbol_izquierdo, sub_arbol_derecho)\n",
    "\n",
    "def rama_terminada(etiquetas):\n",
    "    return len(etiquetas) <= 1 or len(set(etiquetas)) == 1\n",
    "\n",
    "\n",
    "def encontrar_mejor_atributo_y_corte(instancias, etiquetas, criterio):\n",
    "    max_ganancia = 0\n",
    "    mejor_pregunta = None\n",
    "    for columna in instancias.columns:\n",
    "        #Generar valores borde\n",
    "        if atributo % 10 == 0:\n",
    "            print(\"Atributo: {}\".format(columna))\n",
    "        bordes = generar_valores_borde_random(instancias, etiquetas, columna)\n",
    "        #print(\"Bordes {}\".format(bordes))\n",
    "        for valor in bordes:\n",
    "            # Probando corte para atributo y valor\n",
    "            pregunta = Pregunta(columna, valor)\n",
    "            #print('Pregunta: {}'.format(pregunta))\n",
    "            _, etiquetas_rama_izquierda, _, etiquetas_rama_derecha = partir_segun(pregunta, instancias, etiquetas)\n",
    "            #Ver como refactorizar\n",
    "            if(criterio == 'gini'):\n",
    "                ganancia = ganancia_gini(instancias, etiquetas, etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
    "            else:\n",
    "                ganancia = ganancia_entropia(instancias, etiquetas, etiquetas_rama_izquierda, etiquetas_rama_derecha)\n",
    "            #print(\"La ganancia para la pregunta {}, es {}\".format(pregunta, ganancia))\n",
    "            if ganancia > max_ganancia:\n",
    "                max_ganancia = ganancia\n",
    "                mejor_pregunta = pregunta\n",
    "    print(\"La mejor pregunta es {}, con una ganancia de {}\".format(mejor_pregunta, max_ganancia))        \n",
    "    return max_ganancia, mejor_pregunta\n",
    "    \n",
    "#Version mejorada\n",
    "def generar_valores_borde(instancias, etiquetas, columna):\n",
    "    #El metodo argsort de numpy returns the indices that would sort an array.\n",
    "    bordes = []\n",
    "    if len(instancias) <= 1:\n",
    "        return bordes\n",
    "    for atributo in instancias.columns:\n",
    "        valores = instancias.loc[:, atributo]\n",
    "        indices_valores_ordenados = valores.argsort()\n",
    "        \n",
    "        anterior_indice = indices_valores_ordenados.iloc[0]\n",
    "        anterior_valor = valores[anterior_indice]\n",
    "        anterior_etiqueta = etiquetas[anterior_indice]\n",
    "\n",
    "        for actual_indice in indices_valores_ordenados:\n",
    "            #Indice representa el numero de la instancia que estoy mirando\n",
    "            actual_valor = valores[actual_indice]\n",
    "            actual_etiqueta = etiquetas[actual_indice]\n",
    "            if actual_etiqueta != anterior_etiqueta:\n",
    "                bordes.append((anterior_valor + actual_valor)/2)\n",
    "            anterior_indice = actual_indice\n",
    "            anterior_valor = actual_valor\n",
    "            anterior_etiqueta = actual_etiqueta\n",
    "        return bordes\n",
    "\n",
    "def generar_valores_borde_random(instancias, etiquetas, columna):\n",
    "    #Pruebo 25% de los valores totales, seleccionados de manera random, como bordes\n",
    "    valores = instancias.loc[:, columna]\n",
    "    return valores.sample(frac=0.25)\n",
    "\n",
    "def partir_segun(pregunta, instancias, etiquetas):\n",
    "    # Esta función debe separar instancias y etiquetas según si cada instancia cumple o no con la pregunta (ver método 'cumple')\n",
    "    # COMPLETAR (recomendamos utilizar máscaras para este punto)\n",
    "    instancias_cumplen = pd.DataFrame(columns=instancias.columns)\n",
    "    instancias_no_cumplen = pd.DataFrame(columns=instancias.columns)\n",
    "     \n",
    "    columna_etiqueta = pd.DataFrame(data=etiquetas, index=instancias.index, columns=['etiqueta'])\n",
    "    instancias_con_etiqueta = pd.concat([instancias, columna_etiqueta], axis=1)\n",
    "    instancias_cumplen_etiqueta = instancias_con_etiqueta.where(pregunta.cumple(instancias_con_etiqueta)).dropna()\n",
    "    instancias_no_cumplen_etiqueta = instancias_con_etiqueta.mask(pregunta.cumple(instancias_con_etiqueta)).dropna()\n",
    "    etiquetas_cumplen = instancias_cumplen_etiqueta.loc[:,'etiqueta'].tolist()\n",
    "    etiquetas_no_cumplen = instancias_no_cumplen_etiqueta.loc[:,'etiqueta'].tolist()\n",
    "    \n",
    "    del instancias_cumplen_etiqueta['etiqueta']\n",
    "    del instancias_no_cumplen_etiqueta['etiqueta']\n",
    "    \n",
    "    instancias_cumplen = instancias_cumplen_etiqueta\n",
    "    instancias_no_cumplen = instancias_no_cumplen_etiqueta\n",
    "    \n",
    "    return instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen\n",
    "\n",
    "#Version numpy-> No se como hacerlo\n",
    "# sigue estando el mismo problema  np.apply_along_axis(pregunta.cumple, 1, instancias)\n",
    "\n",
    "\"\"\"\n",
    "#Intento de mejora\n",
    "def partir_segun(pregunta, instancias, etiquetas):\n",
    "    # Esta función debe separar instancias y etiquetas según si cada instancia cumple o no con la pregunta (ver método 'cumple')\n",
    "    # COMPLETAR (recomendamos utilizar máscaras para este punto)\n",
    "    instancias_cumplen = pd.DataFrame(columns=instancias.columns)\n",
    "    instancias_no_cumplen = pd.DataFrame(columns=instancias.columns)\n",
    "     \n",
    "    instancias_cumplen = instancias.where(pregunta.cumple(instancias)).dropna()\n",
    "    instancias_no_cumplen = instancias.mask(pregunta.cumple(instancias)).dropna()\n",
    "    etiquetas_cumplen = etiquetas.iloc[instancias_cumplen.index]\n",
    "    etiquetas_no_cumplen = etiquetas.iloc[instancias_no_cumplen.index]\n",
    "    \n",
    "    return instancias_cumplen, etiquetas_cumplen, instancias_no_cumplen, etiquetas_no_cumplen\n",
    "\"\"\"\n",
    "diccionario_gini = {}\n",
    "diccionario_entropia = {}\n",
    "\n",
    "#Como hago para refactorizar esto?\n",
    "def gini(etiquetas):\n",
    "    diccionario = dict(Counter(etiquetas))\n",
    "\n",
    "    tupla = (diccionario.get(0, 0), diccionario.get(1, 0))\n",
    "    if tupla in diccionario_gini:\n",
    "        return diccionario_gini[tupla]\n",
    "    suma = 0\n",
    "    for etiqueta in diccionario.keys():\n",
    "        suma += (diccionario[etiqueta]/len(etiquetas))**2\n",
    "    impureza = 1 - suma\n",
    "    diccionario_gini[tupla] = impureza\n",
    "    return impureza\n",
    "\n",
    "def ganancia_gini(instancias, etiquetas, etiquetas_rama_izquierda, etiquetas_rama_derecha):\n",
    "    n_izq = len(etiquetas_rama_izquierda)\n",
    "    n_der = len(etiquetas_rama_derecha)\n",
    "    n = len(etiquetas)\n",
    "    \n",
    "    gini_total = gini(etiquetas)\n",
    "    gini_izq = gini(etiquetas_rama_izquierda)\n",
    "    gini_der = gini(etiquetas_rama_derecha)\n",
    "    \n",
    "    ganancia_gini = gini_total - ((n_izq/n)*gini_izq + (n_der/n)*gini_der)\n",
    "    \n",
    "    return ganancia_gini\n",
    "\n",
    "def entropia(etiquetas):\n",
    "    diccionario = dict(Counter(etiquetas))\n",
    "    tupla = (diccionario.get(0, 0), diccionario.get(1, 0))\n",
    "    if tupla in diccionario_entropia:\n",
    "        return diccionario_entropia[tupla]\n",
    "    entropia = 0\n",
    "    for etiqueta in diccionario.keys():\n",
    "        proporcion = diccionario[etiqueta]/len(etiquetas)\n",
    "        entropia += -proporcion*log(proporcion,2)\n",
    "    diccionario_entropia[tupla] = entropia\n",
    "    return entropia\n",
    "\n",
    "def ganancia_entropia(instancias, etiquetas, etiquetas_rama_izquierda, etiquetas_rama_derecha):\n",
    "    n_izq = len(etiquetas_rama_izquierda)\n",
    "    n_der = len(etiquetas_rama_derecha)\n",
    "    n = len(etiquetas)\n",
    "    \n",
    "    entropia_total = entropia(etiquetas)\n",
    "    entropia_izq = entropia(etiquetas_rama_izquierda)\n",
    "    entropia_der = entropia(etiquetas_rama_derecha)\n",
    "    \n",
    "    ganancia_entropia = entropia_total - ((n_izq/n)*entropia_izq + (n_der/n)*entropia_der)\n",
    "    \n",
    "    return ganancia_gini\n",
    "\n",
    "def imprimir_arbol(arbol, spacing=\"\"):\n",
    "    if isinstance(arbol, Hoja):\n",
    "        print (spacing + \"Hoja:\", arbol.cuentas)\n",
    "        return\n",
    "\n",
    "    print (spacing + str(arbol.pregunta))\n",
    "\n",
    "    print (spacing + '--> True:')\n",
    "    imprimir_arbol(arbol.sub_arbol_izquierdo, spacing + \"  \")\n",
    "\n",
    "    print (spacing + '--> False:')\n",
    "    imprimir_arbol(arbol.sub_arbol_derecho, spacing + \"  \")\n",
    "\n",
    "\n",
    "def predecir(arbol, x_t):\n",
    "    if isinstance(arbol, Hoja):\n",
    "        return max(arbol.cuentas, key=arbol.cuentas.get)\n",
    "    \n",
    "    if(arbol.pregunta.cumple(x_t)):\n",
    "        return predecir(arbol.sub_arbol_izquierdo, x_t)\n",
    "    else:\n",
    "        return predecir(arbol.sub_arbol_derecho, x_t)\n",
    "\n",
    "def predecir_proba(arbol, x_t):\n",
    "    if isinstance(arbol, Hoja):\n",
    "        #Retorno la probabilidad de que la clase sea 'Si'\n",
    "        return arbol.cuentas.get(1, 0)/(arbol.cuentas.get(1, 0) + arbol.cuentas.get(0, 0))\n",
    "    \n",
    "    if(arbol.pregunta.cumple(x_t)):\n",
    "        return predecir(arbol.sub_arbol_izquierdo, x_t)\n",
    "    else:\n",
    "        return predecir(arbol.sub_arbol_derecho, x_t)\n",
    "\n",
    "##################################################################################################################\n",
    "class MiClasificadorArbol(): \n",
    "    def __init__(self, columnas=None):\n",
    "        self.arbol = None\n",
    "        self.columnas = columnas\n",
    "    \n",
    "    def fit(self, X_train, y_train, max_depth=None, criterion='gini'):\n",
    "        self.arbol = construir_arbol(pd.DataFrame(X_train, columns=self.columnas), y_train, max_depth, criterion)\n",
    "        imprimir_arbol(self.arbol)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for x_t in X_test:\n",
    "            x_t_df = pd.DataFrame([x_t], columns=self.columnas).iloc[0]\n",
    "            prediction = predecir(self.arbol, x_t_df) \n",
    "            #print(x_t, \"predicción ->\", prediction)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        predictions = []\n",
    "        for x_t in X_test:\n",
    "            x_t_df = pd.DataFrame([x_t], columns=self.columnas).iloc[0]\n",
    "            prediction = predecir_proba(self.arbol, x_t_df) \n",
    "            #print(x_t, \"predicción ->\", prediction)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        \n",
    "        accuracy = sum(y_i == y_j for (y_i, y_j) in zip(y_pred, y_test)) / len(y_test)\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "##################################################################################################################\n",
    "def get_dt_scores(train_indexes, test_indexes, decision_tree_criterion=\"gini\", max_depth=3, metrics=[roc_auc_score]):\n",
    "    X_train, X_test = X_dev_np[train_indexes], X_dev_np[test_indexes]\n",
    "    y_train, y_test = y_dev_np[train_indexes], y_dev_np[test_indexes]\n",
    "    \n",
    "    iteration_classifier = MiClasificadorArbol()\n",
    "    iteration_classifier.fit(X_train, y_train, max_depth, decision_tree_criterion)\n",
    "    \n",
    "    metrics_scores = []\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric == accuracy_score:\n",
    "            y_test_prediction = iteration_classifier.predict(X_test)\n",
    "            metrics_scores.append(accuracy_score(y_test, y_test_prediction))\n",
    "\n",
    "            y_train_prediction = iteration_classifier.predict(X_train)\n",
    "            metrics_scores.append(accuracy_score(y_train, y_train_prediction))\n",
    "        elif metric == roc_auc_score:\n",
    "            #Nuestro predictor solamente devuelve la probabilidad de la clase positiva\n",
    "            y_test_proba_prediction = iteration_classifier.predict_proba(X_test)\n",
    "            metrics_scores.append(roc_auc_score(y_test, y_test_proba_prediction))\n",
    "\n",
    "            y_train_proba_prediction = iteration_classifier.predict_proba(X_train)\n",
    "            metrics_scores.append(roc_auc_score(y_train, y_train_proba_prediction))\n",
    "    \n",
    "    return metrics_scores\n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################################################\n",
    "resultados_training = []\n",
    "resultados_validation = []\n",
    "\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "    for altura in [3, 5, None]:\n",
    "        kf = KFold(n_splits=5)\n",
    "        auc_roc_test_list, auc_roc_train_list = [], []\n",
    "        print(\"Criterio: {}, Altura: {}\".format(criterio, altura))\n",
    "        contador_fold = 1\n",
    "        for train_index, test_index in kf.split(X_dev_np):\n",
    "            print(\"Probando fold: {}\".format(contador_fold))\n",
    "            contador_fold+=1\n",
    "            [auc_roc_test_fold, auc_roc_train_fold] = get_dt_scores(train_index, test_index, decision_tree_criterion=criterio, max_depth = altura, metrics = [roc_auc_score])\n",
    "            \n",
    "            auc_roc_test_list.append(auc_roc_test_fold)\n",
    "            auc_roc_train_list.append(auc_roc_train_fold)\n",
    "        resultados_training.append( sum(auc_roc_train_list) / len(auc_roc_train_list) )\n",
    "        resultados_validation.append( sum(auc_roc_test_list) / len(auc_roc_test_list) )\n",
    "###################################################################################################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"] = resultados_training # reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "   \n",
    "display(HTML(\"<h3> TABLA EJERCICIO EXTRA </h3>\"))\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def top_resultados(grid, method, top=25):\n",
    "    print(\"Top {} combinaciones para \".format(top) + method)\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    \n",
    "    # Este sorting score se considero una mejor opción comparado con buscar el mayor mean_score_validation\n",
    "    # porque de esta manera cobra algo de influencia la posibilidad de que el modelo elegido\n",
    "    # presente overfitting, dándole algo de peso a la cercanía entre su validation y training score\n",
    "    sorting_score = df['mean_score_validation'] - (df['mean_score_validation'] - df['mean_score_training'])**2\n",
    "    \n",
    "    df = df \\\n",
    "        .assign(sorting_score = sorting_score) \\\n",
    "        .sort_values('sorting_score', ascending=False) \\\n",
    "        .drop('sorting_score', axis=1)\n",
    "    \n",
    "    pd.options.display.max_rows = 50\n",
    "    display(df.head(top))\n",
    "    print('\\n\\n\\n')\n",
    "\n",
    "########################################################\n",
    "## AQUI VA SU CODIGO \n",
    "## Objetivo: comparar y explorar distintas combinaciones de parámetros para los algoritmos importados arriba\n",
    "\n",
    "iteraciones = 50\n",
    "\n",
    "def doSearch(searchType, clasiffier, parameters):\n",
    "    if searchType == 'grid':\n",
    "        gridSearch = GridSearchCV(clasiffier, parameters, cv=5, scoring=make_scorer(roc_auc_score), return_train_score=True)\n",
    "        gridSearch.fit(X_dev_np, y_dev_np)\n",
    "        return gridSearch\n",
    "\n",
    "    if searchType == 'random':\n",
    "        randomSearch = RandomizedSearchCV(clasiffier, param_distributions=parameters, n_iter=iteraciones, cv=5, scoring=make_scorer(roc_auc_score), refit=True)\n",
    "        randomSearch.fit(X_dev_np, y_dev_np)\n",
    "        return randomSearch\n",
    "\n",
    "#searchs = [{'grid'},{'random'}]\n",
    "#lda_parameters_grid = [{'solver': ['lsqr'], 'shrinkage': [0, 1]}, {'solver': ['lsqr']},\n",
    "#                        {'solver': ['eigen'], 'shrinkage': [0, 1]}, {'solver': ['eigen']}]\n",
    "#shrinkage: solo esta disponible para lsqr y eigen. Por defecto: 'shrinkage':None \n",
    "#lda_parameters_random = {'solver': ['lsqr','eigen','svd'], 'shrinkage': [np.arange(0, 1, 0.000001)]}\n",
    "\n",
    "#lda_parameters_random = {'solver': ['lsqr'], 'shrinkage': np.arange(0, 1, 0.000001)}\n",
    "\n",
    "#tree_parameters_grid = [{'class_weight': ['balanced', None], 'max_features': [None, 100, 'auto'], 'max_depth':  np.arange(1, 50, 2),'criterion': ('gini','entropy') }]\n",
    "#tree_parameters_random = {'class_weight': ['balanced', None], 'max_features': [None, 100, 'auto'], 'max_depth': np.arange(1, 50, 2),'criterion': ('gini','entropy') }\n",
    "\n",
    "# tree_parameters_random = {'max_depth':np.append(np.arange(1, 41), None),'criterion': ('gini','entropy') }\n",
    "#knn_parameters_grid = {'n_neighbors': [1,2,3,5,10,20,30,40,100],'p': np.arange(1,3), \"weights\" : ['uniform', 'distance']}\n",
    "#knn_parameters_random = {'n_neighbors': np.arange(1, 101), 'p': np.arange(1,3), \"weights\" : ['uniform', 'distance']}\n",
    "#svm_parameters_grid = [{'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma': [1e-1, 1e-2,1e-3, 1e-4], 'C': [1, 10, 100]}, {'kernel': ['linear'], 'C': [1, 10, 100]}]\n",
    "#svm_parameters_random = {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':sp.stats.expon(scale=.1),'C': sp.stats.expon(scale=10)}\n",
    "\n",
    "#KNN\n",
    "#grid_KNN_result = doSearch('grid', KNeighborsClassifier(), knn_parameters_grid)\n",
    "#top_resultados(grid_KNN_result, \"KNN GridSearch\")\n",
    "#random_KNN_result =  doSearch('random', KNeighborsClassifier(), knn_parameters_random)\n",
    "#top_resultados(random_KNN_result, \"KNN RandomSearch\")\n",
    "\n",
    "#Arbol\n",
    "#grid_tree_result = doSearch('grid', DecisionTreeClassifier(), tree_parameters_grid)\n",
    "#top_resultados(grid_tree_result, \"Decision Tree GridSearch\")\n",
    "#random_tree_result = doSearch('random', DecisionTreeClassifier(), tree_parameters_random)\n",
    "#top_resultados(random_tree_result, \"Decision Tree RandomSearch\")\n",
    "\n",
    "#LDA\n",
    "#grid_LDA_result = doSearch('grid', LinearDiscriminantAnalysis(), lda_parameters_grid)\n",
    "#top_resultados(grid_LDA_result, \"LDA GridSearch\")\n",
    "#random_LDA_result = doSearch('random', LinearDiscriminantAnalysis(), lda_parameters_random)\n",
    "#top_resultados(random_LDA_result, \"LDA RandomSearch\")\n",
    "\n",
    "#Naive Bayes Gaussiana\n",
    "#grid_gauss_result = doSearch('grid', GaussianNB(), {})\n",
    "#top_resultados(grid_gauss_result, \"Naive Gauss GridSearch\")\n",
    "#iteraciones = 1\n",
    "#random_gauss_result = doSearch('random', GaussianNB(), {})\n",
    "#top_resultados(random_gauss_result, \"Naive Gauss RandomSearch\")\n",
    "\n",
    "#SVM\n",
    "#grid_SVM_result = doSearch('grid', SVC(), svm_parameters_grid)\n",
    "#top_resultados(grid_SVM_result, \"SVM GridSearch\")\n",
    "#random_SVM_result = doSearch('random', SVC(), svm_parameters_random)\n",
    "#top_resultados(random_SVM_result, \"SVM RandomSearch\")\n",
    "\n",
    "\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección de Parametros para KNN:\n",
    "\n",
    "GridSearch:\n",
    "- n: Cantidad de vecinos: elegimos un rango entre 3 y 150 vecinos. Decidimos un valor impar como inicial para evitar problemas de empate en la frontera. Elegir un rango tan amplio nos permite ver en más detalle la interacción de los distintos parámetros. #comentar despues diferencias entre cantidad de vecinos alta ponderados por su distancia.\n",
    "- weights: para predecir los valores utilizaremos uniform y distance para asignarle pesos a los vecinos.\n",
    "- p: forma de calcular la distancia, utilizaremos la distancia euclidiana y la manhattan\n",
    "\n",
    "RandomSearch:\n",
    "La diferencia es que utilizaremos un rango de vecindad entre 3 y 200 de forma aleatoria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para KNN GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.7742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7590</td>\n",
       "      <td>0.7525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.7746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.7792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.7557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.7626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>0.7562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>0.7572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7394</td>\n",
       "      <td>0.7391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.7784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>0.7630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7336</td>\n",
       "      <td>0.7504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.7873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.8155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>0.7413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7162</td>\n",
       "      <td>0.7899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7213</td>\n",
       "      <td>0.8446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7565</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7062</td>\n",
       "      <td>0.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7508</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7486</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  p   weights  mean_score_validation  mean_score_training\n",
       "18           30  2   uniform                 0.7603               0.7742\n",
       "28          110  1   uniform                 0.7590               0.7525\n",
       "22           40  2   uniform                 0.7579               0.7746\n",
       "14           20  2   uniform                 0.7541               0.7792\n",
       "16           30  1   uniform                 0.7511               0.7740\n",
       "32          120  1   uniform                 0.7480               0.7557\n",
       "30          110  2   uniform                 0.7466               0.7626\n",
       "26          100  2   uniform                 0.7459               0.7562\n",
       "24          100  1   uniform                 0.7432               0.7572\n",
       "36          150  1   uniform                 0.7394               0.7391\n",
       "12           20  1   uniform                 0.7393               0.7784\n",
       "20           40  1   uniform                 0.7363               0.7630\n",
       "34          120  2   uniform                 0.7336               0.7504\n",
       "8            10  1   uniform                 0.7315               0.7873\n",
       "6             5  2   uniform                 0.7343               0.8155\n",
       "38          150  2   uniform                 0.7232               0.7413\n",
       "10           10  2   uniform                 0.7162               0.7899\n",
       "19           30  2  distance                 0.7631               1.0000\n",
       "2             3  2   uniform                 0.7213               0.8446\n",
       "23           40  2  distance                 0.7565               1.0000\n",
       "4             5  1   uniform                 0.7062               0.8265\n",
       "27          100  2  distance                 0.7514               1.0000\n",
       "29          110  1  distance                 0.7508               1.0000\n",
       "31          110  2  distance                 0.7500               1.0000\n",
       "17           30  1  distance                 0.7486               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 25 combinaciones para KNN RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>p</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7607</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>0.7655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.7712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>0.7856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7560</td>\n",
       "      <td>0.7606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.7612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7494</td>\n",
       "      <td>0.7603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7483</td>\n",
       "      <td>0.7633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7480</td>\n",
       "      <td>0.7688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>0.7573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>170</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7445</td>\n",
       "      <td>0.7373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>0.7588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>0.7789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7422</td>\n",
       "      <td>0.7390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7415</td>\n",
       "      <td>0.7345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>0.7414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.7793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7391</td>\n",
       "      <td>0.7405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7367</td>\n",
       "      <td>0.7475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7359</td>\n",
       "      <td>0.7413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7349</td>\n",
       "      <td>0.7217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0.7216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors  p  weights  mean_score_validation  mean_score_training\n",
       "20           56  2  uniform                 0.7607               0.7660\n",
       "1            83  2  uniform                 0.7600               0.7652\n",
       "44           61  2  uniform                 0.7580               0.7655\n",
       "19           76  2  uniform                 0.7566               0.7712\n",
       "24           22  2  uniform                 0.7569               0.7856\n",
       "12           60  2  uniform                 0.7560               0.7606\n",
       "4            85  2  uniform                 0.7528               0.7612\n",
       "6            85  1  uniform                 0.7494               0.7603\n",
       "33           43  1  uniform                 0.7483               0.7633\n",
       "40           34  1  uniform                 0.7480               0.7688\n",
       "16          104  2  uniform                 0.7466               0.7613\n",
       "13          126  1  uniform                 0.7456               0.7514\n",
       "30          101  2  uniform                 0.7452               0.7573\n",
       "28          170  2  uniform                 0.7445               0.7373\n",
       "48           42  1  uniform                 0.7428               0.7588\n",
       "0            33  1  uniform                 0.7436               0.7789\n",
       "17          137  1  uniform                 0.7422               0.7390\n",
       "11          156  1  uniform                 0.7415               0.7345\n",
       "14          132  2  uniform                 0.7404               0.7414\n",
       "49           21  1  uniform                 0.7410               0.7793\n",
       "22          162  1  uniform                 0.7391               0.7405\n",
       "32          121  2  uniform                 0.7367               0.7475\n",
       "2           130  2  uniform                 0.7359               0.7413\n",
       "38          189  1  uniform                 0.7349               0.7217\n",
       "7           187  1  uniform                 0.7325               0.7216"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_parameters_grid = {'n_neighbors': [3,5,10,20,30,40,100,110,120,150],'p': np.arange(1,3), \"weights\" : ['uniform', 'distance']}\n",
    "knn_parameters_random = {'n_neighbors': np.arange(3, 201), 'p': np.arange(1,3), \"weights\" : ['uniform', 'distance']}\n",
    "\n",
    "\n",
    "grid_KNN_result = doSearch('grid', KNeighborsClassifier(), knn_parameters_grid)\n",
    "top_resultados(grid_KNN_result, \"KNN GridSearch\")\n",
    "\n",
    "random_KNN_result =  doSearch('random', KNeighborsClassifier(), knn_parameters_random)\n",
    "top_resultados(random_KNN_result, \"KNN RandomSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones de KNN\n",
    "\n",
    "En general pareciera que usar pesos uniformes ha tenido más éxito tanto para Grid Search como para Random Search.\n",
    "\n",
    "Ni en Grid Search ni en Random Search se nota algún tipo de valor n_neighbors que supere por mucho al resto, aunque a simple vista pareciera que los valores mayores o iguales a 20 tienen más éxito.\n",
    "\n",
    "Las distancias Manhattan y euclideanas (p = 1 y 2) parecen ser claramente mejores que el p = 3 para este dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección de Parametros para Tree:\n",
    "\n",
    "GridSearch:\n",
    "- criterion: utilizaremos gini y entropy para decidir los splits\n",
    "- splitter: evaularemos con los criterios de best y random\n",
    "- max_depth: la altura del arbol la iniciaremos en 3, aumentandolo hasta 50. No consideramos arboles de altura mayor ya que se corre el riesgo de caer en overfitting. El objetivo seria buscar uno no tan alto pero que generalice bien.\n",
    "- max_features: la cantidad de instancias que se consideraran en un split inicial en 10 se ira aumentando hasta 100 y en auto\n",
    "\n",
    "RandomSearch:\n",
    "La diferencia es que utilizaremos valores random en la altura de 5 hasta 50 y para el split se consideraran valores random entre 1 y 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para Decision Tree GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>best</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>0.7815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.7636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6913</td>\n",
       "      <td>0.7552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>0.7221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.7433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.7254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6955</td>\n",
       "      <td>0.8187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.7698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>0.7462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6781</td>\n",
       "      <td>0.7365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.7263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.8213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.7812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.6708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6666</td>\n",
       "      <td>0.6888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.7379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.8051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6657</td>\n",
       "      <td>0.6977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.7648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.8057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>auto</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6626</td>\n",
       "      <td>0.6973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6727</td>\n",
       "      <td>0.7803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6728</td>\n",
       "      <td>0.7808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6630</td>\n",
       "      <td>0.7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6802</td>\n",
       "      <td>0.8221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_weight criterion  max_depth max_features splitter  \\\n",
       "8       balanced      gini          3           40     best   \n",
       "193         None      gini          3         None   random   \n",
       "206         None      gini          3         auto     best   \n",
       "289         None   entropy          3         None   random   \n",
       "110     balanced   entropy          3         auto     best   \n",
       "211         None      gini          5           10   random   \n",
       "219         None      gini          5           50   random   \n",
       "296         None   entropy          3           40     best   \n",
       "100     balanced   entropy          3           20     best   \n",
       "98      balanced   entropy          3           10     best   \n",
       "9       balanced      gini          3           40   random   \n",
       "12      balanced      gini          3          100     best   \n",
       "121     balanced   entropy          5           40   random   \n",
       "195         None      gini          3           10   random   \n",
       "203         None      gini          3           50   random   \n",
       "109     balanced   entropy          3          100   random   \n",
       "23      balanced      gini          5           30   random   \n",
       "207         None      gini          3         auto   random   \n",
       "311         None   entropy          5           30   random   \n",
       "123     balanced   entropy          5           50   random   \n",
       "15      balanced      gini          3         auto   random   \n",
       "106     balanced   entropy          3           50     best   \n",
       "315         None   entropy          5           50   random   \n",
       "103     balanced   entropy          3           30   random   \n",
       "125     balanced   entropy          5          100   random   \n",
       "\n",
       "     mean_score_validation  mean_score_training  \n",
       "8                   0.7150               0.7815  \n",
       "193                 0.7059               0.7636  \n",
       "206                 0.6913               0.7552  \n",
       "289                 0.6866               0.7221  \n",
       "110                 0.6869               0.7433  \n",
       "211                 0.6845               0.7254  \n",
       "219                 0.6955               0.8187  \n",
       "296                 0.6841               0.7698  \n",
       "100                 0.6802               0.7462  \n",
       "98                  0.6781               0.7365  \n",
       "9                   0.6732               0.7263  \n",
       "12                  0.6881               0.8213  \n",
       "121                 0.6790               0.7812  \n",
       "195                 0.6679               0.6708  \n",
       "203                 0.6666               0.6888  \n",
       "109                 0.6705               0.7379  \n",
       "23                  0.6812               0.8051  \n",
       "207                 0.6657               0.6977  \n",
       "311                 0.6725               0.7648  \n",
       "123                 0.6792               0.8057  \n",
       "15                  0.6626               0.6973  \n",
       "106                 0.6727               0.7803  \n",
       "315                 0.6728               0.7808  \n",
       "103                 0.6630               0.7106  \n",
       "125                 0.6802               0.8221  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 25 combinaciones para Decision Tree RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_weight</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>splitter</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.7884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.6716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6907</td>\n",
       "      <td>0.8379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>0.8145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.7318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>0.7168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>164</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.9510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>0.8983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>17</td>\n",
       "      <td>113</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6336</td>\n",
       "      <td>0.8218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6911</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6896</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>47</td>\n",
       "      <td>186</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>15</td>\n",
       "      <td>134</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6838</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>31</td>\n",
       "      <td>147</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6836</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>25</td>\n",
       "      <td>66</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>13</td>\n",
       "      <td>160</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>186</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>0.9390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>13</td>\n",
       "      <td>93</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>19</td>\n",
       "      <td>84</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>11</td>\n",
       "      <td>197</td>\n",
       "      <td>random</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.9977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>45</td>\n",
       "      <td>160</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>39</td>\n",
       "      <td>72</td>\n",
       "      <td>best</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_weight criterion  max_depth  max_features splitter  \\\n",
       "11         None   entropy          3           115     best   \n",
       "25         None   entropy          1           150   random   \n",
       "17     balanced   entropy          5           162   random   \n",
       "28         None      gini          3           136     best   \n",
       "47         None      gini          3           120   random   \n",
       "67     balanced   entropy          1            83     best   \n",
       "37     balanced      gini          1           177     best   \n",
       "10     balanced      gini          5           164     best   \n",
       "13         None   entropy          5            58     best   \n",
       "57     balanced   entropy         17           113     best   \n",
       "53         None      gini          5           109   random   \n",
       "96     balanced   entropy         45            47     best   \n",
       "65         None   entropy         19           119     best   \n",
       "26     balanced   entropy         47           186   random   \n",
       "56         None      gini         15           134     best   \n",
       "60     balanced   entropy         31           147   random   \n",
       "3      balanced   entropy         25            66   random   \n",
       "5      balanced   entropy         13           160   random   \n",
       "39         None      gini          5           186     best   \n",
       "80     balanced   entropy         13            93   random   \n",
       "84     balanced      gini         19            84     best   \n",
       "29     balanced   entropy         11           197   random   \n",
       "61     balanced   entropy          9           159     best   \n",
       "99         None   entropy         45           160     best   \n",
       "85     balanced   entropy         39            72     best   \n",
       "\n",
       "    mean_score_validation  mean_score_training  \n",
       "11                 0.6869               0.7884  \n",
       "25                 0.6711               0.6716  \n",
       "17                 0.6907               0.8379  \n",
       "28                 0.6769               0.8145  \n",
       "47                 0.6576               0.7318  \n",
       "67                 0.6369               0.7143  \n",
       "37                 0.6266               0.7168  \n",
       "10                 0.6845               0.9510  \n",
       "13                 0.6584               0.8983  \n",
       "57                 0.6936               1.0000  \n",
       "53                 0.6336               0.8218  \n",
       "96                 0.6911               1.0000  \n",
       "65                 0.6896               1.0000  \n",
       "26                 0.6846               1.0000  \n",
       "56                 0.6838               1.0000  \n",
       "60                 0.6836               1.0000  \n",
       "3                  0.6831               1.0000  \n",
       "5                  0.6805               0.9972  \n",
       "39                 0.6578               0.9390  \n",
       "80                 0.6800               1.0000  \n",
       "84                 0.6777               1.0000  \n",
       "29                 0.6755               0.9977  \n",
       "61                 0.6725               0.9982  \n",
       "99                 0.6731               1.0000  \n",
       "85                 0.6687               1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_parameters_grid = [{ 'class_weight': ['balanced', None], 'splitter': ['best', 'random'], 'max_features': [None, 10, 20, 30, 40, 50, 100, 'auto'], 'max_depth': [3, 5, 10, 15, 20, 50],'criterion': ('gini','entropy') }]\n",
    "tree_parameters_random = {'class_weight': ['balanced', None], 'splitter': ['best', 'random'], 'max_features': np.arange(10, 200, 1), 'max_depth': np.arange(1, 50, 2),'criterion': ('gini','entropy') }\n",
    "\n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(), tree_parameters_grid, cv=5, scoring=make_scorer(roc_auc_score), return_train_score=True)\n",
    "gridSearch.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(gridSearch, \"Decision Tree GridSearch\")\n",
    "\n",
    "\n",
    "randomSearch = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=tree_parameters_random, n_iter=100, cv=5, scoring=make_scorer(roc_auc_score), refit=True)\n",
    "randomSearch.fit(X_dev_np, y_dev_np)\n",
    "top_resultados(randomSearch, \"Decision Tree RandomSearch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones de Tree:\n",
    "\n",
    "Los mejores resultados obtenidos tanto en grid como en random search es para arboles de altura entre 3 y 5. Además encontramos que para arboles de profundidad mayor a 10, el árbol que se obtiene esta overfitteado, para cualquiera de los otros parametros. El splitter random da una mejor relación entre sesgo y varianza. Los criterios para decidir el slipt no mostraron influir demasiado en los resultados.\n",
    "\n",
    "Analizando los resultados obtenidos observamos que el factor que más influye es la profundidad del árbol.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección de Parametros para LDA:\n",
    "\n",
    "GridSearch:\n",
    "- solver: utilizaremos los criterios de descomposición en valores singulares'svd', cuadrados minimos 'lsqr' y autovectores 'eigen'\n",
    "- shrinkage: se combinará con lsqr y eigen con valores de 0.1, 0.5, 1 y none\n",
    "- n_components: es la cantidad de classes sobre las que se hará reducción de la dimensionalidad\n",
    "\n",
    "RandomSearch:\n",
    "Se usarán valores para shrinkage y n_components dentro de los mismos rangos que con GridSearch, pero seleccionando más valores dentro de éstos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para LDA GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>50.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>150.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7720</td>\n",
       "      <td>0.9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components shrinkage solver  mean_score_validation  mean_score_training\n",
       "43         100.0       0.5  eigen                 0.7730               0.9131\n",
       "35          50.0       0.5  eigen                 0.7730               0.9131\n",
       "27          20.0       0.5  eigen                 0.7730               0.9131\n",
       "19          10.0       0.5  eigen                 0.7730               0.9131\n",
       "11           5.0       0.5  eigen                 0.7730               0.9131\n",
       "51         150.0       0.5  eigen                 0.7730               0.9131\n",
       "3            1.0       0.5  eigen                 0.7730               0.9131\n",
       "26          20.0       0.5   lsqr                 0.7726               0.9142\n",
       "2            1.0       0.5   lsqr                 0.7726               0.9142\n",
       "10           5.0       0.5   lsqr                 0.7726               0.9142\n",
       "18          10.0       0.5   lsqr                 0.7726               0.9142\n",
       "42         100.0       0.5   lsqr                 0.7726               0.9142\n",
       "34          50.0       0.5   lsqr                 0.7726               0.9142\n",
       "50         150.0       0.5   lsqr                 0.7726               0.9142\n",
       "31          20.0      auto  eigen                 0.7720               0.9279\n",
       "47         100.0      auto  eigen                 0.7720               0.9279\n",
       "15           5.0      auto  eigen                 0.7720               0.9279\n",
       "39          50.0      auto  eigen                 0.7720               0.9279\n",
       "23          10.0      auto  eigen                 0.7720               0.9279\n",
       "55         150.0      auto  eigen                 0.7720               0.9279\n",
       "7            1.0      auto  eigen                 0.7720               0.9279\n",
       "37          50.0         1  eigen                 0.7290               0.7549\n",
       "45         100.0         1  eigen                 0.7290               0.7549\n",
       "29          20.0         1  eigen                 0.7290               0.7549\n",
       "13           5.0         1  eigen                 0.7290               0.7549"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 25 combinaciones para LDA RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>0.8610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>33</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7716</td>\n",
       "      <td>0.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>0.6058</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7757</td>\n",
       "      <td>0.8961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44</td>\n",
       "      <td>0.7637</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.8642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.8976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44</td>\n",
       "      <td>0.7978</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>0.8554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>0.7994</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>0.8559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35</td>\n",
       "      <td>0.5863</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.8993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.8810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>44</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.8818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>29</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.8818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>28</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>0.8735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0.8140</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.8492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.9042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.6420</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.8870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.9159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>0.8708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>0.8375</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7599</td>\n",
       "      <td>0.8420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.9065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>41</td>\n",
       "      <td>0.5504</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>0.9059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>13</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7485</td>\n",
       "      <td>0.8023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>39</td>\n",
       "      <td>0.8568</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7513</td>\n",
       "      <td>0.8354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>40</td>\n",
       "      <td>0.9411</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.7891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components  shrinkage solver  mean_score_validation  mean_score_training\n",
       "27            23     0.7745   lsqr                 0.7717               0.8610\n",
       "41            33     0.7428   lsqr                 0.7716               0.8691\n",
       "18            23     0.6058  eigen                 0.7757               0.8961\n",
       "11            44     0.7637   lsqr                 0.7692               0.8642\n",
       "40             6     0.7413   lsqr                 0.7696               0.8691\n",
       "36            36     0.5963  eigen                 0.7733               0.8966\n",
       "14             1     0.5915   lsqr                 0.7730               0.8976\n",
       "15            44     0.7978  eigen                 0.7655               0.8554\n",
       "3             35     0.7994   lsqr                 0.7655               0.8559\n",
       "8             35     0.5863   lsqr                 0.7730               0.8993\n",
       "0             29     0.6698   lsqr                 0.7692               0.8810\n",
       "39            44     0.6755  eigen                 0.7692               0.8818\n",
       "35            29     0.6745  eigen                 0.7692               0.8818\n",
       "49            28     0.7140  eigen                 0.7672               0.8735\n",
       "4             13     0.8140  eigen                 0.7630               0.8492\n",
       "12            35     0.5600   lsqr                 0.7727               0.9042\n",
       "1              9     0.6420  eigen                 0.7692               0.8870\n",
       "7              9     0.4932  eigen                 0.7750               0.9159\n",
       "17            22     0.7236  eigen                 0.7651               0.8708\n",
       "29            20     0.8375   lsqr                 0.7599               0.8420\n",
       "37            37     0.5453  eigen                 0.7706               0.9065\n",
       "43            41     0.5504   lsqr                 0.7703               0.9059\n",
       "48            13     0.9225  eigen                 0.7485               0.8023\n",
       "23            39     0.8568   lsqr                 0.7513               0.8354\n",
       "42            40     0.9411   lsqr                 0.7424               0.7891"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_parameters_grid = [{'solver': ['lsqr', 'eigen'], 'shrinkage': [0, 0.5, 1, 'auto'], 'n_components': [1, 5, 10, 20, 50, 100, 150]}, {'solver': ['lsqr']},\n",
    "                       {'solver': ['eigen']}]\n",
    "\n",
    "lda_parameters_random = {'solver': ['lsqr', 'eigen'], 'shrinkage': np.arange(0, 1, 0.000001).tolist() + ['auto'], 'n_components': np.arange(1, 50, 1)}\n",
    "\n",
    "grid_LDA_result = doSearch('grid', LinearDiscriminantAnalysis(), lda_parameters_grid)\n",
    "top_resultados(grid_LDA_result, \"LDA GridSearch\")\n",
    "\n",
    "random_LDA_result_grid = doSearch('random', LinearDiscriminantAnalysis(), lda_parameters_random)\n",
    "top_resultados(random_LDA_result, \"LDA RandomSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones de LDA:\n",
    "\n",
    "En los casos de GridSearch, los modelos con shrinkage 1.0 parecen tener mucho menos overfitting que aquellos con shrinkage 0.5, mientras que variar otros paramétros aparentemente no afecta los resultados de manera significativa.\n",
    "\n",
    "Utilizando RandomSearch pudimos profundizar sobre estas variaciones de shrinkage para intentar mejorar los resultados. Sin embargo no parecen haber contribuido nada nuevo, simplemente cuánto más cerca de 0.5 estamos tenemos mayor overfitting, mientras que a medida que nos acercamos a 1.0 se reduce éste, manteniendo un score de validation razonable.\n",
    "\n",
    "El uso de shrinkage \"auto\" no parece aportar nada nuevo a los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_gauss_result = doSearch('grid', GaussianNB(), {})\n",
    "top_resultados(grid_gauss_result, \"Naive Gauss GridSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones de Naive Bayes:\n",
    "Los resultados obtenidos para Naive Bayes son relativamente buenos, esto podríamos usarlos para tener una intuición de cuánta dependencia existe entre los atributos (dado que naive bayes asume una independencia total entre los atributos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección de Parametros para SVM:\n",
    "\n",
    "GridSearch:\n",
    "- C: es el parametro de penalización a los errores se probaremos con 0.1 daremos poca tolerancia al error a fin de que encuentre un mejor hiperplano, 1.0 es el valor por deafult y 1000 para dejar poca tolerancia a los errores\n",
    "- kernel : probaremos con ‘linear’, ‘poly’, ‘rbf’ y ‘sigmoid’\n",
    "- gamma: se usará en auto\n",
    "- degree: para 'poly' se tomará de grado 3\n",
    "\n",
    "RandomSearch:\n",
    "Se generan modelos con una cobertura más alta y más detallada de gammas y C, pero se mantiene el resto de los hiperparámetros parecidos a los originales de grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 25 combinaciones para SVM GridSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7731</td>\n",
       "      <td>0.6847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>0.7866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.8379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7455</td>\n",
       "      <td>0.7505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7596</td>\n",
       "      <td>0.8807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>0.7433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7171</td>\n",
       "      <td>0.6998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.9958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.6156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.6129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.7128</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7124</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.5947</td>\n",
       "      <td>0.6233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C   gamma   kernel  mean_score_validation  mean_score_training\n",
       "2      0.1  0.1000  sigmoid                 0.7731               0.6847\n",
       "5      0.1  0.0100  sigmoid                 0.7531               0.7866\n",
       "20     1.0  0.0010  sigmoid                 0.7576               0.8379\n",
       "17     1.0  0.0100  sigmoid                 0.7455               0.7505\n",
       "18     1.0  0.0010      rbf                 0.7596               0.8807\n",
       "21     1.0  0.0001      rbf                 0.7326               0.7433\n",
       "29  1000.0  0.0100  sigmoid                 0.7171               0.6998\n",
       "27  1000.0  0.0100      rbf                 0.7696               1.0000\n",
       "15     1.0  0.0100      rbf                 0.7555               0.9958\n",
       "26  1000.0  0.1000  sigmoid                 0.6841               0.6156\n",
       "14     1.0  0.1000  sigmoid                 0.6841               0.6129\n",
       "30  1000.0  0.0010      rbf                 0.7404               1.0000\n",
       "16     1.0  0.0100     poly                 0.7322               1.0000\n",
       "25  1000.0  0.1000     poly                 0.7322               1.0000\n",
       "31  1000.0  0.0010     poly                 0.7322               1.0000\n",
       "1      0.1  0.1000     poly                 0.7322               1.0000\n",
       "28  1000.0  0.0100     poly                 0.7322               1.0000\n",
       "13     1.0  0.1000     poly                 0.7322               1.0000\n",
       "35  1000.0  0.0001  sigmoid                 0.7201               0.9900\n",
       "36     0.1     NaN   linear                 0.7201               0.9900\n",
       "37     1.0     NaN   linear                 0.7128               1.0000\n",
       "38  1000.0     NaN   linear                 0.7128               1.0000\n",
       "32  1000.0  0.0010  sigmoid                 0.7124               1.0000\n",
       "33  1000.0  0.0001      rbf                 0.7090               1.0000\n",
       "6      0.1  0.0010      rbf                 0.5947               0.6233"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Top 25 combinaciones para SVM RandomSearch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>279.79</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7407</td>\n",
       "      <td>0.6581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>308.12</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7333</td>\n",
       "      <td>0.6744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>255.21</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>0.6723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>974.30</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>531.83</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.6668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>670.07</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7127</td>\n",
       "      <td>0.6480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>722.41</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.6379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.30</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>401.37</td>\n",
       "      <td>0.1476</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.7047</td>\n",
       "      <td>0.6223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>496.10</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6968</td>\n",
       "      <td>0.6233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>666.20</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6914</td>\n",
       "      <td>0.6206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>612.16</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6879</td>\n",
       "      <td>0.6233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>366.01</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6897</td>\n",
       "      <td>0.6095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>323.37</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.6116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>17.31</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.6168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>374.73</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.6693</td>\n",
       "      <td>0.6251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>259.86</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>832.34</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>591.69</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>583.54</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>304.76</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>929.15</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>439.24</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>402.22</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>391.42</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.7322</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C   gamma   kernel  mean_score_validation  mean_score_training\n",
       "18  279.79  0.0165  sigmoid                 0.7407               0.6581\n",
       "27  308.12  0.0145  sigmoid                 0.7333               0.6744\n",
       "39  255.21  0.0176  sigmoid                 0.7308               0.6723\n",
       "45  974.30  0.0056      rbf                 0.7727               1.0000\n",
       "22  531.83  0.0178  sigmoid                 0.7215               0.6668\n",
       "12  670.07  0.0345  sigmoid                 0.7127               0.6480\n",
       "5   722.41  0.0497  sigmoid                 0.7051               0.6379\n",
       "0    45.30  0.1282  sigmoid                 0.7088               0.6172\n",
       "8   401.37  0.1476  sigmoid                 0.7047               0.6223\n",
       "17  496.10  0.0691  sigmoid                 0.6968               0.6233\n",
       "29  666.20  0.1717  sigmoid                 0.6914               0.6206\n",
       "38  612.16  0.0630  sigmoid                 0.6879               0.6233\n",
       "36  366.01  0.2678  sigmoid                 0.6897               0.6095\n",
       "47  323.37  0.1639  sigmoid                 0.6851               0.6116\n",
       "26   17.31  0.1978  sigmoid                 0.6807               0.6168\n",
       "20  374.73  0.0898  sigmoid                 0.6693               0.6251\n",
       "24  259.86  0.0116     poly                 0.7322               1.0000\n",
       "41  832.34  0.0239     poly                 0.7322               1.0000\n",
       "32  591.69  0.0049     poly                 0.7322               1.0000\n",
       "31  583.54  0.0990     poly                 0.7322               1.0000\n",
       "28  304.76  0.1189     poly                 0.7322               1.0000\n",
       "44  929.15  0.0425     poly                 0.7322               1.0000\n",
       "34  439.24  0.3113     poly                 0.7322               1.0000\n",
       "25  402.22  0.0559     poly                 0.7322               1.0000\n",
       "49  391.42  0.0257     poly                 0.7322               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_parameters_grid = [{'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma': [1e-1, 1e-2,1e-3, 1e-4], 'C': [0.1, 1, 1000]}, {'kernel': ['linear'], 'C': [0.1, 1, 1000]}]\n",
    "svm_parameters_random = {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':sp.stats.expon(scale=.1),'C': np.arange(0.1, 1000, 0.01)}\n",
    "\n",
    "\n",
    "grid_SVM_result = doSearch('grid', SVC(), svm_parameters_grid)\n",
    "top_resultados(grid_SVM_result, \"SVM GridSearch\")\n",
    "\n",
    "random_SVM_result = doSearch('random', SVC(), svm_parameters_random)\n",
    "top_resultados(random_SVM_result, \"SVM RandomSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones de SVM:\n",
    "\n",
    "Observando los resultados vemos que tomando un kernel sigmoide se obtienen buenos resultados con una"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ESTO DE ACA ABAJO YA NO VA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Conclusiones Grid Search\n",
    "\n",
    "##### KNN \n",
    "    Se buscó probar variando la forma en que se determinan los pesos de los vecinos mas cercanos, para determinar cuál es más performante, uniform parece superar ampliamente a distance en este caso, aparte se testeó con varios números de vecinos más cercanos, y por lo que se ve los mejores resultados se dan cuando se tiene un número de vecinos más cercanos relativamente grande (los buenos resultados se obtienen combinando uniform con numeros grandes de vecinos, entre 20 - 100)\n",
    "    En cuanto al parametro p, que define la fórmula de distancia a utilizar, no encontramos diferencias significativas entre la distancia manhattan y la euclidiana.\n",
    "    \n",
    "    El GridSearch parece presentar mejores resultados, aunque extrañamente el training score supera en muchos casos al validation.\n",
    "    \n",
    "    \n",
    "##### Árboles de Decisión \n",
    "\n",
    "    Se decidió hacer un intento de testear asignar pesos balanceados las clases testeadas (class_weight=\"balanced\"), si bien no pareció influir mucho en el resultado final. Sin embargo se podría suponer que el uso de este parámetro tiene una influencia significativa si se tiene un conocimiento más en profundidad acerca de los atributos analizados y su influencia en el resultado final (maldad o no).\n",
    "\n",
    "    Se decidió probar variar los max_features para decidir si con esto se podría volver más manejable la posibilidad de overfitting en los árboles más altos, sin embargo no se notó ninguna diferencia significativa, ya que parece que max_features parece mantenerse como el superior.\n",
    "\n",
    "    Los árboles con alturas más bajas parecen tener mejores resultados, mientras que los de mayor altura presentan un overfitting cada vez más pronunciado\n",
    "    \n",
    "    Usar GridSearch no provee mejoras significativas en los casos observados.\n",
    "\n",
    "##### LDA \n",
    "    \n",
    "    Los solvers, sin embargo, no parecen afectar en este caso\n",
    "\n",
    "    LDA presenta una mejora significativa cuando se cuenta con shrinkage = 1.0\n",
    "\n",
    "##### Naive Bayes\n",
    "    Si bien Naive-Bayes no ofrece uno de los mejores resultados y no es capaz de detectar ni incorporar ninguna dependencia entre atributos a sus predicciones, se puede ver que es preferible respecto a los árboles de decisión (por ejemplo), dado que no sólo predice mejor al conjunto de testeo, si no que es un algoritmo altamente escalable con una implementación simple. Se lo podría utilizar como una heurística para explorar el conjunto de entrenamiento. Si los atributos son muy dependientes entre sí, en teoría el modelo no debería ser bueno prediciendo.\n",
    "##### SVM \n",
    "\n",
    "    Para SVM variamos los hiperparámetros kernel, gamma y C.\n",
    "    En primer lugar podemos ver que el kernel polinomial genera una curva que se ajusta demasiado a las instancias de entrenamiento, perdiendo frente a los otros dos tipos de kernel.\n",
    "    Por otra parte podemos ver que aumentar C hasta cierto punto suele verse acompañado de una mejora en la validación. Un C demasiado grande únicamente logra ajustar de más a los datos de entrenamiento. Pareciera ser que un C entre 10 y 100 sería el ideal.\n",
    "    Un valor de gamma bajo genera más estabilidad en la frontera de divisón, dado que más puntos se toman en cuenta para calcularla. Para los gammas testeados, parecería ser que el 0.001 es el mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(train_scores, validation_scores, param_range, xlabel=\"X\", title=\"Curva de complejidad\"):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.ylim(0.0,1.1)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xticks(param_range)\n",
    "    plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
    "    \n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\")\n",
    "    \n",
    "    plt.plot(param_range, validation_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "    \n",
    "    marker_line_width = 0.005\n",
    "    plt.axhspan(0.8 - marker_line_width/2, 0.8 + marker_line_width/2, alpha=0.5)\n",
    "    \n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(1.0, 1.0))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#    None\tgini\t2\tauto\t0.6746\t0.6997\n",
    "# \"Seleccionamos el que consideramos uno de los mejores arboles obtenidos en GridSearch del ej 3\"\n",
    "depths_to_try = np.arange(1, 50, 1)\n",
    "decision_tree_train_scores, decision_tree_validation_scores = \\\n",
    "    validation_curve( \\\n",
    "        DecisionTreeClassifier(max_features=\"auto\", criterion=\"gini\"), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        \"max_depth\", \\\n",
    "        depths_to_try, \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score) \\\n",
    "    )\n",
    "\n",
    "# {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':sp.stats.expon(scale=.1),'C': sp.stats.expon(scale=10)}\n",
    "# 0.0001\trbf\t0.7679\t0.8707\n",
    "cs_to_try = np.arange(1,100,2)\n",
    "svm_train_scores, svm_validation_scores = \\\n",
    "    validation_curve( \\\n",
    "        SVC(gamma=0.0001, kernel='rbf'), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        \"C\", \\\n",
    "        cs_to_try, \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score), \\\n",
    "        n_jobs = 1 \\\n",
    "    )\n",
    "\n",
    "plot_validation_curve(decision_tree_train_scores, decision_tree_validation_scores, depths_to_try, xlabel=\"Depth\", title=\"Curva de Complejidad con Arboles de Aprendizaje\")\n",
    "plot_validation_curve(svm_train_scores, svm_validation_scores, cs_to_try, xlabel=\"C\", title=\"Curva de Complejidad con SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Aprendizaje\n",
    "El Depth claramente aumenta la complejidad de los árboles de manera muy rápida, lo cual lleva a modelos con un sesgo cada vez menor pero en general pareciera tener una varianza bastante alta a partir de ciertas alturas (alrededor de 5), algo que parece correlacionado con el grado de overfitting que presenta el árbol.\n",
    "\n",
    "No parece haber una curva tan definida en la que se pueda conseguir un tradeoff útil entre sesgo y varianza basados en el Depth, savlo quizás en las alturas más pequeñas.\n",
    "\n",
    "### SVM\n",
    "\n",
    "El C parece tener una influencia que escala de manera menos brusca en el overfitting y en la varianza presentada por los modelos.\n",
    "\n",
    "Sin embargo, está claro que el sesgo va disminuyendo a medida que se aumenta el C y la varianza va aumentando, debido a que estamos condiciando al algoritmo a darle una mayor importancia a tener en cuenta a minions que con menor C se pueden considerar ignorables.\n",
    "\n",
    "Pareciera que la zona de los mejores Cs antes de comenzar a caer en la varianza aumentada sería la zona de los Cs entre 9 y 15. En particular C = 11 se ve como la mejor opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_scores, validation_scores, param_range, title=\"Curva de aprendizaje\"):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.ylim(0.0,1.1)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"n\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    \n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\")\n",
    "    plt.plot(param_range, validation_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\")\n",
    "    \n",
    "    marker_line_width = 0.005\n",
    "    plt.axhspan(0.8 - marker_line_width/2, 0.8 + marker_line_width/2, alpha=0.5)\n",
    "    \n",
    "    plt.legend(loc='lower right', bbox_to_anchor=(1.0, 1.0))\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#    None\tgini\t2\tauto\t0.6746\t0.6997\n",
    "# \"Seleccionamos el que consideramos uno de los mejores arboles obtenidos en GridSearch del ej 3\"\n",
    "dtree_train_sizes_abs, decision_tree_train_scores, decision_tree_validation_scores = \\\n",
    "    learning_curve( \\\n",
    "        DecisionTreeClassifier(max_features=\"auto\", criterion=\"gini\", max_depth=3), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        train_sizes = np.arange(0.1, 1., 0.02), \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score) \\\n",
    "    )\n",
    "\n",
    "# {'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma':sp.stats.expon(scale=.1),'C': sp.stats.expon(scale=10)}\n",
    "# 0.0001\trbf\t0.7679\t0.8707\n",
    "svm_train_sizes_abs, svm_train_scores, svm_validation_scores = \\\n",
    "    learning_curve( \\\n",
    "        SVC(gamma=0.0001, kernel='rbf', C=3), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        train_sizes = np.arange(0.1, 1., 0.02), \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score), \\\n",
    "    )\n",
    "\n",
    "plot_learning_curve(decision_tree_train_scores, decision_tree_validation_scores, dtree_train_sizes_abs, title=\"Curva de Aprendizaje con Arboles de Decisión\")\n",
    "plot_learning_curve(svm_train_scores, svm_validation_scores, svm_train_sizes_abs, title=\"Curva de Aprendizaje con SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de Decisión\n",
    "\n",
    "En los árboles de decisión parece que hay una tendencia pronunciada a reducir la varianza, pero el sesgo se mantiene bastante malo a lo largo de todos los n's analizados y no parece tener una tendencia a mejorar con mayores cantidades de datos de entrenamiento, por lo que no consideramos que más datos ayudarían a algo que no sea reducir la varianza (cosa que no ayuda cuando no hay esperanza de mejorar el sesgo).\n",
    "\n",
    "### SVM\n",
    "\n",
    "Inicialmente el sesgo de svm es bastante grande y con cantidades menores a 130 aproximadamente es muy poco confiable.\n",
    "\n",
    "En base al análisis de las curvas de aprendizaje pareciera que SVM probablemente se beneficiaría de tener más datos debido a que los datos de validación presentan una tendencia a crecer en su scoring.\n",
    "\n",
    "Presenta una varianza bastante pequeña inicialmente pero la introducción de más datos parece afectar negativamente este valor, por lo que habría que considerar la posibilidad de limitar en un cierto punto la cantidad de datos de entrenamiento para evitar ganar demasiada varianza (si es que esta tendencia se mantiene)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_parameters = [{'max_depth': [None, 3, 8, 15, 30, 50] , 'criterion': ['gini', 'entropy']}]\n",
    "grid_forest_result = doSearch('grid', RandomForestClassifier(n_estimators=200), forest_parameters)\n",
    "top_resultados(grid_forest_result, \"Random Forest\")\n",
    "\n",
    "# Seleccionamos max_depth = 3\n",
    "# porque una depth mayor parecía invariablemente llevar a overfitting en todos los casos\n",
    "\n",
    "max_features_to_try = np.arange(1, 200, 4)\n",
    "random_forest_train_scores, random_forest_validation_scores = \\\n",
    "    validation_curve( \\\n",
    "        RandomForestClassifier(n_estimators=200, criterion=\"gini\", max_depth=3), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        \"max_features\", \\\n",
    "        max_features_to_try, \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score) \\\n",
    "    )\n",
    "\n",
    "plot_validation_curve(random_forest_train_scores, random_forest_validation_scores, max_features_to_try, xlabel=\"Max Features\", title=\"Curva de Complejidad con Random Forest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max features\n",
    "\n",
    "#### Explicación \n",
    "\n",
    "Max features determina la cantidad de atributos que deben observar los árboles cuando se intenta determinar cuál es la mejor manera de separar los valores en cada nodo según los valores de sus atributos.\n",
    "\n",
    "Esto podría resultar beneficioso en el uso de muchos árboles al mismo tiempo para poder analizar los objetos desde diferentes \"perspectivas\" y luego proceder a votar. De otra manera podríamos terminar con muchos árboles parecidos sin que ninguno de estos pueda contribuir nada muy distinto a la hora de clasificar un minion.\n",
    "\n",
    "#### Análisis\n",
    "\n",
    "La curva de complejidad de Random Forest no parece presentar muy buenos valores para límites muy grandes, pareciera que mantener muchos árboles de tamaño pequeño que miran pocas features es la mejor estrategia a juzgar por los datos que se tienen.\n",
    "\n",
    "En particular alrededor de las 15 max_features por árbol se presenta la mejor opción.\n",
    "\n",
    "Estos resultados parecen validar la opinión antes dada de que tener muchos árboles con distintas perspectivas provee una mejor votación a la hora de clasificar cada minion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_train_sizes_abs, random_forest_train_scores, random_forest_validation_scores = \\\n",
    "    learning_curve( \\\n",
    "        RandomForestClassifier(n_estimators=200, criterion=\"gini\", max_depth=3, max_features=15), \\\n",
    "        X_dev_np, y_dev_np, \\\n",
    "        train_sizes = np.arange(0.1, 1., 0.02), \\\n",
    "        cv=5, \\\n",
    "        scoring=make_scorer(roc_auc_score), \\\n",
    "    )\n",
    "\n",
    "plot_learning_curve(random_forest_train_scores, random_forest_validation_scores, random_forest_train_sizes_abs, title=\"Curva de Aprendizaje con Random Forest con Depth bajo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados parecen bastante prometedores, en particular, pareciera que se consiguió un sesgo relativamente bueno desde el principio.\n",
    "\n",
    "Sin embargo, la varianza parece reducirse bastante lentamente, aunque se podría probar con más datos para ver si la tendencia a reducir la varianza se dibuja más pronunciadamente con otro entrenamiento con mayor experiencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  n_neighbors p weights mean_score_validation mean_score_training\n",
    "#  71 2 uniform 0.7674 0.7627\n",
    "kneighbors = KNeighborsClassifier(n_neighbors=71, p=2, weights=\"uniform\")\n",
    "\n",
    "X_eval_np = np.array(X_eval)\n",
    "y_eval_np = np.array(y_eval).ravel()\n",
    "\n",
    "kneighbors.fit(X_dev_np, y_dev_np)\n",
    "# kneighbors.fit(X_eval_np, y_eval_np)\n",
    "# lda.fit(X_eval_np, y_eval_np)\n",
    "\n",
    "y_prediction_knn = kneighbors.predict(X_eval_np)\n",
    "print(\"Scoring esperado para la competencia: \", roc_auc_score(y_eval_np, y_prediction_knn))\n",
    "\n",
    "kneighbors_competition = KNeighborsClassifier(n_neighbors=71, p=2, weights=\"uniform\")\n",
    "kneighbors_competition.fit(np.array(X), np.array(y).ravel())\n",
    "\n",
    "prediction = pd.DataFrame(kneighbors_competition.predict(X_competencia))\n",
    "prediction.columns = ['output']\n",
    "prediction.to_csv('y_competencia.csv', encoding='utf-8', index_label=\"index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
